<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/latest/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/latest/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/latest/img/botorch.png"/><link rel="shortcut icon" href="/v/latest/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-2', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/v/latest/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/latest/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/latest/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/latest/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/latest/css/main.css"/><script src="/v/latest/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/latest/"><img class="logo" src="/v/latest/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/latest/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/latest/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/latest/api/" target="_self">API Reference</a></li><li class=""><a href="/v/latest/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<section id="module-botorch.models">
<span id="botorch-models"></span><h1>botorch.models<a class="headerlink" href="#module-botorch.models" title="Permalink to this headline">¶</a></h1>
<section id="model-apis">
<h2>Model APIs<a class="headerlink" href="#model-apis" title="Permalink to this headline">¶</a></h2>
<section id="module-botorch.models.model">
<span id="abstract-model-api"></span><h3>Abstract Model API<a class="headerlink" href="#module-botorch.models.model" title="Permalink to this headline">¶</a></h3>
<p>Abstract base module for all BoTorch models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.model.Model">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.model.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><a class="reference internal" href="_modules/botorch/models/model.html#Model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for BoTorch models.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.posterior">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="simple">
<dt>Note: The input transforms should be applied here using</dt><dd><p><cite>self.transform_inputs(X)</cite> after the <cite>self.eval()</cite> call and before
any <cite>model.forward</cite> or <cite>model.likelihood</cite> calls.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>b x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of the
feature space, <cite>q</cite> is the number of points considered jointly,
and <cite>b</cite> is the batch dimension.</p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>) – If True, add observation noise to the posterior.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>Posterior</cite> object, representing a batch of <cite>b</cite> joint distributions
over <cite>q</cite> points and <cite>m</cite> outputs each.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">botorch.posteriors.posterior.Posterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.model.Model.batch_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Size</span></em><a class="headerlink" href="#botorch.models.model.Model.batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.model.Model.num_outputs">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#botorch.models.model.Model.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type and with the same parameters as
the current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model">botorch.models.model.Model</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, it is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model">botorch.models.model.Model</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.fantasize">
<span class="sig-name descname"><span class="pre">fantasize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.fantasize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.fantasize" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a fantasy model.</p>
<p>Constructs a fantasy model in the following fashion:
(1) compute the model posterior at <cite>X</cite> (including observation noise if
<cite>observation_noise=True</cite>).
(2) sample from this posterior (using <cite>sampler</cite>) to generate “fake”
observations.
(3) condition the model on the new fake observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.samplers.MCSampler" title="botorch.sampling.samplers.MCSampler"><em>botorch.sampling.samplers.MCSampler</em></a>) – The sampler used for sampling from the posterior at <cite>X</cite>.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>) – If True, include observation noise.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The constructed fantasy model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model">botorch.models.model.Model</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model.Model.transform_inputs">
<span class="sig-name descname"><span class="pre">transform_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.transform_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model.Model.transform_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A tensor of inputs</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><em>torch.nn.modules.module.Module</em><em>]</em>) – A Module that performs the input transformation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of transformed inputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.model.Model.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.model.Model.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.gpytorch">
<span id="gpytorch-model-api"></span><h3>GPyTorch Model API<a class="headerlink" href="#module-botorch.models.gpytorch" title="Permalink to this headline">¶</a></h3>
<p>Abstract model class for all GPyTorch-based botorch models.</p>
<p>To implement your own, simply inherit from both the provided classes and a
GPyTorch Model class such as an ExactGP.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">GPyTorchModel</span></span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.model.Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for models based on GPyTorch models.</p>
<p>The easiest way to use this is to subclass a model from a GPyTorch model
class (e.g. an <cite>ExactGP</cite>) and this <cite>GPyTorchModel</cite>. See e.g. <cite>SingleTaskGP</cite>.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.batch_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Size</span></em><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.num_outputs">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>observation_noise</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>torch.Tensor</em><em>]</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q</cite>).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing a batch of <cite>b</cite> joint
distributions over <cite>q</cite> points. Includes observation noise if
specified.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">botorch.posteriors.gpytorch.GPyTorchPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape’ x n x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model">botorch.models.model.Model</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.gpytorch.GPyTorchModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">BatchedMultiOutputGPyTorchModel</span></span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.GPyTorchModel</span></code></a></p>
<p>Base class for batched multi-output GPyTorch models with independent outputs.</p>
<p>This model should be used when the same training data is used for all outputs.
Outputs are modeled independently by using a different batch for each output.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.get_batch_dimensions">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">get_batch_dimensions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.get_batch_dimensions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.get_batch_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the raw batch shape and output-augmented batch shape of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – A <cite>n x d</cite> or <cite>batch_shape x n x d</cite> (batch mode) tensor of training
features.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – A <cite>n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>The <cite>input_batch_shape</cite></p></li>
<li><p>The output-augmented batch shape: <cite>input_batch_shape x (m)</cite></p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[torch.Size, torch.Size]</p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.batch_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Size</span></em><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>torch.Tensor</em><em>]</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q x m</cite>).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes observation noise if specified.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">botorch.posteriors.gpytorch.GPyTorchPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>m</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>BatchedMultiOutputGPyTorchModel</cite> object of the same type with
<cite>n + n’</cite> training examples, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</a></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">ModelListGPyTorchModel</span></span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.GPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for models based on multi-output GPyTorch models.</p>
<p>This is meant to be used with a gpytorch ModelList wrapper for independent
evaluation of submodels.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.batch_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Size</span></em><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>b x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of the
feature space, <cite>q</cite> is the number of points considered jointly,
and <cite>b</cite> is the batch dimension.</p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>torch.Tensor</em><em>]</em>) – If True, add the observation noise from the
respective likelihoods to the posterior. If a Tensor of shape
<cite>(batch_shape) x q x m</cite>, use it directly as the observation
noise (with <cite>observation_noise[…,i]</cite> added to the posterior
of the <cite>i</cite>-th model).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes measurement noise if
<cite>observation_noise</cite> is specified.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">botorch.posteriors.gpytorch.GPyTorchPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape’ x n x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="botorch.models.gpytorch.ModelListGPyTorchModel">botorch.models.gpytorch.ModelListGPyTorchModel</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.transform_inputs">
<span class="sig-name descname"><span class="pre">transform_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel.transform_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.transform_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Individually transform the inputs for each model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A tensor of inputs</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of tensors of transformed inputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.gpytorch.ModelListGPyTorchModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gpytorch.MultiTaskGPyTorchModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gpytorch.</span></span><span class="sig-name descname"><span class="pre">MultiTaskGPyTorchModel</span></span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#MultiTaskGPyTorchModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.GPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for multi-task models based on GPyTorch models.</p>
<p>This class provides the <cite>posterior</cite> method to models that implement a
“long-format” multi-task GP in the style of <cite>MultiTaskGP</cite>.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gpytorch.MultiTaskGPyTorchModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#MultiTaskGPyTorchModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>q x d</cite> or <cite>batch_shape x q x d</cite> (batch mode) tensor, where <cite>d</cite> is the
dimension of the feature space (not including task indices) and
<cite>q</cite> is the number of points considered jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>torch.Tensor</em><em>]</em>) – If True, add observation noise from the respective
likelihoods. If a Tensor, specifies the observation noise levels
to add.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite>. Includes measurement noise if
<cite>observation_noise</cite> is specified.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">botorch.posteriors.gpytorch.GPyTorchPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.gpytorch.MultiTaskGPyTorchModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.deterministic">
<span id="deterministic-model-api"></span><h3>Deterministic Model API<a class="headerlink" href="#module-botorch.models.deterministic" title="Permalink to this headline">¶</a></h3>
<p>Deterministic Models. Simple wrappers that allow the usage of deterministic
mappings via the BoTorch Model and Posterior APIs. Useful e.g. for defining
known cost functions for cost-aware acquisition utilities.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.DeterministicModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">DeterministicModel</span></span><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.model.Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for deterministic models.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.DeterministicModel.forward">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.deterministic.DeterministicModel.num_outputs">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.DeterministicModel.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) posterior at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.deterministic.DeterministicPosterior" title="botorch.posteriors.deterministic.DeterministicPosterior">botorch.posteriors.deterministic.DeterministicPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.deterministic.DeterministicModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.GenericDeterministicModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">GenericDeterministicModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.deterministic.DeterministicModel</span></code></a></p>
<p>A generic deterministic model constructed from a callable.</p>
<p>A generic deterministic model constructed from a callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – A callable mapping a <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>
to a <cite>batch_shape x n x m</cite>-dimensional output tensor (the
outcome dimension <cite>m</cite> must be explicit, even if <cite>m=1</cite>).</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – The number of outputs <cite>m</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.GenericDeterministicModel.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.deterministic.GenericDeterministicModel" title="botorch.models.deterministic.GenericDeterministicModel">botorch.models.deterministic.GenericDeterministicModel</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.GenericDeterministicModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.deterministic.GenericDeterministicModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.deterministic.AffineDeterministicModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.deterministic.</span></span><span class="sig-name descname"><span class="pre">AffineDeterministicModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.deterministic.DeterministicModel</span></code></a></p>
<p>An affine deterministic model.</p>
<p>Affine deterministic model from weights and offset terms.</p>
<p>A simple model of the form</p>
<blockquote>
<div><p>y[…, m] = b[m] + sum_{i=1}^d a[i, m] * X[…, i]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>Tensor</em>) – A <cite>d x m</cite>-dim tensor of linear weights, where <cite>m</cite> is the number
of outputs (must be explicit if <cite>m=1</cite>)</p></li>
<li><p><strong>b</strong> (<em>Union</em><em>[</em><em>Tensor</em><em>, </em><em>float</em><em>]</em>) – The affine (offset) term. Either a float (for single-output
models or if the offset is shared), or a <cite>m</cite>-dim tensor (with
different offset values for for the <cite>m</cite> different outputs).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.AffineDeterministicModel.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.deterministic.AffineDeterministicModel" title="botorch.models.deterministic.AffineDeterministicModel">botorch.models.deterministic.AffineDeterministicModel</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.deterministic.AffineDeterministicModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.deterministic.AffineDeterministicModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h2>
<section id="module-botorch.models.cost">
<span id="cost-models-for-cost-aware-optimization"></span><h3>Cost Models (for cost-aware optimization)<a class="headerlink" href="#module-botorch.models.cost" title="Permalink to this headline">¶</a></h3>
<p>Cost models to be used with multi-fidelity optimization.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.cost.AffineFidelityCostModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.cost.</span></span><span class="sig-name descname"><span class="pre">AffineFidelityCostModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fidelity_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_cost</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#AffineFidelityCostModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.cost.AffineFidelityCostModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.deterministic.DeterministicModel</span></code></a></p>
<p>Affine cost model operating on fidelity parameters.</p>
<p>For each (q-batch) element of a candidate set <cite>X</cite>, this module computes a
cost of the form</p>
<blockquote>
<div><p>cost = fixed_cost + sum_j weights[j] * X[fidelity_dims[j]]</p>
</div></blockquote>
<p>Affine cost model operating on fidelity parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fidelity_weights</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A dictionary mapping a subset of columns of <cite>X</cite>
(the fidelity parameters) to it’s associated weight in the
affine cost expression. If omitted, assumes that the last
column of X is the fidelity parameter with a weight of 1.0.</p></li>
<li><p><strong>fixed_cost</strong> (<em>float</em>) – The fixed cost of running a single candidate point (i.e.
an element of a q-batch).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.cost.AffineFidelityCostModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#AffineFidelityCostModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.cost.AffineFidelityCostModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the cost on a candidate set X.</p>
<p>Computes a cost of the form</p>
<blockquote>
<div><p>cost = fixed_cost + sum_j weights[j] * X[fidelity_dims[j]]</p>
</div></blockquote>
<p>for each element of the q-batch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x q x d’</cite>-dim tensor of candidate points.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x q x 1</cite>-dim tensor of costs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.cost.AffineFidelityCostModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.cost.AffineFidelityCostModel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.gp_regression">
<span id="gp-regression-models"></span><h3>GP Regression Models<a class="headerlink" href="#module-botorch.models.gp_regression" title="Permalink to this headline">¶</a></h3>
<p>Gaussian Process Regression models based on GPyTorch models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression.SingleTaskGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression.</span></span><span class="sig-name descname"><span class="pre">SingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code></p>
<p>A single-task exact GP model.</p>
<p>A single-task exact GP using relatively strong priors on the Kernel
hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance).</p>
<p>This model works in batch mode (each batch having its own hyperparameters).
When the training observations include multiple outputs, this model will use
batching to model outputs independently.</p>
<p>Use this model when you have independent output(s) and all outputs use the
same training data. If outputs are independent and outputs have different
training data, use the ModelListGP. When modeling correlations between
outputs, use the MultiTaskGP.</p>
<p>A single-task exact GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>likelihood</strong> (<em>Optional</em><em>[</em><em>Likelihood</em><em>]</em>) – A likelihood. If omitted, use a standard
GaussianLikelihood with inferred noise level.</p></li>
<li><p><strong>covar_module</strong> (<em>Optional</em><em>[</em><em>Module</em><em>]</em>) – The module computing the covariance (Kernel) matrix.
If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.SingleTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>gpytorch.distributions.multivariate_normal.MultivariateNormal</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.SingleTaskGP.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – <cite>TrainingData</cite> container with data for single outcome
or for multiple outcomes for batched multi-output case.</p></li>
<li><p><strong>**kwargs</strong> – None expected for this class.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression.FixedNoiseGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression.</span></span><span class="sig-name descname"><span class="pre">FixedNoiseGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code></p>
<p>A single-task exact GP model using fixed noise levels.</p>
<p>A single-task exact GP that uses fixed observation noise levels. This model
also uses relatively strong priors on the Kernel hyperparameters, which work
best when covariates are normalized to the unit cube and outcomes are
standardized (zero mean, unit variance).</p>
<p>This model works in batch mode (each batch having its own hyperparameters).</p>
<p>A single-task exact GP model using fixed noise levels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transfrom that is applied in the model’s
forward pass.</p></li>
<li><p><strong>covar_module</strong> (<em>Optional</em><em>[</em><em>Module</em><em>]</em>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.FixedNoiseGP.fantasize">
<span class="sig-name descname"><span class="pre">fantasize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP.fantasize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP.fantasize" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a fantasy model.</p>
<p>Constructs a fantasy model in the following fashion:
(1) compute the model posterior at <cite>X</cite> (if <cite>observation_noise=True</cite>,
this includes observation noise taken as the mean across the observation
noise in the training data. If <cite>observation_noise</cite> is a Tensor, use
it directly as the observation noise to add).
(2) sample from this posterior (using <cite>sampler</cite>) to generate “fake”
observations.
(3) condition the model on the new fake observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.samplers.MCSampler" title="botorch.sampling.samplers.MCSampler"><em>botorch.sampling.samplers.MCSampler</em></a>) – The sampler used for sampling from the posterior at <cite>X</cite>.</p></li>
<li><p><strong>observation_noise</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>torch.Tensor</em><em>]</em>) – If True, include the mean across the observation
noise in the training data as observation noise in the posterior
from which the samples are drawn. If a Tensor, use it directly
as the specified measurement noise.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The constructed fantasy model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gp_regression.FixedNoiseGP" title="botorch.models.gp_regression.FixedNoiseGP">botorch.models.gp_regression.FixedNoiseGP</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.FixedNoiseGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>gpytorch.distributions.multivariate_normal.MultivariateNormal</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.FixedNoiseGP.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.FixedNoiseGP.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – <cite>TrainingData</cite> container with data for single outcome
or for multiple outcomes for batched multi-output case.</p></li>
<li><p><strong>**kwargs</strong> – None expected for this class.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression.HeteroskedasticSingleTaskGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression.</span></span><span class="sig-name descname"><span class="pre">HeteroskedasticSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#HeteroskedasticSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.SingleTaskGP</span></code></a></p>
<p>A single-task exact GP model using a heteroskeastic noise model.</p>
<p>This model internally wraps another GP (a SingleTaskGP) to model the
observation noise. This allows the likelihood to make out-of-sample
predictions for the observation noise levels.</p>
<p>A single-task exact GP model using a heteroskedastic noise model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).
Note that the noise model internally log-transforms the
variances, which will happen after this transform is applied.</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transfrom that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">se</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="n">se</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">HeteroskedasticSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.HeteroskedasticSingleTaskGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#HeteroskedasticSingleTaskGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>m</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>BatchedMultiOutputGPyTorchModel</cite> object of the same type with
<cite>n + n’</cite> training examples, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP" title="botorch.models.gp_regression.HeteroskedasticSingleTaskGP">botorch.models.gp_regression.HeteroskedasticSingleTaskGP</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression.HeteroskedasticSingleTaskGP.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#HeteroskedasticSingleTaskGP.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP" title="botorch.models.gp_regression.HeteroskedasticSingleTaskGP">botorch.models.gp_regression.HeteroskedasticSingleTaskGP</a></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.gp_regression_fidelity">
<span id="multi-fidelity-gp-regression-models"></span><h3>Multi-Fidelity GP Regression Models<a class="headerlink" href="#module-botorch.models.gp_regression_fidelity" title="Permalink to this headline">¶</a></h3>
<p>Gaussian Process Regression models based on GPyTorch models.</p>
<dl class="citation">
<dt class="label" id="wu2019mf"><span class="brackets">Wu2019mf</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>J. Wu, S. Toscano-Palmerin, P. I. Frazier, and A. G. Wilson. Practical
multi-fidelity bayesian optimization for hyperparameter tuning. ArXiv 2019.</p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression_fidelity.</span></span><span class="sig-name descname"><span class="pre">SingleTaskMultiFidelityGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_fidelity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_fidelity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_truncated</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#SingleTaskMultiFidelityGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.SingleTaskGP</span></code></a></p>
<p>A single task multi-fidelity GP model.</p>
<p>A SingleTaskGP model using a DownsamplingKernel for the data fidelity
parameter (if present) and an ExponentialDecayKernel for the iteration
fidelity parameter (if present).</p>
<p>This kernel is described in <a class="reference internal" href="#wu2019mf" id="id1"><span>[Wu2019mf]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x (d + s)</cite> tensor of training features,
where <cite>s</cite> is the dimension of the fidelity parameters (either one
or two).</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>iteration_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The column index for the training iteration fidelity
parameter (optional).</p></li>
<li><p><strong>data_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The column index for the downsampling fidelity parameter
(optional).</p></li>
<li><p><strong>linear_truncated</strong> (<em>bool</em>) – If True, use a <cite>LinearTruncatedFidelityKernel</cite> instead
of the default kernel.</p></li>
<li><p><strong>nu</strong> (<em>float</em>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2, or
5/2. Only used when <cite>linear_truncated=True</cite>.</p></li>
<li><p><strong>likelihood</strong> (<em>Optional</em><em>[</em><em>Likelihood</em><em>]</em>) – A likelihood. If omitted, use a standard GaussianLikelihood
with inferred noise level.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskMultiFidelityGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">data_fidelity</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>A single-task exact GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>likelihood</strong> (<em>Optional</em><em>[</em><em>Likelihood</em><em>]</em>) – A likelihood. If omitted, use a standard
GaussianLikelihood with inferred noise level.</p></li>
<li><p><strong>covar_module</strong> – The module computing the covariance (Kernel) matrix.
If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>iteration_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>data_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>linear_truncated</strong> (<em>bool</em>) – </p></li>
<li><p><strong>nu</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#SingleTaskMultiFidelityGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – <cite>TrainingData</cite> container with data for single outcome
or for multiple outcomes for batched multi-output case.</p></li>
<li><p><strong>**kwargs</strong> – Options, expected for this class:
- fidelity_features: List of columns of X that are fidelity parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression_fidelity.FixedNoiseMultiFidelityGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression_fidelity.</span></span><span class="sig-name descname"><span class="pre">FixedNoiseMultiFidelityGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_fidelity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_fidelity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linear_truncated</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#FixedNoiseMultiFidelityGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.FixedNoiseMultiFidelityGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.FixedNoiseGP" title="botorch.models.gp_regression.FixedNoiseGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.FixedNoiseGP</span></code></a></p>
<p>A single task multi-fidelity GP model using fixed noise levels.</p>
<p>A FixedNoiseGP model analogue to SingleTaskMultiFidelityGP, using a
DownsamplingKernel for the data fidelity parameter (if present) and
an ExponentialDecayKernel for the iteration fidelity parameter (if present).</p>
<p>This kernel is described in <a class="reference internal" href="#wu2019mf" id="id2"><span>[Wu2019mf]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x (d + s)</cite> tensor of training features,
where <cite>s</cite> is the dimension of the fidelity parameters (either one
or two).</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement noise.</p></li>
<li><p><strong>iteration_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The column index for the training iteration fidelity
parameter (optional).</p></li>
<li><p><strong>data_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The column index for the downsampling fidelity parameter
(optional).</p></li>
<li><p><strong>linear_truncated</strong> (<em>bool</em>) – If True, use a <cite>LinearTruncatedFidelityKernel</cite> instead
of the default kernel.</p></li>
<li><p><strong>nu</strong> (<em>float</em>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2, or
5/2. Only used when <cite>linear_truncated=True</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseMultiFidelityGP</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train_X</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train_Y</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train_Yvar</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">data_fidelity</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>A single-task exact GP model using fixed noise levels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transfrom that is applied in the model’s
forward pass.</p></li>
<li><p><strong>iteration_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>data_fidelity</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>linear_truncated</strong> (<em>bool</em>) – </p></li>
<li><p><strong>nu</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression_fidelity.FixedNoiseMultiFidelityGP.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#FixedNoiseMultiFidelityGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.FixedNoiseMultiFidelityGP.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – <cite>TrainingData</cite> container with data for single outcome
or for multiple outcomes for batched multi-output case.</p></li>
<li><p><strong>**kwargs</strong> – Options, expected for this class:
- fidelity_features: List of columns of X that are fidelity parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.gp_regression_mixed">
<span id="gp-regression-models-for-mixed-parameter-spaces"></span><h3>GP Regression Models for Mixed Parameter Spaces<a class="headerlink" href="#module-botorch.models.gp_regression_mixed" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.gp_regression_mixed.MixedSingleTaskGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.gp_regression_mixed.</span></span><span class="sig-name descname"><span class="pre">MixedSingleTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cont_kernel_factory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_mixed.html#MixedSingleTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_mixed.MixedSingleTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.SingleTaskGP</span></code></a></p>
<p>A single-task exact GP model for mixed search spaces.</p>
<p>This model uses a kernel that combines a CategoricalKernel (based on
Hamming distances) and a regular kernel into a kernel of the form</p>
<blockquote>
<div><dl class="simple">
<dt>K((x1, c1), (x2, c2)) =</dt><dd><p>K_cont_1(x1, x2) + K_cat_1(c1, c2) +
K_cont_2(x1, x2) * K_cat_2(c1, c2)</p>
</dd>
</dl>
</div></blockquote>
<p>where <cite>xi</cite> and <cite>ci</cite> are the continuous and categorical features of the
input, respectively. The suffix <cite>_i</cite> indicates that we fit different
lengthscales for the kernels in the sum and product terms.</p>
<p>Since this model does not provide gradients for the categorical features,
optimization of the acquisition function will need to be performed in
a mixed fashion, i.e., treating the categorical features properly as
discrete optimization variables.</p>
<p>A single-task exact GP model supporting categorical parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>cat_dims</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – A list of indices corresponding to the columns of
the input <cite>X</cite> that should be considered categorical features.</p></li>
<li><p><strong>cont_kernel_factory</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>int</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em><em>, </em><em>Kernel</em><em>]</em><em>]</em>) – A method that accepts <cite>ard_num_dims</cite> and
<cite>active_dims</cite> arguments and returns an instatiated GPyTorch
<cite>Kernel</cite> object to be used as the ase kernel for the continuous
dimensions. If omitted, this model uses a Matern-2.5 kernel as
the kernel for the ordinal parameters.</p></li>
<li><p><strong>likelihood</strong> (<em>Optional</em><em>[</em><em>Likelihood</em><em>]</em>) – A likelihood. If omitted, use a standard
GaussianLikelihood with inferred noise level.</p></li>
<li><p><strong>outcome_transform</strong> (<em>#</em>) – An outcome transform that is applied to the</p></li>
<li><p><strong>during</strong> (<em>#     training data during instantiation and to the posterior</em>) – </p></li>
<li><p><strong>is</strong> (<em>#     inference</em><em> (</em><em>that</em>) – </p></li>
<li><p><strong>calling</strong> (<em>the Posterior obtained by</em>) – </p></li>
<li><p><strong>scale</strong><strong>)</strong><strong></strong> (<em>#     .posterior on the model will be on the original</em>) – </p></li>
<li><p><strong>input_transform</strong> (<em>#</em>) – An input transform that is applied in the model’s</p></li>
<li><p><strong>pass.</strong> (<em>#     forward</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
<span class="go">        [torch.rand(20, 2), torch.randint(3, (20, 1))], dim=-1)</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="p">(</span>
<span class="go">        torch.sin(train_X[..., :-1]).sum(dim=1, keepdim=True)</span>
<span class="go">        + train_X[..., -1:]</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MixedSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">cat_dims</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.gp_regression_mixed.MixedSingleTaskGP.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_mixed.html#MixedSingleTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.gp_regression_mixed.MixedSingleTaskGP.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – <cite>TrainingData</cite> container with data for single outcome
or for multiple outcomes for batched multi-output case.</p></li>
<li><p><strong>**kwargs</strong> – None expected for this class.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.model_list_gp_regression">
<span id="model-list-gp-regression-models"></span><h3>Model List GP Regression Models<a class="headerlink" href="#module-botorch.models.model_list_gp_regression" title="Permalink to this headline">¶</a></h3>
<p>Model List GP Regression models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.model_list_gp_regression.ModelListGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.model_list_gp_regression.</span></span><span class="sig-name descname"><span class="pre">ModelListGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">gp_models</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.model_list.IndependentModelList</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="botorch.models.gpytorch.ModelListGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.ModelListGPyTorchModel</span></code></a></p>
<p>A multi-output GP model with independent GPs for the outputs.</p>
<p>This model supports different-shaped training inputs for each of its
sub-models. It can be used with any BoTorch models.</p>
<p>Internally, this model is just a list of individual models, but it implements
the same input/output interface as all other BoTorch models. This makes it
very flexible and convenient to work with. The sequential evaluation comes
at a performance cost though - if you are using a block design (i.e. the
same number of training example for each output, and a similar model
structure, you should consider using a batched GP model instead).</p>
<p>A multi-output GP model with independent GPs for the outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*gp_models</strong> – An variable number of single-output BoTorch models.
If models have input/output transforms, these are honored
individually for each model.</p></li>
<li><p><strong>gp_models</strong> (<a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><em>GPyTorchModel</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model1</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X1</span><span class="p">,</span> <span class="n">train_Y1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model2</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X2</span><span class="p">,</span> <span class="n">train_Y2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelListGP</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model_list_gp_regression.ModelListGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>ModelListGPyTorchModel</cite> representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs). Here the <cite>i</cite>-th model has
<cite>n_i + n’</cite> training examples, where the <cite>n’</cite> training examples have
been added and all test-time caches have been updated.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP">botorch.models.model_list_gp_regression.ModelListGP</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.model_list_gp_regression.ModelListGP.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current model, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP">botorch.models.model_list_gp_regression.ModelListGP</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.model_list_gp_regression.ModelListGP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.multitask">
<span id="multitask-gp-models"></span><h3>Multitask GP Models<a class="headerlink" href="#module-botorch.models.multitask" title="Permalink to this headline">¶</a></h3>
<p>Multi-Task GP models.</p>
<p>References</p>
<dl class="citation">
<dt class="label" id="doucet2010sampl"><span class="brackets"><a class="fn-backref" href="#id4">Doucet2010sampl</a></span></dt>
<dd><p>A. Doucet. A Note on Efficient Conditional Simulation of Gaussian Distributions.
<a class="reference external" href="http://www.stats.ox.ac.uk/~doucet/doucet_simulationconditionalgaussian.pdf">http://www.stats.ox.ac.uk/~doucet/doucet_simulationconditionalgaussian.pdf</a>,
Apr 2010.</p>
</dd>
<dt class="label" id="maddox2021bohdo"><span class="brackets"><a class="fn-backref" href="#id5">Maddox2021bohdo</a></span></dt>
<dd><p>W. Maddox, M. Balandat, A. Wilson, and E. Bakshy. Bayesian Optimization with
High-Dimensional Outputs. <a class="reference external" href="https://botorch.org">https://botorch.org</a>, Jun 2021.</p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.multitask.</span></span><span class="sig-name descname"><span class="pre">MultiTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_covar_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel" title="botorch.models.gpytorch.MultiTaskGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.MultiTaskGPyTorchModel</span></code></a></p>
<p>Multi-Task GP model using an ICM kernel, inferring observation noise.</p>
<p>Multi-task exact GP that uses a simple ICM kernel. Can be single-output or
multi-output. This model uses relatively strong priors on the base Kernel
hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance).</p>
<p>This model infers the noise level. WARNING: It currently does not support
different noise levels for the different tasks. If you have known observation
noise, please use <cite>FixedNoiseMultiTaskGP</cite> instead.</p>
<p>Multi-Task GP model using an ICM kernel, inferring observation noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>n x (d + 1)</cite> or <cite>b x n x (d + 1)</cite> (batch mode) tensor
of training data. One of the columns should contain the task
features (see <cite>task_feature</cite> argument).</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of training observations.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – The index of the task feature (<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>output_tasks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The rank to be used for the index kernel. If omitted, use a
full rank (i.e. number of tasks) kernel.</p></li>
<li><p><strong>task_covar_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – A Prior on the task covariance matrix. Must operate
on p.s.d. matrices. A common prior for this is the <cite>LKJ</cite> prior.</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">task_feature</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>gpytorch.distributions.multivariate_normal.MultivariateNormal</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP.get_all_tasks">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">get_all_tasks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP.get_all_tasks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.get_all_tasks" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – </p></li>
<li><p><strong>output_tasks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tuple[List[int], int, int]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – <cite>TrainingData</cite> container with data for single outcome
or for multiple outcomes for batched multi-output case.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional options for the model that pertain to the
training data, including:</p>
<ul>
<li><p><cite>task_features</cite>: Indices of the input columns containing the task
features (expected list of length 1),</p></li>
<li><p><cite>task_covar_prior</cite>: A GPyTorch <cite>Prior</cite> object to use as prior on
the cross-task covariance matrix,</p></li>
<li><p><cite>prior_config</cite>: A dict representing a prior config, should only be
used if <cite>prior</cite> is not passed directly. Should contain:
<cite>use_LKJ_prior</cite> (whether to use LKJ prior) and <cite>eta</cite> (eta value,
float),</p></li>
<li><p><cite>rank</cite>: The rank of the cross-task covariance matrix.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.multitask.MultiTaskGP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.multitask.FixedNoiseMultiTaskGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.multitask.</span></span><span class="sig-name descname"><span class="pre">FixedNoiseMultiTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_covar_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#FixedNoiseMultiTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.FixedNoiseMultiTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.multitask.MultiTaskGP" title="botorch.models.multitask.MultiTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.multitask.MultiTaskGP</span></code></a></p>
<p>Multi-Task GP model using an ICM kernel, with known observation noise.</p>
<p>Multi-task exact GP that uses a simple ICM kernel. Can be single-output or
multi-output. This model uses relatively strong priors on the base Kernel
hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance).</p>
<p>This model requires observation noise data (specified in <cite>train_Yvar</cite>).</p>
<p>Multi-Task GP model using an ICM kernel and known observation noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>n x (d + 1)</cite> or <cite>b x n x (d + 1)</cite> (batch mode) tensor
of training data. One of the columns should contain the task
features (see <cite>task_feature</cite> argument).</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of training
observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Tensor</em>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of observation
noise standard errors.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – The index of the task feature (<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>task_covar_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – A Prior on the task covariance matrix. Must operate
on p.s.d. matrices. A common prior for this is the <cite>LKJ</cite> prior.</p></li>
<li><p><strong>output_tasks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The rank to be used for the index kernel. If omitted, use a
full rank (i.e. number of tasks) kernel.</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseMultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.FixedNoiseMultiTaskGP.construct_inputs">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">construct_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#FixedNoiseMultiTaskGP.construct_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.FixedNoiseMultiTaskGP.construct_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct kwargs for the <cite>Model</cite> from <cite>TrainingData</cite> and other options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> (<a class="reference internal" href="utils.html#botorch.utils.containers.TrainingData" title="botorch.utils.containers.TrainingData"><em>botorch.utils.containers.TrainingData</em></a>) – <cite>TrainingData</cite> container with data for single outcome
or for multiple outcomes for batched multi-output case.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional options for the model that pertain to the
training data, including:</p>
<ul>
<li><p><cite>task_features</cite>: Indices of the input columns containing the task
features (expected list of length 1),</p></li>
<li><p><cite>task_covar_prior</cite>: A GPyTorch <cite>Prior</cite> object to use as prior on
the cross-task covariance matrix,</p></li>
<li><p><cite>prior_config</cite>: A dict representing a prior config, should only be
used if <cite>prior</cite> is not passed directly. Should contain:
use_LKJ_prior` (whether to use LKJ prior) and <cite>eta</cite> (eta value,
float),</p></li>
<li><p><cite>rank</cite>: The rank of the cross-task covariance matrix.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict[str, Any]</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.multitask.FixedNoiseMultiTaskGP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.multitask.FixedNoiseMultiTaskGP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.multitask.</span></span><span class="sig-name descname"><span class="pre">KroneckerMultiTaskGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_covar_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.GPyTorchModel</span></code></a></p>
<p>Multi-task GP with Kronecker structure, using an ICM kernel.</p>
<p>This model assumes the “block design” case, i.e., it requires that all tasks
are observed at all data points.</p>
<p>For posterior sampling, this model uses Matheron’s rule [Doucet2010sampl] to compute
the posterior over all tasks as in [Maddox2021bohdo] by exploiting Kronecker
structure.</p>
<p>Multi-task GP with Kronecker structure, using a simple ICM kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>likelihood</strong> (<em>Optional</em><em>[</em><em>MultitaskGaussianLikelihood</em><em>]</em>) – A <cite>MultitaskGaussianLikelihood</cite>. If omitted, uses a
<cite>MultitaskGaussianLikelihood</cite> with a <cite>GammaPrior(1.1, 0.05)</cite>
noise prior.</p></li>
<li><p><strong>task_covar_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – A Prior on the task covariance matrix. Must operate
on p.s.d. matrices. A common prior for this is the <cite>LKJ</cite> prior. If
omitted, uses <cite>LKJCovariancePrior</cite> with <cite>eta</cite> parameter as specified
in the keyword arguments (if not specified, use <cite>eta=1.5</cite>).</p></li>
<li><p><strong>rank</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The rank of the ICM kernel. If omitted, use a full rank kernel.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additional arguments to override default settings of priors,
including:
- eta: The eta parameter on the default LKJ task_covar_prior.
A value of 1.0 is uninformative, values &lt;1.0 favor stronger
correlations (in magnitude), correlations vanish as eta -&gt; inf.
- sd_prior: A scalar prior over nonnegative numbers, which is used
for the default LKJCovariancePrior task_covar_prior.
- likelihood_rank: The rank of the task covariance matrix to fit.
Defaults to 0 (which corresponds to a diagonal covariance matrix).</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – </p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">f_1</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">f_2</span><span class="p">(</span><span class="n">X</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">KroneckerMultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>gpytorch.distributions.multitask_multivariate_normal.MultitaskMultivariateNormal</p>
</dd>
</dl>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.train_full_covar">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">train_full_covar</span></span><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.train_full_covar" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.predictive_mean_cache">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">predictive_mean_cache</span></span><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.predictive_mean_cache" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>observation_noise</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>torch.Tensor</em><em>]</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q</cite>).</p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing a batch of <cite>b</cite> joint
distributions over <cite>q</cite> points. Includes observation noise if
specified.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.multitask.MultitaskGPPosterior" title="botorch.posteriors.multitask.MultitaskGPPosterior">botorch.posteriors.multitask.MultitaskGPPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#KroneckerMultiTaskGP.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.multitask.KroneckerMultiTaskGP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.multitask.KroneckerMultiTaskGP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.higher_order_gp">
<span id="higher-order-gp-models"></span><h3>Higher Order GP Models<a class="headerlink" href="#module-botorch.models.higher_order_gp" title="Permalink to this headline">¶</a></h3>
<p>References</p>
<dl class="citation">
<dt class="label" id="zhe2019hogp"><span class="brackets"><a class="fn-backref" href="#id3">Zhe2019hogp</a></span></dt>
<dd><p>S. Zhe, W. Xing, and R. M. Kirby. Scalable high-order gaussian process regression.
Proceedings of Machine Learning Research, volume 89, Apr 2019.</p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.higher_order_gp.</span></span><span class="sig-name descname"><span class="pre">FlattenedStandardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.Standardize" title="botorch.models.transforms.outcome.Standardize"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.Standardize</span></code></a></p>
<p>Standardize outcomes in a structured multi-output settings by reshaping the
batched output dimensions to be a vector. Specifically, an output dimension
of [a x b x c] will be squeezed to be a vector of [a * b * c].</p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> – The output dimension.</p></li>
<li><p><strong>outputs</strong> – Which of the outputs to standardize. If omitted, all
outputs will be standardized.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch_shape of the training targets.</p></li>
<li><p><strong>min_stddv</strong> – The minimum standard deviation for which to perform
standardization (if lower, only de-mean the data).</p></li>
<li><p><strong>output_shape</strong> (<em>torch.Size</em>) – </p></li>
<li><p><strong>min_stdv</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-standardize outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized observation
noises associated with the targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-standardized outcome observations.</p></li>
<li><p>The un-standardized observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-standardized outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#FlattenedStandardize.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-standardize the posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.higher_order.HigherOrderGPPosterior" title="botorch.posteriors.higher_order.HigherOrderGPPosterior"><em>botorch.posteriors.higher_order.HigherOrderGPPosterior</em></a>) – A posterior in the standardized space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The un-standardized posterior. If the input posterior is a MVN,
the transformed posterior is again an MVN.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.transformed.TransformedPosterior" title="botorch.posteriors.transformed.TransformedPosterior">botorch.posteriors.transformed.TransformedPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.FlattenedStandardize.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.higher_order_gp.FlattenedStandardize.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.higher_order_gp.</span></span><span class="sig-name descname"><span class="pre">HigherOrderGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_modules</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_latent_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_latent_pars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code></p>
<p>A Higher order Gaussian process model (HOGP) (predictions are matrices/tensors) as
described in <a class="reference internal" href="#zhe2019hogp" id="id3"><span>[Zhe2019hogp]</span></a>. The posterior uses Matheron’s rule <a class="reference internal" href="#doucet2010sampl" id="id4"><span>[Doucet2010sampl]</span></a>
as described in <a class="reference internal" href="#maddox2021bohdo" id="id5"><span>[Maddox2021bohdo]</span></a>.</p>
<p>A HigherOrderGP model for high-dim output regression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of training inputs.</p></li>
<li><p><strong>train_Y</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x output_shape</cite>-dim tensor of training targets.</p></li>
<li><p><strong>likelihood</strong> (<em>Optional</em><em>[</em><em>Likelihood</em><em>]</em>) – Gaussian likelihood for the model.</p></li>
<li><p><strong>covar_modules</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Kernel</em><em>]</em><em>]</em>) – List of kernels for each output structure.</p></li>
<li><p><strong>num_latent_dims</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Sizes for the latent dimensions.</p></li>
<li><p><strong>learn_latent_pars</strong> (<em>bool</em>) – If true, learn the latent parameters.</p></li>
<li><p><strong>latent_init</strong> (<em>str</em>) – [default or gp] how to initialize the latent parameters.</p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a><em>]</em>) – </p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>gpytorch.distributions.multivariate_normal.MultivariateNormal</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.get_fantasy_model">
<span class="sig-name descname"><span class="pre">get_fantasy_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.get_fantasy_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.get_fantasy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new GP model that incorporates the specified inputs and targets as new training data.</p>
<p>Using this method is more efficient than updating with <cite>set_train_data</cite> when the number of inputs is relatively
small, because any computed test-time caches will be updated in linear time rather than computed from scratch.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <cite>targets</cite> is a batch (e.g. <cite>b x m</cite>), then the GP returned from this method will be a batch mode GP.
If <cite>inputs</cite> is of the same (or lesser) dimension as <cite>targets</cite>, then it is assumed that the fantasy points
are the same for each target batch.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>torch.Tensor</em>) – (<cite>b1 x … x bk x m x d</cite> or <cite>f x b1 x … x bk x m x d</cite>) Locations of fantasy
observations.</p></li>
<li><p><strong>targets</strong> (<em>torch.Tensor</em>) – (<cite>b1 x … x bk x m</cite> or <cite>f x b1 x … x bk x m</cite>) Labels of fantasy observations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An <cite>ExactGP</cite> model with <cite>n + m</cite> training examples, where the <cite>m</cite> fantasy examples have been added
and all test-time caches have been updated.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ExactGP</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>m</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape’ x n’ x m_d</cite>-dim Tensor, where <cite>m_d</cite> is the shaping
of the model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>BatchedMultiOutputGPyTorchModel</cite> object of the same type with
<cite>n + n’</cite> training examples, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.higher_order_gp.HigherOrderGP" title="botorch.models.higher_order_gp.HigherOrderGP">botorch.models.higher_order_gp.HigherOrderGP</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<em>Union</em><em>[</em><em>bool</em><em>, </em><em>torch.Tensor</em><em>]</em>) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q x m</cite>).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes observation noise if specified.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior">botorch.posteriors.gpytorch.GPyTorchPosterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.higher_order_gp.HigherOrderGP.make_posterior_variances">
<span class="sig-name descname"><span class="pre">make_posterior_variances</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">joint_covariance_matrix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/higher_order_gp.html#HigherOrderGP.make_posterior_variances"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.higher_order_gp.HigherOrderGP.make_posterior_variances" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior variances given the data points X. As currently
implemented, it computes another forwards call with the stacked data to get out
the joint covariance across all data points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>joint_covariance_matrix</strong> (<em>gpytorch.lazy.lazy_tensor.LazyTensor</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.pairwise_gp">
<span id="pairwise-gp-models"></span><h3>Pairwise GP Models<a class="headerlink" href="#module-botorch.models.pairwise_gp" title="Permalink to this headline">¶</a></h3>
<p>Preference Learning with Gaussian Process</p>
<dl class="citation">
<dt class="label" id="chu2005preference"><span class="brackets">Chu2005preference</span><span class="fn-backref">(<a href="#id6">1</a>,<a href="#id8">2</a>,<a href="#id9">3</a>)</span></dt>
<dd><p>Wei Chu, and Zoubin Ghahramani. Preference learning with Gaussian processes.
Proceedings of the 22nd international conference on Machine learning. 2005.</p>
</dd>
<dt class="label" id="brochu2010tutorial"><span class="brackets"><a class="fn-backref" href="#id7">Brochu2010tutorial</a></span></dt>
<dd><p>Eric Brochu, Vlad M. Cora, and Nando De Freitas.
A tutorial on Bayesian optimization of expensive cost functions,
with application to active user modeling and hierarchical reinforcement learning.
arXiv preprint arXiv:1012.2599 (2010).</p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.pairwise_gp.</span></span><span class="sig-name descname"><span class="pre">PairwiseGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datapoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comparisons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.model.Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.gp.GP</span></code></p>
<p>Probit GP for preference learning with Laplace approximation</p>
<p>Implementation is based on <a class="reference internal" href="#chu2005preference" id="id6"><span>[Chu2005preference]</span></a>.
Also see <a class="reference internal" href="#brochu2010tutorial" id="id7"><span>[Brochu2010tutorial]</span></a> for additional reference.</p>
<p>Note that in <a class="reference internal" href="#chu2005preference" id="id8"><span>[Chu2005preference]</span></a> the likelihood of a pairwise comparison
is <span class="math notranslate nohighlight">\(\left(\frac{f(x_1) - f(x_2)}{\sqrt{2}\sigma}\right)\)</span>, i.e. a scale is
used in the denominator. To maintain consistency with usage of kernels
elsewhere in botorch, we instead do not include <span class="math notranslate nohighlight">\(\sigma\)</span> in the code
(implicitly setting it to 1) and use ScaleKernel to scale the function.</p>
<dl class="simple">
<dt>A probit-likelihood GP with Laplace approximation model that learns via</dt><dd><p>pairwise comparison data. By default it uses a scaled RBF kernel.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datapoints</strong> (<em>Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>comparisons</strong> (<em>Tensor</em>) – A <cite>batch_shape x m x 2</cite> training comparisons;
comparisons[i] is a noisy indicator suggesting the utility value
of comparisons[i, 0]-th is greater than comparisons[i, 1]-th.</p></li>
<li><p><strong>covar_module</strong> (<em>Optional</em><em>[</em><em>Module</em><em>]</em>) – Covariance module.</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.num_outputs">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">num_outputs</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of outputs of the model.</p>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.batch_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">batch_shape</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Size</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The batch shape of the model.</p>
<p>This is a batch shape from an I/O perspective, independent of the internal
representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).
For a model with <cite>m</cite> outputs, a <cite>test_batch_shape x q x d</cite>-shaped input <cite>X</cite>
to the <cite>posterior</cite> method returns a Posterior object over an output of
shape <cite>broadcast(test_batch_shape, model.batch_shape) x q x m</cite>.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.set_train_data">
<span class="sig-name descname"><span class="pre">set_train_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datapoints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comparisons</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.set_train_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.set_train_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Set datapoints and comparisons and update model properties if needed</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>datapoints</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x d</cite> dimension tensor X. If there are input
transformations, assume the datapoints are not transformed</p></li>
<li><p><strong>comparisons</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A tensor of size <cite>batch_shape x m x 2</cite>. (i, j) means
f_i is preferred over f_j.</p></li>
<li><p><strong>strict</strong> (<em>bool</em>) – <cite>strict</cite> argument as in gpytorch.models.exact_gp for compatibility
when using fit_gpytorch_model with input_transform.</p></li>
<li><p><strong>update_model</strong> (<em>bool</em>) – True if we want to refit the model (see _update) after
re-setting the data.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datapoints</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate a posterior or prior prediction.</p>
<p>During training mode, forward implemented solely for gradient-based
hyperparam opt. Essentially what it does is to re-calculate the utility
f using its analytical form at f_map so that we are able to obtain
gradients of the hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>datapoints</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite> Tensor,
should be the same as self.datapoints during training</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ol class="arabic simple">
<li><p>Posterior centered at MAP points for training data (training mode)</p></li>
<li><p>Prior predictions (prior mode)</p></li>
<li><p>Predictive posterior (eval mode)</p></li>
</ol>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A MultivariateNormal object, being one of the followings</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered jointly.</p></li>
<li><p><strong>output_indices</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – As defined in parent Model class, not used for this model.</p></li>
<li><p><strong>observation_noise</strong> (<em>bool</em>) – Ignored (since noise is not identifiable from scale
in probit models).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <cite>Posterior</cite> object, representing joint</dt><dd><p>distributions over <cite>q</cite> points.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">botorch.posteriors.posterior.Posterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.condition_on_observations">
<span class="sig-name descname"><span class="pre">condition_on_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseGP.condition_on_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<p>Note that unlike other BoTorch models, PairwiseGP requires Y to be
pairwise comparisons</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite> dimension tensor X</p></li>
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A tensor of size <cite>batch_shape x m x 2</cite>. (i, j) means
f_i is preferred over f_j</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A (deepcopied) <cite>Model</cite> object of the same type, representing the
original model conditioned on the new observations <cite>(X, Y)</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model">botorch.models.model.Model</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseGP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseGP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.pairwise_gp.</span></span><span class="sig-name descname"><span class="pre">PairwiseLaplaceMarginalLogLikelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseLaplaceMarginalLogLikelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.mlls.marginal_log_likelihood.MarginalLogLikelihood</span></code></p>
<p>Laplace-approximated marginal log likelihood/evidence for PairwiseGP</p>
<p>See (12) from <a class="reference internal" href="#chu2005preference" id="id9"><span>[Chu2005preference]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="#botorch.models.pairwise_gp.PairwiseGP" title="botorch.models.pairwise_gp.PairwiseGP"><em>PairwiseGP</em></a>) – A model using laplace approximation (currently only supports
<cite>PairwiseGP</cite>)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">post</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comp</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/pairwise_gp.html#PairwiseLaplaceMarginalLogLikelihood.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate approximated log evidence, i.e., log(P(D|theta))</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>post</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>botorch.posteriors.posterior.Posterior</em></a>) – training posterior distribution from self.model</p></li>
<li><p><strong>comp</strong> (<em>torch.Tensor</em>) – Comparisons pairs, see PairwiseGP.__init__ for more details</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The approximated evidence, i.e., the marginal log likelihood</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.pairwise_gp.PairwiseLaplaceMarginalLogLikelihood.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.contextual">
<span id="contextual-gp-models-with-aggregate-rewards"></span><h3>Contextual GP Models with Aggregate Rewards<a class="headerlink" href="#module-botorch.models.contextual" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.contextual.SACGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.contextual.</span></span><span class="sig-name descname"><span class="pre">SACGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual.html#SACGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual.SACGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.FixedNoiseGP" title="botorch.models.gp_regression.FixedNoiseGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.FixedNoiseGP</span></code></a></p>
<p>The GP uses Structural Additive Contextual(SAC) kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – (n x 1) Y training data.</p></li>
<li><p><strong>train_Yvar</strong> (<em>torch.Tensor</em>) – (n x 1) Noise variances of each training Y.</p></li>
<li><p><strong>decomposition</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys are context names. Values are the indexes of
parameters belong to the context. The parameter indexes are in
the same order across contexts.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>A single-task exact GP model using fixed noise levels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> – An input transfrom that is applied in the model’s
forward pass.</p></li>
<li><p><strong>decomposition</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.contextual.LCEAGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.contextual.</span></span><span class="sig-name descname"><span class="pre">LCEAGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_weight_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual.html#LCEAGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual.LCEAGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.FixedNoiseGP" title="botorch.models.gp_regression.FixedNoiseGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.FixedNoiseGP</span></code></a></p>
<p>The GP with Latent Context Embedding Additive (LCE-A) Kernel.
Note that the model does not support batch training. Input training
data sets should have dim = 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – (n x 1) Y training data.</p></li>
<li><p><strong>train_Yvar</strong> (<em>torch.Tensor</em>) – (n x 1) Noise variance of Y.</p></li>
<li><p><strong>decomposition</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys are context names. Values are the indexes of
parameters belong to the context. The parameter indexes are in the
same order across contexts.</p></li>
<li><p><strong>cat_feature_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – Keys are context names and values are list of categorical
features i.e. {“context_name” : [cat_0, …, cat_k]}. k equals to number
of categorical variables. If None, we use context names in the
decomposition as the only categorical feature i.e. k = 1</p></li>
<li><p><strong>embs_feature_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – Pre-trained continuous embedding features of each context.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Embedding dimension for each categorical variable. The length
equals to num of categorical features k. If None, emb dim is set to 1
for each categorical variable.</p></li>
<li><p><strong>context_weight_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – Known population Weights of each context.</p></li>
<li><p><strong>train_embedding</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>A single-task exact GP model using fixed noise levels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
<li><p><strong>input_transform</strong> – An input transfrom that is applied in the model’s
forward pass.</p></li>
<li><p><strong>decomposition</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>train_embedding</strong> (<em>bool</em>) – </p></li>
<li><p><strong>cat_feature_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – </p></li>
<li><p><strong>embs_feature_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – </p></li>
<li><p><strong>embs_dim_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>context_weight_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</section>
<section id="module-botorch.models.contextual_multioutput">
<span id="contextual-gp-models-with-context-rewards"></span><h3>Contextual GP Models with Context Rewards<a class="headerlink" href="#module-botorch.models.contextual_multioutput" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.LCEMGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.contextual_multioutput.</span></span><span class="sig-name descname"><span class="pre">LCEMGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_cat_feature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_emb_feature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outcome_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual_multioutput.html#LCEMGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual_multioutput.LCEMGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.multitask.MultiTaskGP" title="botorch.models.multitask.MultiTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.multitask.MultiTaskGP</span></code></a></p>
<p>The Multi-Task GP with the latent context embedding multioutput
(LCE-M) kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – (n x 1) Y training data.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – column index of train_X to get context indices.</p></li>
<li><p><strong>context_cat_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – (n_contexts x k) one-hot encoded context
features. Rows are ordered by context indices. k equals to
number of categorical variables. If None, task indices will
be used and k = 1</p></li>
<li><p><strong>context_emb_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – (n_contexts x m) pre-given continuous
embedding features. Rows are ordered by context indices.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Embedding dimension for each categorical variable.
The length equals to k. If None, emb dim is set to 1 for each
categorical variable.</p></li>
<li><p><strong>output_tasks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>botorch.models.transforms.input.InputTransform</em></a><em>]</em>) – </p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>botorch.models.transforms.outcome.OutcomeTransform</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Multi-Task GP model using an ICM kernel, inferring observation noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – A <cite>n x (d + 1)</cite> or <cite>b x n x (d + 1)</cite> (batch mode) tensor
of training data. One of the columns should contain the task
features (see <cite>task_feature</cite> argument).</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of training observations.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – The index of the task feature (<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>output_tasks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> – The rank to be used for the index kernel. If omitted, use a
full rank (i.e. number of tasks) kernel.</p></li>
<li><p><strong>task_covar_prior</strong> – A Prior on the task covariance matrix. Must operate
on p.s.d. matrices. A common prior for this is the <cite>LKJ</cite> prior.</p></li>
<li><p><strong>input_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>botorch.models.transforms.input.InputTransform</em></a><em>]</em>) – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>context_cat_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – </p></li>
<li><p><strong>context_emb_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – </p></li>
<li><p><strong>embs_dim_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>outcome_transform</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>botorch.models.transforms.outcome.OutcomeTransform</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">task_feature</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.LCEMGP.task_covar_matrix">
<span class="sig-name descname"><span class="pre">task_covar_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task_idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual_multioutput.html#LCEMGP.task_covar_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual_multioutput.LCEMGP.task_covar_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>compute covariance matrix of a list of given context</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>task_idcs</strong> (<em>torch.Tensor</em>) – (n x 1) or (b x n x 1) task indices tensor</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.LCEMGP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual_multioutput.html#LCEMGP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual_multioutput.LCEMGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>gpytorch.distributions.multivariate_normal.MultivariateNormal</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.LCEMGP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.contextual_multioutput.LCEMGP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.FixedNoiseLCEMGP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.contextual_multioutput.</span></span><span class="sig-name descname"><span class="pre">FixedNoiseLCEMGP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_cat_feature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_emb_feature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tasks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/contextual_multioutput.html#FixedNoiseLCEMGP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.contextual_multioutput.FixedNoiseLCEMGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.contextual_multioutput.LCEMGP" title="botorch.models.contextual_multioutput.LCEMGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.contextual_multioutput.LCEMGP</span></code></a></p>
<p>The Multi-Task GP the latent context embedding multioutput
(LCE-M) kernel, with known observation noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – (n x 1) Y training data.</p></li>
<li><p><strong>train_Yvar</strong> (<em>torch.Tensor</em>) – (n x 1) Noise variances of each training Y.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – column index of train_X to get context indices.</p></li>
<li><p><strong>context_cat_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – (n_contexts x k) one-hot encoded context
features. Rows are ordered by context indices. k equals to
number of categorical variables. If None, task indices will
be used and k = 1.</p></li>
<li><p><strong>context_emb_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – (n_contexts x m) pre-given continuous
embedding features. Rows are ordered by context indices.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Embedding dimension for each categorical variable.
The length equals to k. If None, emb dim is set to 1 for each
categorical variable.</p></li>
<li><p><strong>output_tasks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Multi-Task GP model using an ICM kernel, inferring observation noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – A <cite>n x (d + 1)</cite> or <cite>b x n x (d + 1)</cite> (batch mode) tensor
of training data. One of the columns should contain the task
features (see <cite>task_feature</cite> argument).</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of training observations.</p></li>
<li><p><strong>task_feature</strong> (<em>int</em>) – The index of the task feature (<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>output_tasks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> – The rank to be used for the index kernel. If omitted, use a
full rank (i.e. number of tasks) kernel.</p></li>
<li><p><strong>task_covar_prior</strong> – A Prior on the task covariance matrix. Must operate
on p.s.d. matrices. A common prior for this is the <cite>LKJ</cite> prior.</p></li>
<li><p><strong>input_transform</strong> – An input transform that is applied in the model’s
forward pass.</p></li>
<li><p><strong>train_Yvar</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>context_cat_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – </p></li>
<li><p><strong>context_emb_feature</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – </p></li>
<li><p><strong>embs_dim_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">task_feature</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.contextual_multioutput.FixedNoiseLCEMGP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.contextual_multioutput.FixedNoiseLCEMGP.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
</section>
<section id="model-components">
<h2>Model Components<a class="headerlink" href="#model-components" title="Permalink to this headline">¶</a></h2>
<section id="module-botorch.models.kernels.categorical">
<span id="kernels"></span><h3>Kernels<a class="headerlink" href="#module-botorch.models.kernels.categorical" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.kernels.categorical.CategoricalKernel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.categorical.</span></span><span class="sig-name descname"><span class="pre">CategoricalKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ard_num_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/categorical.html#CategoricalKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.categorical.CategoricalKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>A Kernel for categorical features.</p>
<p>Computes <cite>exp(-(dist(x1, x2) / lengthscale)**2)</cite>, where
<cite>dist(x1, x2)</cite> is zero if <cite>x1 == x2</cite> and one if <cite>x1 != x2</cite>.</p>
<p>Note: This kernel is NOT differentiable w.r.t. the inputs.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
<span class="target" id="module-botorch.models.kernels.downsampling"></span><dl class="py class">
<dt class="sig sig-object py" id="botorch.models.kernels.downsampling.DownsamplingKernel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.downsampling.</span></span><span class="sig-name descname"><span class="pre">DownsamplingKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">power_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/downsampling.html#DownsamplingKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.downsampling.DownsamplingKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>GPyTorch Downsampling Kernel.</p>
<p>Computes a covariance matrix based on the down sampling kernel between
inputs <cite>x_1</cite> and <cite>x_2</cite> (we expect <cite>d = 1</cite>):</p>
<blockquote>
<div><dl class="simple">
<dt>K(mathbf{x_1}, mathbf{x_2}) = c + (1 - x_1)^(1 + delta) *</dt><dd><p>(1 - x_2)^(1 + delta).</p>
</dd>
</dl>
</div></blockquote>
<p>where <cite>c</cite> is an offset parameter, and <cite>delta</cite> is a power parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>power_constraint</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>) – Constraint to place on power parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>power_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – Prior over the power parameter.</p></li>
<li><p><strong>offset_constraint</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>) – Constraint to place on offset parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>active_dims</strong> – List of data dimensions to operate on. <cite>len(active_dims)</cite>
should equal <cite>num_dimensions</cite>.</p></li>
<li><p><strong>offset_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
<span class="target" id="module-botorch.models.kernels.exponential_decay"></span><dl class="py class">
<dt class="sig sig-object py" id="botorch.models.kernels.exponential_decay.ExponentialDecayKernel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.exponential_decay.</span></span><span class="sig-name descname"><span class="pre">ExponentialDecayKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">power_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/exponential_decay.html#ExponentialDecayKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.exponential_decay.ExponentialDecayKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>GPyTorch Exponential Decay Kernel.</p>
<p>Computes a covariance matrix based on the exponential decay kernel
between inputs <cite>x_1</cite> and <cite>x_2</cite> (we expect <cite>d = 1</cite>):</p>
<blockquote>
<div><p>K(x_1, x_2) = w + beta^alpha / (x_1 + x_2 + beta)^alpha.</p>
</div></blockquote>
<p>where <cite>w</cite> is an offset parameter, <cite>beta</cite> is a lenthscale parameter, and
<cite>alpha</cite> is a power parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lengthscale_constraint</strong> – Constraint to place on lengthscale parameter.
Default is <cite>Positive</cite>.</p></li>
<li><p><strong>lengthscale_prior</strong> – Prior over the lengthscale parameter.</p></li>
<li><p><strong>power_constraint</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>) – Constraint to place on power parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>power_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – Prior over the power parameter.</p></li>
<li><p><strong>offset_constraint</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>) – Constraint to place on offset parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>active_dims</strong> – List of data dimensions to operate on. <cite>len(active_dims)</cite>
should equal <cite>num_dimensions</cite>.</p></li>
<li><p><strong>offset_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
<span class="target" id="module-botorch.models.kernels.linear_truncated_fidelity"></span><dl class="py class">
<dt class="sig sig-object py" id="botorch.models.kernels.linear_truncated_fidelity.LinearTruncatedFidelityKernel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.linear_truncated_fidelity.</span></span><span class="sig-name descname"><span class="pre">LinearTruncatedFidelityKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fidelity_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power_constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_prior_unbiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_prior_biased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_constraint_unbiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengthscale_constraint_biased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module_unbiased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar_module_biased</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/linear_truncated_fidelity.html#LinearTruncatedFidelityKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.linear_truncated_fidelity.LinearTruncatedFidelityKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>GPyTorch Linear Truncated Fidelity Kernel.</p>
<p>Computes a covariance matrix based on the Linear truncated kernel between
inputs <cite>x_1</cite> and <cite>x_2</cite> for up to two fidelity parmeters:</p>
<blockquote>
<div><p>K(x_1, x_2) = k_0 + c_1(x_1, x_2)k_1 + c_2(x_1,x_2)k_2 + c_3(x_1,x_2)k_3</p>
</div></blockquote>
<p>where</p>
<ul class="simple">
<li><dl class="simple">
<dt><cite>k_i(i=0,1,2,3)</cite> are Matern kernels calculated between non-fidelity</dt><dd><p>parameters of <cite>x_1</cite> and <cite>x_2</cite> with different priors.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_1=(1 - x_1[f_1])(1 - x_2[f_1]))(1 + x_1[f_1] x_2[f_1])^p</cite> is the kernel</dt><dd><p>of the the bias term, which can be decomposed into a determistic part
and a polynomial kernel. Here <cite>f_1</cite> is the first fidelity dimension and
<cite>p</cite> is the order of the polynomial kernel.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_3</cite> is the same as <cite>c_1</cite> but is calculated for the second fidelity</dt><dd><p>dimension <cite>f_2</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_2</cite> is the interaction term with four deterministic terms and the</dt><dd><p>polynomial kernel between <cite>x_1[…, [f_1, f_2]]</cite> and
<cite>x_2[…, [f_1, f_2]]</cite>.</p>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fidelity_dims</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – A list containing either one or two indices specifying
the fidelity parameters of the input.</p></li>
<li><p><strong>dimension</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The dimension of <cite>x</cite>. Unused if <cite>active_dims</cite> is specified.</p></li>
<li><p><strong>power_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – Prior for the power parameter of the polynomial kernel.
Default is <cite>None</cite>.</p></li>
<li><p><strong>power_constraint</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>) – Constraint on the power parameter of the polynomial
kernel. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>nu</strong> (<em>float</em>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2,
or 5/2. Unused if both <cite>covar_module_unbiased</cite> and
<cite>covar_module_biased</cite> are specified.</p></li>
<li><p><strong>lengthscale_prior_unbiased</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – Prior on the lengthscale parameter of Matern
kernel <cite>k_0</cite>. Default is <cite>Gamma(1.1, 1/20)</cite>.</p></li>
<li><p><strong>lengthscale_constraint_unbiased</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>) – Constraint on the lengthscale parameter
of the Matern kernel <cite>k_0</cite>. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>lengthscale_prior_biased</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – Prior on the lengthscale parameter of Matern
kernels <cite>k_i(i&gt;0)</cite>. Default is <cite>Gamma(5, 1/20)</cite>.</p></li>
<li><p><strong>lengthscale_constraint_biased</strong> (<em>Optional</em><em>[</em><em>Interval</em><em>]</em>) – Constraint on the lengthscale parameter
of the Matern kernels <cite>k_i(i&gt;0)</cite>. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>covar_module_unbiased</strong> (<em>Optional</em><em>[</em><em>Kernel</em><em>]</em>) – Specify a custom kernel for <cite>k_0</cite>. If omitted,
use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>covar_module_biased</strong> (<em>Optional</em><em>[</em><em>Kernel</em><em>]</em>) – Specify a custom kernel for the biased parts
<cite>k_i(i&gt;0)</cite>. If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>batch_shape</strong> – If specified, use a separate lengthscale for each batch of
input data. If <cite>x1</cite> is a <cite>batch_shape x n x d</cite> tensor, this should
be <cite>batch_shape</cite>.</p></li>
<li><p><strong>active_dims</strong> – Compute the covariance of a subset of input dimensions. The
numbers correspond to the indices of the dimensions.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Non-batch: Simple option</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">LinearTruncatedFidelityKernel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Output: LazyVariable of size (10 x 10)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batch: Simple option</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">LinearTruncatedFidelityKernel</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Output: LazyVariable of size (2 x 10 x 10)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
<span class="target" id="module-botorch.models.kernels.contextual_lcea"></span><dl class="py class">
<dt class="sig sig-object py" id="botorch.models.kernels.contextual_lcea.LCEAKernel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.contextual_lcea.</span></span><span class="sig-name descname"><span class="pre">LCEAKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_feature_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embs_dim_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_weight_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/contextual_lcea.html#LCEAKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.contextual_lcea.LCEAKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>The Latent Context Embedding Additive (LCE-A) Kernel.</p>
<p>This kernel is similar to the SACKernel, and is used when context breakdowns are
unbserverable. It assumes the same additive structure and a spatial kernel shared
across contexts. Rather than assuming independence, LCEAKernel models the
correlation in the latent functions for each context through learning context
embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decomposition</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys index context names. Values are the indexes of parameters
belong to the context. The parameter indexes are in the same order across
contexts.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – Batch shape as usual for gpytorch kernels. Model does not support
batch training. When batch_shape is non-empty, it is used for loading
hyper-parameter values generated from MCMC sampling.</p></li>
<li><p><strong>train_embedding</strong> (<em>bool</em>) – A boolean indictor of whether to learn context embeddings</p></li>
<li><p><strong>cat_feature_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – Keys are context names and values are list of categorical
features i.e. {“context_name” : [cat_0, …, cat_k]}. k equals to number
of categorical variables. If None, we use context names in the
decomposition as the only categorical feature i.e. k = 1</p></li>
<li><p><strong>embs_feature_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – Pre-trained continuous embedding features of each context.</p></li>
<li><p><strong>embs_dim_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Embedding dimension for each categorical variable. The length
equals to num of categorical features k. If None, emb dim is set to 1
for each categorical variable.</p></li>
<li><p><strong>context_weight_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) – Known population Weights of each context.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>torch.device</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
<span class="target" id="module-botorch.models.kernels.contextual_sac"></span><dl class="py class">
<dt class="sig sig-object py" id="botorch.models.kernels.contextual_sac.SACKernel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.kernels.contextual_sac.</span></span><span class="sig-name descname"><span class="pre">SACKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decomposition</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/contextual_sac.html#SACKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.kernels.contextual_sac.SACKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>The structural additive contextual(SAC) kernel.</p>
<p>The kernel is used for contextual BO without oberseving context breakdowns.
There are d parameters and M contexts. In total, the dimension of parameter space
is d*M and input x can be written as
x=[x_11, …, x_1d, x_21, …, x_2d, …,  x_M1, …, x_Md].</p>
<p>The kernel uses the parameter decomposition and assumes an additive structure
across contexts. Each context compponent is assumed to be independent.</p>
<div class="math notranslate nohighlight">
\[\begin{equation*}
   k(\mathbf{x}, \mathbf{x'}) = k_1(\mathbf{x_(1)}, \mathbf{x'_(1)}) + \cdots
   + k_M(\mathbf{x_(M)}, \mathbf{x'_(M)})
\end{equation*}\]</div>
<p>where
* :math: M is the number of partitions of parameter space. Each partition contains
same number of parameters d. Each kernel <cite>k_i</cite> acts only on d parameters of ith
partition i.e. <cite>mathbf{x}_(i)</cite>. Each kernel <cite>k_i</cite> is a scaled Matern kernel
with same lengthscales but different outputscales.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decomposition</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Keys are context names. Values are the indexes of parameters
belong to the context. The parameter indexes are in the same order across
contexts.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – Batch shape as usual for gpytorch kernels.</p></li>
<li><p><strong>device</strong> (<em>Optional</em><em>[</em><em>torch.device</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
</section>
</section>
<section id="transforms">
<h2>Transforms<a class="headerlink" href="#transforms" title="Permalink to this headline">¶</a></h2>
<section id="module-botorch.models.transforms.outcome">
<span id="outcome-transforms"></span><h3>Outcome Transforms<a class="headerlink" href="#module-botorch.models.transforms.outcome" title="Permalink to this headline">¶</a></h3>
<p>Outcome transformations for automatically transforming and un-transforming
model outputs. Outcome transformations are typically part of a Model and
applied (i) within the model constructor to transform the train observations
to the model space, and (ii) in the <cite>Model.posterior</cite> call to untransform
the model posterior back to the original space.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">OutcomeTransform</span></span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for outcome transforms.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.forward">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the outcomes in a model’s training targets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<p>This functionality is used to properly treat outcome transformations
in the <cite>subset_model</cite> functionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform">botorch.models.transforms.outcome.OutcomeTransform</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform previously transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transfomred training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transformed observation
noises associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-transformed outcome observations.</p></li>
<li><p>The un-transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform a posterior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>botorch.posteriors.posterior.Posterior</em></a>) – A posterior in the transformed space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">botorch.posteriors.posterior.Posterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.OutcomeTransform.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">ChainedOutcomeTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">transforms</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.OutcomeTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.ModuleDict</span></code></p>
<p>An outcome transform representing the chaining of individual transforms</p>
<p>Chaining of outcome transforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>transforms</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><em>OutcomeTransform</em></a>) – The transforms to chain. Internally, the names of the
kwargs are used as the keys for accessing the individual
transforms on the module.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the outcomes in a model’s training targets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform">botorch.models.transforms.outcome.OutcomeTransform</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform previously transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transfomred training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of transformed observation
noises associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-transformed outcome observations.</p></li>
<li><p>The un-transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform a posterior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>botorch.posteriors.posterior.Posterior</em></a>) – A posterior in the transformed space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">botorch.posteriors.posterior.Posterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.ChainedOutcomeTransform.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">Standardize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_stdv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.OutcomeTransform</span></code></a></p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<p>This module is stateful: If in train mode, calling forward updates the
module state (i.e. the mean/std normalizing constants). If in eval mode,
calling forward simply applies the standardization using the current module
state.</p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<em>int</em>) – The output dimension.</p></li>
<li><p><strong>outputs</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Which of the outputs to standardize. If omitted, all
outputs will be standardized.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch_shape of the training targets.</p></li>
<li><p><strong>min_stddv</strong> – The minimum standard deviation for which to perform
standardization (if lower, only de-mean the data).</p></li>
<li><p><strong>min_stdv</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform">botorch.models.transforms.outcome.OutcomeTransform</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-standardize outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized observation
noises associated with the targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-standardized outcome observations.</p></li>
<li><p>The un-standardized observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-standardized outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-standardize the posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>botorch.posteriors.posterior.Posterior</em></a>) – A posterior in the standardized space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The un-standardized posterior. If the input posterior is a MVN,
the transformed posterior is again an MVN.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">botorch.posteriors.posterior.Posterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Standardize.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.outcome.</span></span><span class="sig-name descname"><span class="pre">Log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.OutcomeTransform</span></code></a></p>
<p>Log-transform outcomes.</p>
<p>Useful if the targets are modeled using a (multivariate) log-Normal
distribution. This means that we can use a standard GP model on the
log-transformed outcomes and un-transform the model posterior of that GP.</p>
<p>Log-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>outputs</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Which of the outputs to log-transform. If omitted, all
outputs will be standardized.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.subset_output">
<span class="sig-name descname"><span class="pre">subset_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idcs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.subset_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the transform along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The output indices to subset the transform to.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The current outcome transform, subset to the specified output indices.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform">botorch.models.transforms.outcome.OutcomeTransform</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Log-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform log-transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of log-transfomred targets.</p></li>
<li><p><strong>Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite>-dim tensor of log- transformed
observation noises associated with the training targets
(if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The exponentiated outcome observations.</p></li>
<li><p>The exponentiated observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.untransform_posterior">
<span class="sig-name descname"><span class="pre">untransform_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posterior</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.untransform_posterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform the log-transformed posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><em>botorch.posteriors.posterior.Posterior</em></a>) – A posterior in the log-transformed space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The un-transformed posterior.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior">botorch.posteriors.posterior.Posterior</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.outcome.Log.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.outcome.Log.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.transforms.input">
<span id="input-transforms"></span><h3>Input Transforms<a class="headerlink" href="#module-botorch.models.transforms.input" title="Permalink to this headline">¶</a></h3>
<p>Input Transformations.</p>
<p>These classes implement a variety of transformations for
input parameters including: learned input warping functions,
rounding functions, and log transformations. The input transformation
is typically part of a Model and applied within the model.forward()
method.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">InputTransform</span></span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for input transforms.</p>
<dl class="simple">
<dt>Note: Input transforms must inherit from <cite>torch.nn.Module</cite>. This</dt><dd><p>is deferred to the subclasses to avoid any potential conflict
between <cite>gpytorch.module.Module</cite> and <cite>torch.nn.Module</cite> in <cite>Warp</cite>.</p>
</dd>
<dt>Properties:</dt><dd><dl class="simple">
<dt>transform_on_train: A boolean indicating whether to apply the</dt><dd><p>transform in train() mode.</p>
</dd>
<dt>transform_on_eval: A boolean indicating whether to apply the</dt><dd><p>transform in eval() mode.</p>
</dd>
<dt>transform_on_fantasize: A boolean indicating whether to apply</dt><dd><p>the transform when called from within a <cite>fantasize</cite> call.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n’ x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.transform">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.equals" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<p>Note: The reason that a custom equals method is defined rather than
defining an __eq__ method is because defining an __eq__ method sets
the __hash__ method to None. Hashing modules is currently used in
pytorch. See <a class="reference external" href="https://github.com/pytorch/pytorch/issues/7733">https://github.com/pytorch/pytorch/issues/7733</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>botorch.models.transforms.input.InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputTransform.preprocess_transform">
<span class="sig-name descname"><span class="pre">preprocess_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.preprocess_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.preprocess_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply transforms for preprocessing inputs.</p>
<p>The main use cases for this method are 1) to preprocess training data
before calling <cite>set_train_data</cite> and 2) preprocess <cite>X_baseline</cite> for noisy
acquisition functions so that <cite>X_baseline</cite> is “preprocessed” with the
same transformations as the cached training inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of (transformed) inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">ChainedInputTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">transforms</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.ModuleDict</span></code></p>
<p>An input transform representing the chaining of individual transforms.</p>
<p>Chaining of input transforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>transforms</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>InputTransform</em></a>) – The transforms to chain. Internally, the names of the
kwargs are used as the keys for accessing the individual
transforms on the module.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tf1</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf2</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf</span> <span class="o">=</span> <span class="n">ChainedInputTransform</span><span class="p">(</span><span class="n">tf1</span><span class="o">=</span><span class="n">tf1</span><span class="p">,</span> <span class="n">tf2</span><span class="o">=</span><span class="n">tf2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">['tf1', 'tf2']</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf</span><span class="p">[</span><span class="s2">"tf1"</span><span class="p">]</span>
<span class="go">Normalize()</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs to a model.</p>
<p>Individual transforms are applied in sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform the inputs to a model.</p>
<p>Un-transforms of the individual transforms are applied in reverse sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.equals" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>botorch.models.transforms.input.InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ChainedInputTransform.preprocess_transform">
<span class="sig-name descname"><span class="pre">preprocess_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.preprocess_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.preprocess_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply transforms for preprocessing inputs.</p>
<p>The main use cases for this method are 1) to preprocess training data
before calling <cite>set_train_data</cite> and 2) preprocess <cite>X_baseline</cite> for noisy
acquisition functions so that <cite>X_baseline</cite> is “preprocessed” with the
same transformations as the cached training inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of (transformed) inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">ReversibleInputTransform</span></span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>An abstract class for a reversible input transform.</p>
<dl class="simple">
<dt>Properties:</dt><dd><dl class="simple">
<dt>reverse: A boolean indicating if the functionality of transform</dt><dd><p>and untransform methods should be swapped.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.reverse">
<span class="sig-name descname"><span class="pre">reverse</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.reverse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.untransform">
<span class="sig-name descname"><span class="pre">untransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform.untransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.ReversibleInputTransform.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ReversibleInputTransform.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.ReversibleInputTransform.equals" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>botorch.models.transforms.input.InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size([])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.ReversibleInputTransform" title="botorch.models.transforms.input.ReversibleInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.ReversibleInputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Normalize the inputs to the unit cube.</p>
<p>If no explicit bounds are provided this module is stateful: If in train mode,
calling <cite>forward</cite> updates the module state (i.e. the normalizing bounds). If
in eval mode, calling <cite>forward</cite> simply applies the normalization using the
current module state.</p>
<p>Normalize the inputs to the unit cube.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d</strong> (<em>int</em>) – The dimension of the input space.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – If provided, use these bounds to normalize the inputs. If
omitted, learn the bounds in train mode.</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The batch shape of the inputs (asssuming input tensors
of shape <cite>batch_shape x n x d</cite>). If provided, perform individual
normalization per batch, otherwise uses a single normalization.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Normalize.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Normalize.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Normalize.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.reverse">
<span class="sig-name descname"><span class="pre">reverse</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Normalize.reverse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.bounds">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">bounds</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Tensor</span></em><a class="headerlink" href="#botorch.models.transforms.input.Normalize.bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>The bounds used for normalizing the inputs.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Normalize.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Normalize.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Normalize.equals" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>botorch.models.transforms.input.InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Round</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Round"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Round" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A rounding transformation for integer inputs.</p>
<p>This will typically be used in conjunction with normalization as
follows:</p>
<p>In eval() mode (i.e. after training), the inputs pass
would typically be normalized to the unit cube (e.g. during candidate
optimization). 1. These are unnormalized back to the raw input space.
2. The integers are rounded. 3. All values are normalized to the unit
cube.</p>
<p>In train() mode, the inputs can either (a) be normalized to the unit
cube or (b) provided using their raw values. In the case of (a)
transform_on_train should be set to True, so that the normalized inputs
are unnormalized before rounding. In the case of (b) transform_on_train
should be set to False, so that the raw inputs are rounded and then
normalized to the unit cube.</p>
<p>This transformation uses differentiable approximate rounding by default.
The rounding function is approximated with a piece-wise function where
each piece is a hyperbolic tangent function.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">unnormalize_tf</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">transform_on_eval</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">transform_on_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">round_tf</span> <span class="o">=</span> <span class="n">Round</span><span class="p">(</span><span class="n">integer_indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normalize_tf</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tf</span> <span class="o">=</span> <span class="n">ChainedInputTransform</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">tf1</span><span class="o">=</span><span class="n">unnormalize_tf</span><span class="p">,</span> <span class="n">tf2</span><span class="o">=</span><span class="n">round_tf</span><span class="p">,</span> <span class="n">tf3</span><span class="o">=</span><span class="n">normalize_tf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The indices of the integer inputs.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>approximate</strong> (<em>bool</em>) – A boolean indicating whether approximate or exact
rounding should be used. Default: approximate.</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – The temperature parameter for approximate rounding.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Round.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Round.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Round.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Round.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Round.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Round the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x n x d</cite>-dim tensor of rounded inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Round.equals">
<span class="sig-name descname"><span class="pre">equals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Round.equals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Round.equals" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if another input transform is equivalent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><em>botorch.models.transforms.input.InputTransform</em></a>) – Another input transform.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A boolean indicating if the other transform is equivalent.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Log10">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Log10</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Log10"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Log10" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.ReversibleInputTransform" title="botorch.models.transforms.input.ReversibleInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.ReversibleInputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A base-10 log transformation.</p>
<p>Initialize transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The indices of the inputs to log transform.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Log10.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Log10.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Log10.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Log10.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Log10.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Log10.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Log10.reverse">
<span class="sig-name descname"><span class="pre">reverse</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Log10.reverse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Warp">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">Warp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration1_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concentration0_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Warp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.Warp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.ReversibleInputTransform" title="botorch.models.transforms.input.ReversibleInputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.ReversibleInputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.module.Module</span></code></p>
<p>A transform that uses learned input warping functions.</p>
<p>Each specified input dimension is warped using the CDF of a
Kumaraswamy distribution. Typically, MAP estimates of the
parameters of the Kumaraswamy distribution, for each input
dimension, are learned jointly with the GP hyperparameters.</p>
<p>TODO: implement support using independent warping functions
for each output in batched multi-output and multi-task models.</p>
<p>For now, ModelListGPs should be used to learn independent warping
functions for each output.</p>
<p>Initialize transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The indices of the inputs to warp.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: True.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: True.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) – A boolean indicating whether the forward pass should untransform
the inputs.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – A small value used to clip values to be in the interval (0, 1).</p></li>
<li><p><strong>concentration1_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – A prior distribution on the concentration1 parameter
of the Kumaraswamy distribution.</p></li>
<li><p><strong>concentration0_prior</strong> (<em>Optional</em><em>[</em><em>Prior</em><em>]</em>) – A prior distribution on the concentration0 parameter
of the Kumaraswamy distribution.</p></li>
<li><p><strong>batch_shape</strong> (<em>Optional</em><em>[</em><em>torch.Size</em><em>]</em>) – The batch shape.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Warp.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Warp.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Warp.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Warp.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Warp.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Warp.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.Warp.reverse">
<span class="sig-name descname"><span class="pre">reverse</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.Warp.reverse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">AppendFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#AppendFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A transform that appends the input with a given set of features.</p>
<p>As an example, this can be used with <cite>RiskMeasureMCObjective</cite> to optimize risk
measures as described in <a class="reference internal" href="acquisition.html#cakmak2020risk" id="id10"><span>[Cakmak2020risk]</span></a>. A tutorial notebook implementing the
rhoKG acqusition function introduced in <a class="reference internal" href="acquisition.html#cakmak2020risk" id="id11"><span>[Cakmak2020risk]</span></a> can be found at
<a class="reference external" href="https://botorch.org/tutorials/risk_averse_bo_with_environmental_variables">https://botorch.org/tutorials/risk_averse_bo_with_environmental_variables</a>.</p>
<p>The steps for using this to obtain samples of a risk measure are as follows:</p>
<ul class="simple">
<li><p>Train a model on <cite>(x, w)</cite> inputs and the corresponding observations;</p></li>
<li><p>Pass in an instance of <cite>AppendFeatures</cite> with the <cite>feature_set</cite> denoting the
samples of <cite>W</cite> as the <cite>input_transform</cite> to the trained model;</p></li>
<li><p>Call <cite>posterior(…).rsample(…)</cite> on the model with <cite>x</cite> inputs only to
get the joint posterior samples over <cite>(x, w)`s, where the `w`s come
from the `feature_set</cite>;</p></li>
<li><p>Pass these posterior samples through the <cite>RiskMeasureMCObjective</cite> of choice to
get the samples of the risk measure.</p></li>
</ul>
<p>Note: The samples of the risk measure obtained this way are in general biased
since the <cite>feature_set</cite> does not fully represent the distribution of the
environmental variable.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># We consider 1D `x` and 1D `w`, with `W` having a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># uniform distribution over [0, 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">train_X</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">train_Y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">input_transform</span><span class="o">=</span><span class="n">AppendFeatures</span><span class="p">(</span><span class="n">feature_set</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_gpytorch_model</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># `posterior_samples` is a `10 x 30 x 1`-dim tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">rsamples</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">size</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">risk_measure</span> <span class="o">=</span> <span class="n">VaR</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">n_w</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># `risk_measure_samples` is a `10 x 3`-dim tensor of samples of the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># risk measure VaR</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">risk_measure_samples</span> <span class="o">=</span> <span class="n">risk_measure</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Append <cite>feature_set</cite> to each input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_set</strong> (<em>Tensor</em>) – An <cite>n_f x d_f</cite>-dim tensor denoting the features to be
appended to the inputs.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: False.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.AppendFeatures.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#AppendFeatures.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.AppendFeatures.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs by appending <cite>feature_set</cite> to each input.</p>
<p>For each <cite>1 x d</cite>-dim element in the input tensor, this will produce
an <cite>n_f x (d + d_f)</cite>-dim tensor with <cite>feature_set</cite> appended as the last <cite>d_f</cite>
dimensions. For a generic <cite>batch_shape x q x d</cite>-dim <cite>X</cite>, this translates to a
<cite>batch_shape x (q * n_f) x (d + d_f)</cite>-dim output, where the values corresponding
to <cite>X[…, i, :]</cite> are found in <cite>output[…, i * n_f: (i + 1) * n_f, :]</cite>.</p>
<p>Note: Adding the <cite>feature_set</cite> on the <cite>q-batch</cite> dimension is necessary to avoid
introducing additional bias by evaluating the inputs on independent GP
sample paths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x (q * n_f) x (d + d_f)</cite>-dim tensor of appended inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.input.</span></span><span class="sig-name descname"><span class="pre">InputPerturbation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">perturbation_set</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiplicative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_on_fantasize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputPerturbation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A transform that adds the set of perturbations to the given input.</p>
<p>Similar to <cite>AppendFeatures</cite>, this can be used with <cite>RiskMeasureMCObjective</cite>
to optimize risk measures. See <cite>AppendFeatures</cite> for additional discussion
on optimizing risk measures.</p>
<p>A tutorial notebook using this with <cite>qNoisyExpectedImprovement</cite> can be found at
<a class="reference external" href="https://botorch.org/tutorials/risk_averse_bo_with_input_perturbations">https://botorch.org/tutorials/risk_averse_bo_with_input_perturbations</a>.</p>
<p>Add <cite>perturbation_set</cite> to each input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>perturbation_set</strong> (<em>Tensor</em>) – An <cite>n_p x d</cite>-dim tensor denoting the perturbations
to be added to the inputs.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – A <cite>2 x d</cite>-dim tensor of lower and upper bounds for each
column of the input. If given, the perturbed inputs will be
clamped to these bounds.</p></li>
<li><p><strong>multiplicative</strong> (<em>bool</em>) – A boolean indicating whether the input perturbations
are additive or multiplicative. If True, inputs will be multiplied
with the perturbations.</p></li>
<li><p><strong>transform_on_train</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transforms in train() mode. Default: False.</p></li>
<li><p><strong>transform_on_eval</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform in eval() mode. Default: True.</p></li>
<li><p><strong>transform_on_fantasize</strong> (<em>bool</em>) – A boolean indicating whether to apply the
transform when called from within a <cite>fantasize</cite> call. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation.transform_on_train">
<span class="sig-name descname"><span class="pre">transform_on_train</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation.transform_on_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation.transform_on_eval">
<span class="sig-name descname"><span class="pre">transform_on_eval</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation.transform_on_eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation.transform_on_fantasize">
<span class="sig-name descname"><span class="pre">transform_on_fantasize</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation.transform_on_fantasize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.models.transforms.input.InputPerturbation.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputPerturbation.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.input.InputPerturbation.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs by adding <cite>perturbation_set</cite> to each input.</p>
<p>For each <cite>1 x d</cite>-dim element in the input tensor, this will produce
an <cite>n_p x d</cite>-dim tensor with the <cite>perturbation_set</cite> added to the input.
For a generic <cite>batch_shape x q x d</cite>-dim <cite>X</cite>, this translates to a
<cite>batch_shape x (q * n_p) x d</cite>-dim output, where the values corresponding
to <cite>X[…, i, :]</cite> are found in <cite>output[…, i * n_w: (i + 1) * n_w, :]</cite>.</p>
<p>Note: Adding the <cite>perturbation_set</cite> on the <cite>q-batch</cite> dimension is necessary
to avoid introducing additional bias by evaluating the inputs on independent
GP sample paths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x q x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape x (q * n_p) x d</cite>-dim tensor of perturbed inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="module-botorch.models.transforms.utils">
<span id="transform-utilities"></span><h3>Transform Utilities<a class="headerlink" href="#module-botorch.models.transforms.utils" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.lognorm_to_norm">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">lognorm_to_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cov</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#lognorm_to_norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.lognorm_to_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean and covariance of a MVN from those of the associated log-MVN</p>
<p>If <cite>Y</cite> is log-normal with mean mu_ln and covariance Cov_ln, then
<cite>X ~ N(mu_n, Cov_n)</cite> with</p>
<blockquote>
<div><p>Cov_n_{ij} = log(1 + Cov_ln_{ij} / (mu_ln_{i} * mu_n_{j}))
mu_n_{i} = log(mu_ln_{i}) - 0.5 * log(1 + Cov_ln_{ii} / mu_ln_{i}**2)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the log-Normal distribution.</p></li>
<li><p><strong>Cov</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x n</cite> covariance matrix of the log-Normal
distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The <cite>batch_shape x n</cite> mean vector of the Normal distribution</p></li>
<li><p>The <cite>batch_shape x n x n</cite> covariance matrix of the Normal distribution</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple containing</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.norm_to_lognorm">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">norm_to_lognorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cov</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean and covariance of a log-MVN from its MVN sufficient statistics</p>
<p>If <cite>X ~ N(mu, Cov)</cite> and <cite>Y = exp(X)</cite>, then <cite>Y</cite> is log-normal with</p>
<blockquote>
<div><p>mu_ln_{i} = exp(mu_{i} + 0.5 * Cov_{ii})
Cov_ln_{ij} = exp(mu_{i} + mu_{j} + 0.5 * (Cov_{ii} + Cov_{jj})) *
(exp(Cov_{ij}) - 1)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>Cov</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x n</cite> covariance matrix of the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The <cite>batch_shape x n</cite> mean vector of the log-Normal distribution.</p></li>
<li><dl class="simple">
<dt>The <cite>batch_shape x n x n</cite> covariance matrix of the log-Normal</dt><dd><p>distribution.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple containing</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.norm_to_lognorm_mean">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">norm_to_lognorm_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm_mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm_mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean of a log-MVN from its MVN marginals</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>var</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n</cite> variance vectorof the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The <cite>batch_shape x n</cite> mean vector of the log-Normal distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.norm_to_lognorm_variance">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">norm_to_lognorm_variance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm_variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm_variance" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute variance of a log-MVN from its MVN marginals</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>var</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n</cite> variance vectorof the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The <cite>batch_shape x n</cite> variance vector of the log-Normal distribution.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.transforms.utils.expand_and_copy_tensor">
<span class="sig-prename descclassname"><span class="pre">botorch.models.transforms.utils.</span></span><span class="sig-name descname"><span class="pre">expand_and_copy_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#expand_and_copy_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.transforms.utils.expand_and_copy_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand and copy X according to batch_shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>input_batch_shape x n x d</cite>-dim tensor of inputs</p></li>
<li><p><strong>batch_shape</strong> (<em>torch.Size</em>) – The new batch shape</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>input_batch_shape x batch_shape x n x d</cite>-dim tensor of inputs</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
</section>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">¶</a></h2>
<section id="module-botorch.models.converter">
<span id="model-conversion"></span><h3>Model Conversion<a class="headerlink" href="#module-botorch.models.converter" title="Permalink to this headline">¶</a></h3>
<p>Utilities for converting between different models.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.model_list_to_batched">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">model_list_to_batched</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#model_list_to_batched"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.model_list_to_batched" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a ModelListGP to a BatchedMultiOutputGPyTorchModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_list</strong> (<a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><em>botorch.models.model_list_gp_regression.ModelListGP</em></a>) – The <cite>ModelListGP</cite> to be converted to the appropriate
<cite>BatchedMultiOutputGPyTorchModel</cite>. All sub-models must be of the same
type and have the shape (batch shape and number of training inputs).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The model converted into a <cite>BatchedMultiOutputGPyTorchModel</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">list_gp</span> <span class="o">=</span> <span class="n">ModelListGP</span><span class="p">(</span><span class="n">gp1</span><span class="p">,</span> <span class="n">gp2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_gp</span> <span class="o">=</span> <span class="n">model_list_to_batched</span><span class="p">(</span><span class="n">list_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.batched_to_model_list">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">batched_to_model_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#batched_to_model_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.batched_to_model_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a BatchedMultiOutputGPyTorchModel to a ModelListGP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch_model</strong> (<a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</em></a>) – The <cite>BatchedMultiOutputGPyTorchModel</cite> to be converted to a
<cite>ModelListGP</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The model converted into a <cite>ModelListGP</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP">botorch.models.model_list_gp_regression.ModelListGP</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">list_gp</span> <span class="o">=</span> <span class="n">batched_to_model_list</span><span class="p">(</span><span class="n">batch_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.converter.batched_multi_output_to_single_output">
<span class="sig-prename descclassname"><span class="pre">botorch.models.converter.</span></span><span class="sig-name descname"><span class="pre">batched_multi_output_to_single_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_mo_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#batched_multi_output_to_single_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.converter.batched_multi_output_to_single_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a model from batched multi-output to a batched single-output.</p>
<p>Note: the underlying GPyTorch GP does not change. The GPyTorch GP’s batch_shape
(referred to as <cite>_aug_batch_shape</cite>) is still <cite>_input_batch_shape x num_outputs</cite>.
The only things that change are the attributes of the
BatchedMultiOutputGPyTorchModel that are responsible the internal accounting of
the number of outputs: namely, num_outputs, _input_batch_shape, and
_aug_batch_shape.
Initially for the batched MO models these are: <cite>num_outputs = m</cite>,
<cite>_input_batch_shape = train_X.batch_shape</cite>, and
<cite>_aug_batch_shape = train_X.batch_shape + torch.Size([num_outputs])</cite>.
In the new SO model, these are: <cite>num_outputs = 1</cite>,
<cite>_input_batch_shape = train_X.batch_shape + torch.Size([num_outputs])</cite>,
and <cite>_aug_batch_shape = train_X.batch_shape + torch.Size([num_outputs])</cite>.</p>
<p>This is a (hopefully) temporary measure until multi-output MVNs with
independent outputs have better support in GPyTorch (see
<a class="reference external" href="https://github.com/cornellius-gp/gpytorch/pull/1083">https://github.com/cornellius-gp/gpytorch/pull/1083</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batched_mo_model</strong> – The BatchedMultiOutputGPyTorchModel</p></li>
<li><p><strong>batch_mo_model</strong> (<a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><em>botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</em></a>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The model converted into a batch single-output model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_mo_gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_so_gp</span> <span class="o">=</span> <span class="n">batched_multioutput_to_single_output</span><span class="p">(</span><span class="n">batch_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</section>
<section id="module-botorch.models.utils">
<span id="other-utilties"></span><h3>Other Utilties<a class="headerlink" href="#module-botorch.models.utils" title="Permalink to this headline">¶</a></h3>
<p>Utiltiy functions for models.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.multioutput_to_batch_mode_transform">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">multioutput_to_batch_mode_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#multioutput_to_batch_mode_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.multioutput_to_batch_mode_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transforms training inputs for a multi-output model.</p>
<p>Used for multi-output models that internally are represented by a
batched single output model, where each output is modeled as an
independent batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – A <cite>n x d</cite> or <cite>input_batch_shape x n x d</cite> (batch mode) tensor of
training features.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – A <cite>n x m</cite> or <cite>target_batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of outputs</p></li>
<li><p><strong>train_Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>n x m</cite> or <cite>target_batch_shape x n x m</cite> tensor of observed
measurement noise.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>3-element tuple containing</p>
<ul class="simple">
<li><p>A <cite>input_batch_shape x m x n x d</cite> tensor of training features.</p></li>
<li><p>A <cite>target_batch_shape x m x n</cite> tensor of training observations.</p></li>
<li><p>A <cite>target_batch_shape x m x n</cite> tensor observed measurement noise.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.add_output_dim">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">add_output_dim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">original_batch_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#add_output_dim"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.add_output_dim" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert the output dimension at the correct location.</p>
<p>The trailing batch dimensions of X must match the original batch dimensions
of the training inputs, but can also include extra batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>(new_batch_shape) x (original_batch_shape) x n x d</cite> tensor of
features.</p></li>
<li><p><strong>original_batch_shape</strong> (<em>torch.Size</em>) – the batch shape of the model’s training inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A <cite>(new_batch_shape) x (original_batch_shape) x m x n x d</cite> tensor of</dt><dd><p>features.</p>
</dd>
</dl>
</li>
<li><p>The index corresponding to the output dimension.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, int]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.check_no_nans">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">check_no_nans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#check_no_nans"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.check_no_nans" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that tensor does not contain NaN values.</p>
<p>Raises an InputDataError if <cite>Z</cite> contains NaN values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>Z</strong> (<em>torch.Tensor</em>) – The input tensor.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.check_min_max_scaling">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">check_min_max_scaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_fail</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#check_min_max_scaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.check_min_max_scaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that tensor is normalized to the unit cube.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – A <cite>batch_shape x n x d</cite> input tensor. Typically the training inputs
of a model.</p></li>
<li><p><strong>strict</strong> (<em>bool</em>) – If True, require <cite>X</cite> to be scaled to the unit cube (rather than
just to be contained within the unit cube).</p></li>
<li><p><strong>atol</strong> (<em>float</em>) – The tolerance for the boundary check. Only used if <cite>strict=True</cite>.</p></li>
<li><p><strong>raise_on_fail</strong> (<em>bool</em>) – If True, raise an exception instead of a warning.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.check_standardization">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">check_standardization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_fail</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#check_standardization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.check_standardization" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that tensor is standardized (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<em>torch.Tensor</em>) – The input tensor of shape <cite>batch_shape x n x m</cite>. Typically the
train targets of a model. Standardization is checked across the
<cite>n</cite>-dimension.</p></li>
<li><p><strong>atol_mean</strong> (<em>float</em>) – The tolerance for the mean check.</p></li>
<li><p><strong>atol_std</strong> (<em>float</em>) – The tolerance for the std check.</p></li>
<li><p><strong>raise_on_fail</strong> (<em>bool</em>) – If True, raise an exception instead of a warning.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.validate_input_scaling">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">validate_input_scaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_Yvar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_fail</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#validate_input_scaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.validate_input_scaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function to validate input data to models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<em>torch.Tensor</em>) – A <cite>n x d</cite> or <cite>batch_shape x n x d</cite> (batch mode) tensor of
training features.</p></li>
<li><p><strong>train_Y</strong> (<em>torch.Tensor</em>) – A <cite>n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<em>Optional</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A <cite>batch_shape x n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode)
tensor of observed measurement noise.</p></li>
<li><p><strong>raise_on_fail</strong> (<em>bool</em>) – If True, raise an error instead of emitting a warning
(only for normalization/standardization checks, an error is always
raised if NaN values are present).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>This function is typically called inside the constructor of standard BoTorch
models. It validates the following:
(i) none of the inputs contain NaN values
(ii) the training data (<cite>train_X</cite>) is normalized to the unit cube
(iii) the training targets (<cite>train_Y</cite>) are standardized (zero mean, unit var)
No checks (other than the NaN check) are performed for observed variances
(<cite>train_Yvar</cite>) at this point.</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.mod_batch_shape">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">mod_batch_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#mod_batch_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.mod_batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Recursive helper to modify gpytorch modules’ batch shape attribute.</p>
<p>Modifies the module in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>gpytorch.module.Module</em>) – The module to be modified.</p></li>
<li><p><strong>names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – The list of names to access the attribute. If the full name of
the module is <cite>“module.sub_module.leaf_module”</cite>, this will be
<cite>[“sub_module”, “leaf_module”]</cite>.</p></li>
<li><p><strong>b</strong> (<em>int</em>) – The new size of the last element of the module’s <cite>batch_shape</cite>
attribute.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.models.utils.gpt_posterior_settings">
<span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">gpt_posterior_settings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#gpt_posterior_settings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.gpt_posterior_settings" title="Permalink to this definition">¶</a></dt>
<dd><p>Context manager for settings used for computing model posteriors.</p>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.models.utils.fantasize">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">botorch.models.utils.</span></span><span class="sig-name descname"><span class="pre">fantasize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#fantasize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.models.utils.fantasize" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.settings._Flag</span></code></p>
<p>A flag denoting whether we are currently in a <cite>fantasize</cite> context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>bool</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
</section>
</section>
</section>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">botorch.distributions</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="acquisition.html" title="previous chapter">botorch.acquisition</a></li>
<li>Next: <a href="generation.html" title="next chapter">botorch.generation</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/latest/" class="nav-home"><img src="/v/latest/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/latest/docs/introduction">Introduction</a><a href="/v/latest/docs/getting_started">Getting Started</a><a href="/v/latest/tutorials/">Tutorials</a><a href="/v/latest/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/latest/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2021 Facebook Inc.</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/latest/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div></body></html>