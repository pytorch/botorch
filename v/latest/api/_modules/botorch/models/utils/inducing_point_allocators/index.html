<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/latest/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/latest/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/latest/img/botorch.png"/><link rel="shortcut icon" href="/v/latest/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CXN3PGE3CC"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'G-CXN3PGE3CC');
            </script><link rel="stylesheet" href="/v/latest/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/latest/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/latest/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/latest/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/latest/css/main.css"/><script src="/v/latest/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/latest/"><img class="logo" src="/v/latest/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/latest/versions"><h3>latest</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/latest/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/latest/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/latest/api/" target="_self">API Reference</a></li><li class=""><a href="/v/latest/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for botorch.models.utils.inducing_point_allocators</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">"""</span>
<span class="sd">Functionality for allocating the inducing points of sparse Gaussian</span>
<span class="sd">process models.</span>

<span class="sd">References</span>

<span class="sd">.. [chen2018dpp]</span>
<span class="sd">    Laming Chen and Guoxin Zhang and Hanning Zhou, Fast greedy MAP inference</span>
<span class="sd">    for determinantal point process to improve recommendation diversity,</span>
<span class="sd">    Proceedings of the 32nd International Conference on Neural Information</span>
<span class="sd">    Processing Systems, 2018, https://arxiv.org/abs/1709.05135.</span>

<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">botorch.exceptions.errors</span> <span class="kn">import</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span> <span class="nn">botorch.models.model</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="kn">from</span> <span class="nn">botorch.utils.probability.utils</span> <span class="kn">import</span> <span class="n">ndtr</span> <span class="k">as</span> <span class="n">Phi</span><span class="p">,</span> <span class="n">phi</span>
<span class="kn">from</span> <span class="nn">gpytorch.module</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">linear_operator.operators</span> <span class="kn">import</span> <span class="n">LinearOperator</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">NEG_INF</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">"-inf"</span><span class="p">))</span>


<div class="viewcode-block" id="InducingPointAllocator"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators.InducingPointAllocator">[docs]</a><span class="k">class</span> <span class="nc">InducingPointAllocator</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    This class provides functionality to initialize the inducing point locations</span>
<span class="sd">    of an inducing point-based model, e.g. a `SingleTaskVariationalGP`.</span>
<span class="sd">    """</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_get_quality_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QualityFunction</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Build the quality function required for this inducing point allocation strategy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A quality function.</span>
<span class="sd">        """</span>

<div class="viewcode-block" id="InducingPointAllocator.allocate_inducing_points"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators.InducingPointAllocator.allocate_inducing_points">[docs]</a>    <span class="k">def</span> <span class="nf">allocate_inducing_points</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">covar_module</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">num_inducing</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">input_batch_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">        Initialize the `num_inducing` inducing point locations according to a</span>
<span class="sd">        specific initialization strategy. todo say something about quality</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: A (\*batch_shape, n, d)-dim input data tensor.</span>
<span class="sd">            covar_module: GPyTorch Module returning a LinearOperator kernel matrix.</span>
<span class="sd">            num_inducing: The maximun number (m) of inducing points (m &lt;= n).</span>
<span class="sd">            input_batch_shape: The non-task-related batch shape.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A (\*batch_shape, m, d)-dim tensor of inducing point locations.</span>
<span class="sd">        """</span>
        <span class="n">quality_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quality_function</span><span class="p">()</span>
        <span class="n">covar_module</span> <span class="o">=</span> <span class="n">covar_module</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># We use 'no_grad' here because `inducing_points` are not</span>
        <span class="c1"># auto-differentiable with respect to the kernel hyper-parameters,</span>
        <span class="c1"># because `_pivoted_cholesky_init` does in-place operations.</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Evaluate lazily because this may only be needed to figure out what</span>
            <span class="c1"># case we are in</span>
            <span class="n">possibly_lazy_kernel</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">base_case</span> <span class="o">=</span> <span class="n">possibly_lazy_kernel</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="n">multi_task_case</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">possibly_lazy_kernel</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_batch_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">base_case</span> <span class="ow">or</span> <span class="n">multi_task_case</span><span class="p">:</span>
            <span class="n">train_train_kernel</span> <span class="o">=</span> <span class="n">possibly_lazy_kernel</span><span class="o">.</span><span class="n">evaluate_kernel</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">base_case</span><span class="p">:</span>
            <span class="n">quality_scores</span> <span class="o">=</span> <span class="n">quality_function</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">inducing_points</span> <span class="o">=</span> <span class="n">_pivoted_cholesky_init</span><span class="p">(</span>
                <span class="n">train_inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">kernel_matrix</span><span class="o">=</span><span class="n">train_train_kernel</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">num_inducing</span><span class="p">,</span>
                <span class="n">quality_scores</span><span class="o">=</span><span class="n">quality_scores</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">inducing_points</span>

        <span class="k">if</span> <span class="n">multi_task_case</span><span class="p">:</span>
            <span class="n">input_element</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span> <span class="k">else</span> <span class="n">inputs</span>
            <span class="n">kernel_element</span> <span class="o">=</span> <span class="n">train_train_kernel</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">quality_scores</span> <span class="o">=</span> <span class="n">quality_function</span><span class="p">(</span><span class="n">input_element</span><span class="p">)</span>
            <span class="n">inducing_points</span> <span class="o">=</span> <span class="n">_pivoted_cholesky_init</span><span class="p">(</span>
                <span class="n">train_inputs</span><span class="o">=</span><span class="n">input_element</span><span class="p">,</span>
                <span class="n">kernel_matrix</span><span class="o">=</span><span class="n">kernel_element</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">num_inducing</span><span class="p">,</span>
                <span class="n">quality_scores</span><span class="o">=</span><span class="n">quality_scores</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">inducing_points</span>

        <span class="c1"># batched input cases</span>
        <span class="n">batched_inputs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">inputs</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">input_batch_shape</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span>
            <span class="k">else</span> <span class="n">inputs</span>
        <span class="p">)</span>
        <span class="n">reshaped_inputs</span> <span class="o">=</span> <span class="n">batched_inputs</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">end_dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">inducing_points</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">input_element</span> <span class="ow">in</span> <span class="n">reshaped_inputs</span><span class="p">:</span>
            <span class="c1"># the extra kernel evals are a little wasteful but make it</span>
            <span class="c1"># easier to infer the task batch size</span>
            <span class="c1"># We use 'no_grad' here because `inducing_points` are not</span>
            <span class="c1"># auto-differentiable with respect to the kernel hyper-parameters,</span>
            <span class="c1"># because `_pivoted_cholesky_init` does in-place operations.</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">kernel_element</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">input_element</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_kernel</span><span class="p">()</span>
            <span class="c1"># handle extra task batch dimension</span>
            <span class="n">kernel_element</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">kernel_element</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">kernel_element</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span>
                <span class="k">else</span> <span class="n">kernel_element</span>
            <span class="p">)</span>
            <span class="n">quality_scores</span> <span class="o">=</span> <span class="n">quality_function</span><span class="p">(</span><span class="n">input_element</span><span class="p">)</span>
            <span class="n">inducing_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_pivoted_cholesky_init</span><span class="p">(</span>
                    <span class="n">train_inputs</span><span class="o">=</span><span class="n">input_element</span><span class="p">,</span>
                    <span class="n">kernel_matrix</span><span class="o">=</span><span class="n">kernel_element</span><span class="p">,</span>
                    <span class="n">max_length</span><span class="o">=</span><span class="n">num_inducing</span><span class="p">,</span>
                    <span class="n">quality_scores</span><span class="o">=</span><span class="n">quality_scores</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">inducing_points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inducing_points</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
            <span class="o">*</span><span class="n">input_batch_shape</span><span class="p">,</span> <span class="n">num_inducing</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">inducing_points</span></div></div>


<div class="viewcode-block" id="QualityFunction"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators.QualityFunction">[docs]</a><span class="k">class</span> <span class="nc">QualityFunction</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A function that scores inputs with respect</span>
<span class="sd">    to a specific criterion."""</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>  <span class="c1"># [n, d] -&gt; [n]</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            inputs: inputs (of shape n x d)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tensor of quality scores for each input, of shape [n]</span>
<span class="sd">        """</span></div>


<div class="viewcode-block" id="UnitQualityFunction"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators.UnitQualityFunction">[docs]</a><span class="k">class</span> <span class="nc">UnitQualityFunction</span><span class="p">(</span><span class="n">QualityFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A function returning ones for each element. Using this quality function</span>
<span class="sd">    for inducing point allocation corresponds to allocating inducing points</span>
<span class="sd">    with the sole aim of minimizing predictive variance, i.e. the approach</span>
<span class="sd">    of [burt2020svgp]_.</span>
<span class="sd">    """</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>  <span class="c1"># [n, d]-&gt; [n]</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            inputs: inputs (of shape n x d)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tensor of ones for each input, of shape [n]</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="ExpectedImprovementQualityFunction"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators.ExpectedImprovementQualityFunction">[docs]</a><span class="k">class</span> <span class="nc">ExpectedImprovementQualityFunction</span><span class="p">(</span><span class="n">QualityFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A function measuring the quality of input points as their expected</span>
<span class="sd">    improvement with respect to a conservative baseline. Expectations</span>
<span class="sd">    are according to the model from the previous BO step. See [moss2023ipa]_</span>
<span class="sd">    for details and justification.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span> <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            model: The model fitted during the previous BO step. For now, this</span>
<span class="sd">                must be a single task model (i.e. num_outputs=1).</span>
<span class="sd">            maximize: Set True if we are performing function maximization, else</span>
<span class="sd">                set False.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">"Multi-output models are currently not supported. "</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maximize</span> <span class="o">=</span> <span class="n">maximize</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>  <span class="c1"># [n, d] -&gt; [n]</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            inputs: inputs (of shape n x d)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tensor of quality scores for each input, of shape [n]</span>
<span class="sd">        """</span>

        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># removing redundant dimensions</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mf">1e-12</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">best_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maximize</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="n">best_f</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maximize</span> <span class="k">else</span> <span class="o">-</span><span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="n">best_f</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
        <span class="k">return</span> <span class="n">sigma</span> <span class="o">*</span> <span class="p">(</span><span class="n">phi</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">+</span> <span class="n">u</span> <span class="o">*</span> <span class="n">Phi</span><span class="p">(</span><span class="n">u</span><span class="p">))</span></div>


<div class="viewcode-block" id="GreedyVarianceReduction"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators.GreedyVarianceReduction">[docs]</a><span class="k">class</span> <span class="nc">GreedyVarianceReduction</span><span class="p">(</span><span class="n">InducingPointAllocator</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    The inducing point allocator proposed by [burt2020svgp]_, that</span>
<span class="sd">    greedily chooses inducing point locations with maximal (conditional)</span>
<span class="sd">    predictive variance.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">_get_quality_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QualityFunction</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Build the unit quality function required for the greedy variance</span>
<span class="sd">        reduction inducing point allocation strategy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A quality function.</span>
<span class="sd">        """</span>

        <span class="k">return</span> <span class="n">UnitQualityFunction</span><span class="p">()</span></div>


<div class="viewcode-block" id="GreedyImprovementReduction"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators.GreedyImprovementReduction">[docs]</a><span class="k">class</span> <span class="nc">GreedyImprovementReduction</span><span class="p">(</span><span class="n">InducingPointAllocator</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    An inducing point allocator that greedily chooses inducing points with large</span>
<span class="sd">    predictive variance and that are in promising regions of the search</span>
<span class="sd">    space (according to the model form the previous BO step), see [moss2023ipa]_.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span> <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The model fitted during the previous BO step.</span>
<span class="sd">            maximize: Set True if we are performing function maximization, else</span>
<span class="sd">                set False.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_maximize</span> <span class="o">=</span> <span class="n">maximize</span>

    <span class="k">def</span> <span class="nf">_get_quality_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QualityFunction</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Build the improvement-based quality function required for the greedy</span>
<span class="sd">        improvement reduction inducing point allocation strategy.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A quality function.</span>
<span class="sd">        """</span>

        <span class="k">return</span> <span class="n">ExpectedImprovementQualityFunction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maximize</span><span class="p">)</span></div>


<div class="viewcode-block" id="_pivoted_cholesky_init"><a class="viewcode-back" href="../../../../models.html#botorch.models.utils.inducing_point_allocators._pivoted_cholesky_init">[docs]</a><span class="k">def</span> <span class="nf">_pivoted_cholesky_init</span><span class="p">(</span>
    <span class="n">train_inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">kernel_matrix</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">LinearOperator</span><span class="p">],</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">quality_scores</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    A pivoted Cholesky initialization method for the inducing points,</span>
<span class="sd">    originally proposed in [burt2020svgp]_ with the algorithm itself coming from</span>
<span class="sd">    [chen2018dpp]_. Code is a PyTorch version from [chen2018dpp]_, based on</span>
<span class="sd">    https://github.com/laming-chen/fast-map-dpp/blob/master/dpp.py but with a small</span>
<span class="sd">    modification to allow the underlying DPP to be defined through its diversity-quality</span>
<span class="sd">    decomposition,as discussed by [moss2023ipa]_. This method returns a greedy</span>
<span class="sd">    approximation of the MAP estimate of the specified DPP, i.e. its returns a</span>
<span class="sd">    set of points that are highly diverse (according to the provided kernel_matrix)</span>
<span class="sd">    and have high quality (according to the provided quality_scores).</span>

<span class="sd">    Args:</span>
<span class="sd">        train_inputs: training inputs (of shape n x d)</span>
<span class="sd">        kernel_matrix: kernel matrix on the training inputs</span>
<span class="sd">        max_length: number of inducing points to initialize</span>
<span class="sd">        quality_scores: scores representing the quality of each candidate</span>
<span class="sd">            input (of shape [n])</span>
<span class="sd">        epsilon: numerical jitter for stability.</span>

<span class="sd">    Returns:</span>
<span class="sd">        max_length x d tensor of the training inputs corresponding to the top</span>
<span class="sd">        max_length pivots of the training kernel matrix</span>
<span class="sd">    """</span>

    <span class="c1"># this is numerically equivalent to iteratively performing a pivoted cholesky</span>
    <span class="c1"># while storing the diagonal pivots at each iteration</span>
    <span class="c1"># TODO: use gpytorch's pivoted cholesky instead once that gets an exposed list</span>
    <span class="c1"># TODO: ensure this works in batch mode, which it does not currently.</span>

    <span class="c1"># todo test for shape of quality function</span>

    <span class="k">if</span> <span class="n">quality_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">train_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">"_pivoted_cholesky_init requires a quality score for each of train_inputs"</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">kernel_matrix</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
            <span class="s2">"`_pivoted_cholesky_init` does not support using a `kernel_matrix` "</span>
            <span class="s2">"with `requires_grad=True`."</span>
        <span class="p">)</span>

    <span class="n">item_size</span> <span class="o">=</span> <span class="n">kernel_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">cis</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="n">max_length</span><span class="p">,</span> <span class="n">item_size</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">kernel_matrix</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">kernel_matrix</span><span class="o">.</span><span class="n">dtype</span>
    <span class="p">)</span>
    <span class="n">di2s</span> <span class="o">=</span> <span class="n">kernel_matrix</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">di2s</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">quality_scores</span><span class="p">)</span>
    <span class="n">selected_item</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">selected_items</span> <span class="o">=</span> <span class="p">[</span><span class="n">selected_item</span><span class="p">]</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">selected_items</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_length</span><span class="p">:</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">selected_items</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">ci_optimal</span> <span class="o">=</span> <span class="n">cis</span><span class="p">[:</span><span class="n">k</span><span class="p">,</span> <span class="n">selected_item</span><span class="p">]</span>
        <span class="n">di_optimal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">di2s</span><span class="p">[</span><span class="n">selected_item</span><span class="p">])</span>
        <span class="n">elements</span> <span class="o">=</span> <span class="n">kernel_matrix</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">selected_item</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">eis</span> <span class="o">=</span> <span class="p">(</span><span class="n">elements</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">ci_optimal</span><span class="p">,</span> <span class="n">cis</span><span class="p">[:</span><span class="n">k</span><span class="p">,</span> <span class="p">:]))</span> <span class="o">/</span> <span class="n">di_optimal</span>
        <span class="n">cis</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">eis</span>
        <span class="n">di2s</span> <span class="o">=</span> <span class="n">di2s</span> <span class="o">-</span> <span class="n">eis</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="n">di2s</span><span class="p">[</span><span class="n">selected_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">NEG_INF</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">di2s</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">quality_scores</span><span class="p">)</span>
        <span class="n">selected_item</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">di2s</span><span class="p">[</span><span class="n">selected_item</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">selected_items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">selected_item</span><span class="p">)</span>

    <span class="n">ind_points</span> <span class="o">=</span> <span class="n">train_inputs</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">selected_items</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">ind_points</span><span class="p">[:</span><span class="n">max_length</span><span class="p">,</span> <span class="p">:]</span></div>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../../index.html">Documentation overview</a><ul>
<li><a href="../../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/latest/" class="nav-home"><img src="/v/latest/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/latest/docs/introduction">Introduction</a><a href="/v/latest/docs/getting_started">Getting Started</a><a href="/v/latest/tutorials/">Tutorials</a><a href="/v/latest/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/latest/img/oss_logo.png" alt="Meta Open Source" width="300" height="25"/></a><section class="copyright"> Copyright © 2023 Meta Platforms, Inc</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/latest/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div></body></html>