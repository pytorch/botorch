<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/latest/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/latest/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/latest/img/botorch.png"/><link rel="shortcut icon" href="/v/latest/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CXN3PGE3CC"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'G-CXN3PGE3CC');
            </script><link rel="stylesheet" href="/v/latest/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/latest/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/latest/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/latest/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/latest/css/main.css"/><script src="/v/latest/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/latest/"><img class="logo" src="/v/latest/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/latest/versions"><h3>latest</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/latest/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/latest/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/latest/api/" target="_self">API Reference</a></li><li class=""><a href="/v/latest/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for botorch.acquisition.monte_carlo</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">"""</span>
<span class="sd">Batch acquisition functions using the reparameterization trick in combination</span>
<span class="sd">with (quasi) Monte-Carlo sampling. See [Rezende2014reparam]_, [Wilson2017reparam]_ and</span>
<span class="sd">[Balandat2020botorch]_.</span>

<span class="sd">.. [Rezende2014reparam]</span>
<span class="sd">    D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic backpropagation and</span>
<span class="sd">    approximate inference in deep generative models. ICML 2014.</span>

<span class="sd">.. [Wilson2017reparam]</span>
<span class="sd">    J. T. Wilson, R. Moriconi, F. Hutter, and M. P. Deisenroth.</span>
<span class="sd">    The reparameterization trick for acquisition functions. ArXiv 2017.</span>
<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Protocol</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.acquisition</span> <span class="kn">import</span> <span class="n">AcquisitionFunction</span><span class="p">,</span> <span class="n">MCSamplerMixin</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.cached_cholesky</span> <span class="kn">import</span> <span class="n">CachedCholeskyMCAcquisitionFunction</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.objective</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConstrainedMCObjective</span><span class="p">,</span>
    <span class="n">IdentityMCObjective</span><span class="p">,</span>
    <span class="n">MCAcquisitionObjective</span><span class="p">,</span>
    <span class="n">PosteriorTransform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_best_feasible_objective</span><span class="p">,</span>
    <span class="n">prune_inferior_points</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.exceptions.errors</span> <span class="kn">import</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span> <span class="nn">botorch.models.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.base</span> <span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span> <span class="nn">botorch.utils.objective</span> <span class="kn">import</span> <span class="n">compute_smoothed_feasibility_indicator</span>
<span class="kn">from</span> <span class="nn">botorch.utils.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">concatenate_pending_points</span><span class="p">,</span>
    <span class="n">match_batch_shape</span><span class="p">,</span>
    <span class="n">t_batch_mode_transform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="MCAcquisitionFunction"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.MCAcquisitionFunction">[docs]</a><span class="k">class</span> <span class="nc">MCAcquisitionFunction</span><span class="p">(</span><span class="n">AcquisitionFunction</span><span class="p">,</span> <span class="n">MCSamplerMixin</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    Abstract base class for Monte-Carlo based batch acquisition functions.</span>

<span class="sd">    :meta private:</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            sampler: The sampler used to draw base samples. If not given,</span>
<span class="sd">                a sampler is generated using `get_sampler`.</span>
<span class="sd">                NOTE: For posteriors that do not support base samples,</span>
<span class="sd">                a sampler compatible with intended use case must be provided.</span>
<span class="sd">                See `ForkedRNGSampler` and `StochasticSampler` as examples.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape, m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="n">MCSamplerMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                    <span class="s2">"Must specify an objective or a posterior transform when using "</span>
                    <span class="s2">"a multi-output model."</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">posterior_transform</span><span class="o">.</span><span class="n">scalarize</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                    <span class="s2">"If using a multi-output model without an objective, "</span>
                    <span class="s2">"posterior_transform must scalarize the output."</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="n">IdentityMCObjective</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span> <span class="o">=</span> <span class="n">posterior_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">=</span> <span class="n">objective</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_pending</span><span class="p">(</span><span class="n">X_pending</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_samples_and_objectives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Computes posterior samples and objective values at input X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d`-dim Tensor of model inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple `(samples, obj)`, where `samples` is a tensor of posterior</span>
<span class="sd">            samples with shape `sample_shape x batch_shape x q x m`, and `obj` is a</span>
<span class="sd">            tensor of MC objective values with shape `sample_shape x batch_shape x q`.</span>
<span class="sd">        """</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
        <span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>

<div class="viewcode-block" id="MCAcquisitionFunction.forward"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.MCAcquisitionFunction.forward">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Takes in a `batch_shape x q x d` X Tensor of t-batches with `q` `d`-dim</span>
<span class="sd">        design points each, and returns a Tensor with shape `batch_shape'`, where</span>
<span class="sd">        `batch_shape'` is the broadcasted batch shape of model and input `X`. Should</span>
<span class="sd">        utilize the result of `set_X_pending` as needed to account for pending function</span>
<span class="sd">        evaluations.</span>
<span class="sd">        """</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div></div>


<div class="viewcode-block" id="SampleReductionProtocol"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.SampleReductionProtocol">[docs]</a><span class="k">class</span> <span class="nc">SampleReductionProtocol</span><span class="p">(</span><span class="n">Protocol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""For static type check of SampleReducingMCAcquisitionFunction's mc_reduction."""</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>


<div class="viewcode-block" id="SampleReducingMCAcquisitionFunction"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction">[docs]</a><span class="k">class</span> <span class="nc">SampleReducingMCAcquisitionFunction</span><span class="p">(</span><span class="n">MCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch acquisition function that reduces across samples and implements</span>
<span class="sd">    a general treatment of outcome constraints.</span>

<span class="sd">    This class's `forward` computes the - possibly constrained - acquisition value by</span>
<span class="sd">    (1) computing the unconstrained utility for each MC sample using `_sample_forward`,</span>
<span class="sd">    (2) weighing the utility values by the constraint indicator per MC sample, and</span>
<span class="sd">    (3) reducing (e.g. averaging) the weighted utility values over the MC dimension.</span>

<span class="sd">    NOTE: Do *NOT* override the `forward` method, unless you have thought about it well.</span>

<span class="sd">    `forward` is implemented generically to incorporate constraints in a principled way,</span>
<span class="sd">    and takes care of reducing over the Monte Carlo and batch dimensions via the</span>
<span class="sd">    `sample_reduction` and `q_reduction` arguments, which default to `torch.mean` and</span>
<span class="sd">    `torch.max`, respectively.</span>

<span class="sd">    In order to implement a custom SampleReducingMCAcquisitionFunction, we only need to</span>
<span class="sd">    implement the `_sample_forward(obj: Tensor) -&gt; Tensor` method, which maps objective</span>
<span class="sd">    samples to acquisition utility values without reducing the Monte Carlo and batch</span>
<span class="sd">    (i.e. q) dimensions (see details in the docstring of `_sample_forward`).</span>

<span class="sd">    A note on design choices:</span>

<span class="sd">    The primary purpose of `SampleReducingMCAcquisitionFunction`is to support outcome</span>
<span class="sd">    constraints. On the surface, designing a wrapper `ConstrainedMCAcquisitionFunction`</span>
<span class="sd">    could be an elegant solution to this end, but it would still require the acquisition</span>
<span class="sd">    functions to implement a `_sample_forward` method to weigh acquisition utilities at</span>
<span class="sd">    the sample level. Further, `qNoisyExpectedImprovement` is a special case that is</span>
<span class="sd">    hard to encompass in this pattern, since it requires the computation of the best</span>
<span class="sd">    *feasible* objective, which requires access to the constraint functions. However,</span>
<span class="sd">    if the constraints are stored in a wrapper class, they will be inaccessible to the</span>
<span class="sd">    forward pass. These problems are circumvented by the design of this class.</span>
<span class="sd">    """</span>

    <span class="n">_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># whether the acquisition utilities are in log-space</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_reduction</span><span class="p">:</span> <span class="n">SampleReductionProtocol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span>
        <span class="n">q_reduction</span><span class="p">:</span> <span class="n">SampleReductionProtocol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">amax</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Constructor of SampleReducingMCAcquisitionFunction.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            sampler: The sampler used to draw base samples. If not given,</span>
<span class="sd">                a sampler is generated using `get_sampler`.</span>
<span class="sd">                NOTE: For posteriors that do not support base samples,</span>
<span class="sd">                a sampler compatible with intended use case must be provided.</span>
<span class="sd">                See `ForkedRNGSampler` and `StochasticSampler` as examples.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A `PosteriorTransform` (optional).</span>
<span class="sd">            X_pending: A `batch_shape, m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            sample_reduction: A callable that takes in a `sample_shape x batch_shape`</span>
<span class="sd">                Tensor of acquisition utility values, a keyword-argument `dim` that</span>
<span class="sd">                specifies the sample dimensions to reduce over, and returns a</span>
<span class="sd">                `batch_shape`-dim Tensor of acquisition values.</span>
<span class="sd">            q_reduction: A callable that takes in a `sample_shape x batch_shape x q`</span>
<span class="sd">                Tensor of acquisition utility values, a keyword-argument `dim` that</span>
<span class="sd">                specifies the q dimension to reduce over (i.e. -1), and returns a</span>
<span class="sd">                `sample_shape x batch_shape`-dim Tensor of acquisition values.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are considered satisfied if the output is less than zero.</span>
<span class="sd">                NOTE: Constraint-weighting is only compatible with non-negative</span>
<span class="sd">                acquistion utilities, e.g. all improvement-based acquisition functions.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>
<span class="sd">            fat: Wether to apply a fat-tailed smooth approximation to the feasibility</span>
<span class="sd">                indicator or the canonical sigmoid approximation.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">ConstrainedMCObjective</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"ConstrainedMCObjective as well as constraints passed to constructor."</span>
                <span class="s2">"Choose one or the other, preferably the latter."</span>
            <span class="p">)</span>
        <span class="c1"># TODO: deprecate ConstrainedMCObjective</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Shall the need arise, sample_dim could be exposed in the constructor.</span>
        <span class="n">sample_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sample_reduction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">sample_reduction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">sample_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_q_reduction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">q_reduction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="n">constraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fat</span> <span class="o">=</span> <span class="n">fat</span>

<div class="viewcode-block" id="SampleReducingMCAcquisitionFunction.forward"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.SampleReducingMCAcquisitionFunction.forward">[docs]</a>    <span class="nd">@concatenate_pending_points</span>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Computes the acquisition value associated with the input `X`. Weighs the</span>
<span class="sd">        acquisition utility values by smoothed constraint indicators if `constraints`</span>
<span class="sd">        was passed to the constructor of the class. Applies `self.sample_reduction` and</span>
<span class="sd">        `self.q_reduction` to reduce over the Monte Carlo and batch (q) dimensions.</span>

<span class="sd">        NOTE: Do *NOT* override the `forward` method for a custom acquisition function.</span>
<span class="sd">        Instead, implement the `_sample_forward` method. See the docstring of this class</span>
<span class="sd">        for details.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d` Tensor of t-batches with `q` `d`-dim</span>
<span class="sd">                design points each.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor with shape `batch_shape'`, where `batch_shape'` is the broadcasted</span>
<span class="sd">            batch shape of model and input `X`.</span>
<span class="sd">        """</span>
        <span class="n">non_reduced_acqval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_reduced_forward</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_reduction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_q_reduction</span><span class="p">(</span><span class="n">non_reduced_acqval</span><span class="p">))</span></div>

    <span class="k">def</span> <span class="nf">_non_reduced_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Compute the constrained acquisition values at the MC-sample, q level.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d` Tensor of t-batches with `q` `d`-dim</span>
<span class="sd">                design points each.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor with shape `sample_sample x batch_shape x q`.</span>
<span class="sd">        """</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_samples_and_objectives</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">acqval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_forward</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>  <span class="c1"># `sample_sample x batch_shape x q`</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_constraints</span><span class="p">(</span><span class="n">acqval</span><span class="o">=</span><span class="n">acqval</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Evaluates the acquisition utility per MC sample based on objective value obj.</span>
<span class="sd">        Should utilize the result of `set_X_pending` as needed to account for pending</span>
<span class="sd">        function evaluations.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of acquisition utility values.</span>
<span class="sd">        """</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span>

    <span class="k">def</span> <span class="nf">_apply_constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">acqval</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Multiplies the acquisition utility by constraint indicators.</span>

<span class="sd">        Args:</span>
<span class="sd">            acqval: `sample_shape x batch_shape x q`-dim acquisition utility values.</span>
<span class="sd">            samples: `sample_shape x batch_shape x q x m`-dim posterior samples.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of acquisition utility values</span>
<span class="sd">                multiplied by a smoothed constraint indicator per sample.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log</span> <span class="ow">and</span> <span class="p">(</span><span class="n">acqval</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">"Constraint-weighting requires unconstrained "</span>
                    <span class="s2">"acquisition values to be non-negative."</span>
                <span class="p">)</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">compute_smoothed_feasibility_indicator</span><span class="p">(</span>
                <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
                <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
                <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_eta</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">,</span>
                <span class="n">fat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fat</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">acqval</span> <span class="o">=</span> <span class="n">acqval</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log</span> <span class="k">else</span> <span class="n">acqval</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">acqval</span></div>


<div class="viewcode-block" id="qExpectedImprovement"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.qExpectedImprovement">[docs]</a><span class="k">class</span> <span class="nc">qExpectedImprovement</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch Expected Improvement.</span>

<span class="sd">    This computes qEI by</span>
<span class="sd">    (1) sampling the joint posterior over q points</span>
<span class="sd">    (2) evaluating the improvement over the current best for each sample</span>
<span class="sd">    (3) maximizing over q</span>
<span class="sd">    (4) averaging over the samples</span>

<span class="sd">    `qEI(X) = E(max(max Y - best_f, 0)), Y ~ f(X), where X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; best_f = train_Y.max()[0]</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qEI = qExpectedImprovement(model, best_f, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qei = qEI(test_X)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">best_f</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""q-Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            best_f: The best objective value observed so far (assumed noiseless). Can be</span>
<span class="sd">                a `batch_shape`-shaped tensor, which in case of a batched model</span>
<span class="sd">                specifies potentially different values for each element of the batch.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are evaluated.</span>
<span class="sd">                Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending:  A `m x d`-dim Tensor of `m` design points that have been</span>
<span class="sd">                submitted for function evaluation but have not yet been evaluated.</span>
<span class="sd">                Concatenated into X upon forward call. Copied and set to have no</span>
<span class="sd">                gradient.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are considered satisfied if the output is less than zero.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"best_f"</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">best_f</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Evaluate qExpectedImprovement per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of improvement utility values.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_f</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="qNoisyExpectedImprovement"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.qNoisyExpectedImprovement">[docs]</a><span class="k">class</span> <span class="nc">qNoisyExpectedImprovement</span><span class="p">(</span>
    <span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">,</span> <span class="n">CachedCholeskyMCAcquisitionFunction</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch Noisy Expected Improvement.</span>

<span class="sd">    This function does not assume a `best_f` is known (which would require</span>
<span class="sd">    noiseless observations). Instead, it uses samples from the joint posterior</span>
<span class="sd">    over the `q` test points and previously observed points. The improvement</span>
<span class="sd">    over previously observed points is computed for each sample and averaged.</span>

<span class="sd">    `qNEI(X) = E(max(max Y - max Y_baseline, 0))`, where</span>
<span class="sd">    `(Y, Y_baseline) ~ f((X, X_baseline)), X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qNEI = qNoisyExpectedImprovement(model, train_X, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qnei = qNEI(test_X)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prune_baseline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">cache_root</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""q-Noisy Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            X_baseline: A `batch_shape x r x d`-dim Tensor of `r` design points</span>
<span class="sd">                that have already been observed. These points are considered as</span>
<span class="sd">                the potential best design point.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape x m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated. Concatenated into `X` upon</span>
<span class="sd">                forward call. Copied and set to have no gradient.</span>
<span class="sd">            prune_baseline: If True, remove points in `X_baseline` that are</span>
<span class="sd">                highly unlikely to be the best point. This can significantly</span>
<span class="sd">                improve performance and is generally recommended. In order to</span>
<span class="sd">                customize pruning parameters, instead manually call</span>
<span class="sd">                `botorch.acquisition.utils.prune_inferior_points` on `X_baseline`</span>
<span class="sd">                before instantiating the acquisition function.</span>
<span class="sd">            cache_root: A boolean indicating whether to cache the root</span>
<span class="sd">                decomposition over `X_baseline` and use low-rank updates.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are considered satisfied if the output is less than zero.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>

<span class="sd">        TODO: similar to qNEHVI, when we are using sequential greedy candidate</span>
<span class="sd">        selection, we could incorporate pending points X_baseline and compute</span>
<span class="sd">        the incremental qNEI from the new point. This would greatly increase</span>
<span class="sd">        efficiency for large batches.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prune_baseline</span><span class="p">:</span>
            <span class="n">X_baseline</span> <span class="o">=</span> <span class="n">prune_inferior_points</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
                <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
                <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
                <span class="n">marginalize_dim</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"marginalize_dim"</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"X_baseline"</span><span class="p">,</span> <span class="n">X_baseline</span><span class="p">)</span>
        <span class="c1"># registering buffers for _get_samples_and_objectives in the next `if` block</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"baseline_samples"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"baseline_obj"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">q_in</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="c1"># set baseline samples</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># this is _get_samples_and_objectives(X_baseline)</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                    <span class="n">X_baseline</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
                <span class="p">)</span>
                <span class="c1"># Note: The root decomposition is cached in two different places. It</span>
                <span class="c1"># may be confusing to have two different caches, but this is not</span>
                <span class="c1"># trivial to change since each is needed for a different reason:</span>
                <span class="c1"># - LinearOperator caching to `posterior.mvn` allows for reuse within</span>
                <span class="c1">#  this function, which may be helpful if the same root decomposition</span>
                <span class="c1">#  is produced by the calls to `self.base_sampler` and</span>
                <span class="c1">#  `self._cache_root_decomposition`.</span>
                <span class="c1"># - self._baseline_L allows a root decomposition to be persisted outside</span>
                <span class="c1">#   this method.</span>
                <span class="n">baseline_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
                <span class="n">baseline_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">)</span>

            <span class="c1"># We make a copy here because we will write an attribute `base_samples`</span>
            <span class="c1"># to `self.base_sampler.base_samples`, and we don't want to mutate</span>
            <span class="c1"># `self.sampler`.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_sampler</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span> <span class="o">=</span> <span class="n">baseline_samples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span> <span class="o">=</span> <span class="n">baseline_obj</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">"_baseline_best_f"</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                    <span class="n">samples</span><span class="o">=</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="n">baseline_obj</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_L</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_root_decomposition</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>

<div class="viewcode-block" id="qNoisyExpectedImprovement.compute_best_f"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.qNoisyExpectedImprovement.compute_best_f">[docs]</a>    <span class="k">def</span> <span class="nf">compute_best_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Computes the best (feasible) noisy objective value.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `sample_shape x batch_shape x q`-dim Tensor of objectives in forward.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x 1`-dim Tensor of best feasible objectives.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_best_f</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                <span class="n">samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span>
            <span class="p">)</span>
        <span class="c1"># ensuring shape, dtype, device compatibility with obj</span>
        <span class="n">n_sample_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">)</span>
        <span class="n">view_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">n_sample_dims</span><span class="p">],</span>  <span class="c1"># sample dimensions</span>
                <span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="n">val</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span>  <span class="c1"># pad to match obj</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">n_sample_dims</span><span class="p">:],</span>  <span class="c1"># the rest</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Evaluate qNoisyExpectedImprovement per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of noisy improvement values.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_best_f</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_samples_and_objectives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Compute samples at new points, using the cached root decomposition.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple `(samples, obj)`, where `samples` is a tensor of posterior</span>
<span class="sd">            samples with shape `sample_shape x batch_shape x q x m`, and `obj` is a</span>
<span class="sd">            tensor of MC objective values with shape `sample_shape x batch_shape x q`.</span>
<span class="sd">        """</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">X</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># TODO: Implement more efficient way to compute posterior over both training and</span>
        <span class="c1"># test points in GPyTorch (https://github.com/cornellius-gp/gpytorch/issues/567)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">X_full</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">samples_full</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="n">samples_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:,</span> <span class="p">:]</span>
            <span class="n">obj_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples_full</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">)</span>
            <span class="c1"># assigning baseline buffers so `best_f` can be computed in _sample_forward</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span><span class="p">,</span> <span class="n">obj</span> <span class="o">=</span> <span class="n">obj_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="n">q</span><span class="p">],</span> <span class="n">obj_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span> <span class="o">=</span> <span class="n">samples_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="n">q</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

        <span class="c1"># handle one-to-many input transforms</span>
        <span class="n">n_plus_q</span> <span class="o">=</span> <span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">n_w</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_extended_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="n">n_plus_q</span>
        <span class="n">q_in</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">n_w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_sampler</span><span class="p">(</span><span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">,</span> <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_f_X_samples</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:,</span> <span class="p">:])</span>
        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

    <span class="k">def</span> <span class="nf">_compute_best_feasible_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Computes best feasible objective value from samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: `sample_shape x batch_shape x q x m`-dim posterior samples.</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x 1`-dim Tensor of best feasible objectives.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">compute_best_feasible_objective</span><span class="p">(</span>
            <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
            <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_baseline</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="qProbabilityOfImprovement"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.qProbabilityOfImprovement">[docs]</a><span class="k">class</span> <span class="nc">qProbabilityOfImprovement</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch Probability of Improvement.</span>

<span class="sd">    Estimates the probability of improvement over the current best observed</span>
<span class="sd">    value by sampling from the joint posterior distribution of the q-batch.</span>
<span class="sd">    MC-based estimates of a probability involves taking expectation of an</span>
<span class="sd">    indicator function; to support auto-differntiation, the indicator is</span>
<span class="sd">    replaced with a sigmoid function with temperature parameter `tau`.</span>

<span class="sd">    `qPI(X) = P(max Y &gt;= best_f), Y ~ f(X), X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; best_f = train_Y.max()[0]</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qPI = qProbabilityOfImprovement(model, best_f, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qpi = qPI(test_X)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">best_f</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tau</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""q-Probability of Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            best_f: The best objective value observed so far (assumed noiseless). Can</span>
<span class="sd">                be a `batch_shape`-shaped tensor, which in case of a batched model</span>
<span class="sd">                specifies potentially different values for each element of the batch.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending:  A `m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.  Concatenated into X upon</span>
<span class="sd">                forward call.  Copied and set to have no gradient.</span>
<span class="sd">            tau: The temperature parameter used in the sigmoid approximation</span>
<span class="sd">                of the step function. Smaller values yield more accurate</span>
<span class="sd">                approximations of the function, but result in gradients</span>
<span class="sd">                estimates with higher variance.</span>
<span class="sd">            constraints: A list of constraint callables which map posterior samples to</span>
<span class="sd">                a scalar. The associated constraint is considered satisfied if this</span>
<span class="sd">                scalar is less than zero.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">best_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">best_f</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># adding batch dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"best_f"</span><span class="p">,</span> <span class="n">best_f</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"tau"</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Evaluate qProbabilityOfImprovement per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of improvement indicators.</span>
<span class="sd">        """</span>
        <span class="n">improvement</span> <span class="o">=</span> <span class="n">obj</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_f</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">improvement</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span></div>


<div class="viewcode-block" id="qSimpleRegret"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.qSimpleRegret">[docs]</a><span class="k">class</span> <span class="nc">qSimpleRegret</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch Simple Regret.</span>

<span class="sd">    Samples from the joint posterior over the q-batch and computes the simple regret.</span>

<span class="sd">    `qSR(X) = E(max Y), Y ~ f(X), X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qSR = qSimpleRegret(model, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qsr = qSR(test_X)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Evaluate qSimpleRegret per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of simple regret values.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">obj</span></div>


<div class="viewcode-block" id="qUpperConfidenceBound"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.monte_carlo.qUpperConfidenceBound">[docs]</a><span class="k">class</span> <span class="nc">qUpperConfidenceBound</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch Upper Confidence Bound.</span>

<span class="sd">    Uses a reparameterization to extend UCB to qUCB for q &gt; 1 (See Appendix A</span>
<span class="sd">    of [Wilson2017reparam].)</span>

<span class="sd">    `qUCB = E(max(mu + |Y_tilde - mu|))`, where `Y_tilde ~ N(mu, beta pi/2 Sigma)`</span>
<span class="sd">    and `f(X)` has distribution `N(mu, Sigma)`.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qUCB = qUpperConfidenceBound(model, 0.1, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qucb = qUCB(test_X)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""q-Upper Confidence Bound.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            beta: Controls tradeoff between mean and standard deviation in UCB.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape x m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation but have not yet</span>
<span class="sd">                been evaluated. Concatenated into X upon forward call. Copied and set to</span>
<span class="sd">                have no gradient.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_prime</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">beta</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Evaluate qUpperConfidenceBound per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of acquisition values.</span>
<span class="sd">        """</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_prime</span> <span class="o">*</span> <span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span></div>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../index.html">Documentation overview</a><ul>
<li><a href="../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/latest/" class="nav-home"><img src="/v/latest/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/latest/docs/introduction">Introduction</a><a href="/v/latest/docs/getting_started">Getting Started</a><a href="/v/latest/tutorials/">Tutorials</a><a href="/v/latest/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/latest/img/oss_logo.png" alt="Meta Open Source" width="300" height="25"/></a><section class="copyright"> Copyright © 2023 Meta Platforms, Inc</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/latest/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div></body></html>