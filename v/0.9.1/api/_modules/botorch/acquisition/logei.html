<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/0.9.1/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/0.9.1/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/0.9.1/img/botorch.png"/><link rel="shortcut icon" href="/v/0.9.1/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CXN3PGE3CC"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'G-CXN3PGE3CC');
            </script><link rel="stylesheet" href="/v/0.9.1/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/0.9.1/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/0.9.1/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/0.9.1/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/0.9.1/css/main.css"/><script src="/v/0.9.1/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/0.9.1/"><img class="logo" src="/v/0.9.1/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/0.9.1/versions"><h3>0.9.1</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/0.9.1/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/0.9.1/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/0.9.1/api/" target="_self">API Reference</a></li><li class=""><a href="/v/0.9.1/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for botorch.acquisition.logei</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">"""</span>
<span class="sd">Batch implementations of the LogEI family of improvements-based acquisition functions.</span>
<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">TypeVar</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.cached_cholesky</span> <span class="kn">import</span> <span class="n">CachedCholeskyMCAcquisitionFunction</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.monte_carlo</span> <span class="kn">import</span> <span class="n">SampleReducingMCAcquisitionFunction</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.objective</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConstrainedMCObjective</span><span class="p">,</span>
    <span class="n">MCAcquisitionObjective</span><span class="p">,</span>
    <span class="n">PosteriorTransform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_best_feasible_objective</span><span class="p">,</span>
    <span class="n">prune_inferior_points</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.exceptions.errors</span> <span class="kn">import</span> <span class="n">BotorchError</span>
<span class="kn">from</span> <span class="nn">botorch.models.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.base</span> <span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span> <span class="nn">botorch.utils.safe_math</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">fatmax</span><span class="p">,</span>
    <span class="n">log_fatplus</span><span class="p">,</span>
    <span class="n">log_softplus</span><span class="p">,</span>
    <span class="n">logmeanexp</span><span class="p">,</span>
    <span class="n">smooth_amax</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.utils.transforms</span> <span class="kn">import</span> <span class="n">match_batch_shape</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="sd">"""</span>
<span class="sd">NOTE: On the default temperature parameters:</span>

<span class="sd">tau_relu: It is generally important to set `tau_relu` to be very small, in particular,</span>
<span class="sd">smaller than the expected improvement value. Otherwise, the optimization can stagnate.</span>
<span class="sd">By setting `tau_relu=1e-6` by default, stagnation is exceedingly unlikely to occur due</span>
<span class="sd">to the smooth ReLU approximation for practical applications of BO.</span>
<span class="sd">IDEA: We could consider shrinking `tau_relu` with the progression of the optimization.</span>

<span class="sd">tau_max: This is only relevant for the batch (`q &gt; 1`) case, and `tau_max=1e-2` is</span>
<span class="sd">sufficient to get a good approximation to the maximum improvement in the batch of</span>
<span class="sd">candidates. If `fat=False`, the smooth approximation to the maximum can saturate</span>
<span class="sd">numerically. It is therefore recommended to use `fat=True` when optimizing batches</span>
<span class="sd">of `q &gt; 1` points.</span>
<span class="sd">"""</span>
<span class="n">TAU_RELU</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">TAU_MAX</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">FloatOrTensor</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">"FloatOrTensor"</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LogImprovementMCAcquisitionFunction</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    Abstract base class for Monte-Carlo-based batch LogEI acquisition functions.</span>

<span class="sd">    :meta private:</span>
<span class="sd">    """</span>

    <span class="n">_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">tau_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_MAX</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            sampler: The sampler used to draw base samples. If not given,</span>
<span class="sd">                a sampler is generated using `get_sampler`.</span>
<span class="sd">                NOTE: For posteriors that do not support base samples,</span>
<span class="sd">                a sampler compatible with intended use case must be provided.</span>
<span class="sd">                See `ForkedRNGSampler` and `StochasticSampler` as examples.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape, m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. See the docs of</span>
<span class="sd">                `compute_(log_)constraint_indicator` for more details on this parameter.</span>
<span class="sd">            fat: Toggles the logarithmic / linear asymptotic behavior of the smooth</span>
<span class="sd">                approximation to the ReLU.</span>
<span class="sd">            tau_max: Temperature parameter controlling the sharpness of the</span>
<span class="sd">                approximation to the `max` operator over the `q` candidate points.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">ConstrainedMCObjective</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">BotorchError</span><span class="p">(</span>
                <span class="s2">"Log-Improvement should not be used with `ConstrainedMCObjective`."</span>
                <span class="s2">"Please pass the `constraints` directly to the constructor of the "</span>
                <span class="s2">"acquisition function."</span>
            <span class="p">)</span>
        <span class="n">q_reduction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">fatmax</span> <span class="k">if</span> <span class="n">fat</span> <span class="k">else</span> <span class="n">smooth_amax</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="n">tau_max</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">sample_reduction</span><span class="o">=</span><span class="n">logmeanexp</span><span class="p">,</span>
            <span class="n">q_reduction</span><span class="o">=</span><span class="n">q_reduction</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="n">fat</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_max</span> <span class="o">=</span> <span class="n">tau_max</span>


<div class="viewcode-block" id="qLogExpectedImprovement"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.qLogExpectedImprovement">[docs]</a><span class="k">class</span> <span class="nc">qLogExpectedImprovement</span><span class="p">(</span><span class="n">LogImprovementMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch Log Expected Improvement.</span>

<span class="sd">    This computes qLogEI by</span>
<span class="sd">    (1) sampling the joint posterior over q points,</span>
<span class="sd">    (2) evaluating the smoothed log improvement over the current best for each sample,</span>
<span class="sd">    (3) smoothly maximizing over q, and</span>
<span class="sd">    (4) averaging over the samples in log space.</span>

<span class="sd">    `qLogEI(X) ~ log(qEI(X)) = log(E(max(max Y - best_f, 0)))`,</span>

<span class="sd">    where `Y ~ f(X)`, and `X = (x_1,...,x_q)`.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; best_f = train_Y.max()[0]</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qLogEI = qLogExpectedImprovement(model, best_f, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qei = qLogEI(test_X)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">best_f</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">tau_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_MAX</span><span class="p">,</span>
        <span class="n">tau_relu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_RELU</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""q-Log Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            best_f: The best objective value observed so far (assumed noiseless). Can be</span>
<span class="sd">                a `batch_shape`-shaped tensor, which in case of a batched model</span>
<span class="sd">                specifies potentially different values for each element of the batch.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are evaluated.</span>
<span class="sd">                Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending:  A `m x d`-dim Tensor of `m` design points that have been</span>
<span class="sd">                submitted for function evaluation but have not yet been evaluated.</span>
<span class="sd">                Concatenated into `X` upon forward call. Copied and set to have no</span>
<span class="sd">                gradient.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. See the docs of</span>
<span class="sd">                `compute_(log_)smoothed_constraint_indicator` for details.</span>
<span class="sd">            fat: Toggles the logarithmic / linear asymptotic behavior of the smooth</span>
<span class="sd">                approximation to the ReLU.</span>
<span class="sd">            tau_max: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to max.</span>
<span class="sd">            tau_relu: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to ReLU.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
            <span class="n">tau_max</span><span class="o">=</span><span class="n">check_tau</span><span class="p">(</span><span class="n">tau_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"tau_max"</span><span class="p">),</span>
            <span class="n">fat</span><span class="o">=</span><span class="n">fat</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"best_f"</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">best_f</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span> <span class="o">=</span> <span class="n">check_tau</span><span class="p">(</span><span class="n">tau_relu</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"tau_relu"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Evaluate qLogExpectedImprovement on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `mc_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `mc_shape x batch_shape x q`-dim Tensor of expected improvement values.</span>
<span class="sd">        """</span>
        <span class="n">li</span> <span class="o">=</span> <span class="n">_log_improvement</span><span class="p">(</span>
            <span class="n">Y</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">best_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">best_f</span><span class="p">,</span>
            <span class="n">tau</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fat</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">li</span></div>


<div class="viewcode-block" id="qLogNoisyExpectedImprovement"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.qLogNoisyExpectedImprovement">[docs]</a><span class="k">class</span> <span class="nc">qLogNoisyExpectedImprovement</span><span class="p">(</span>
    <span class="n">LogImprovementMCAcquisitionFunction</span><span class="p">,</span> <span class="n">CachedCholeskyMCAcquisitionFunction</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""MC-based batch Log Noisy Expected Improvement.</span>

<span class="sd">    This function does not assume a `best_f` is known (which would require</span>
<span class="sd">    noiseless observations). Instead, it uses samples from the joint posterior</span>
<span class="sd">    over the `q` test points and previously observed points. A smooth approximation</span>
<span class="sd">    to the canonical improvement over previously observed points is computed</span>
<span class="sd">    for each sample and the logarithm of the average is returned.</span>

<span class="sd">    `qLogNEI(X) ~ log(qNEI(X)) = Log E(max(max Y - max Y_baseline, 0))`, where</span>
<span class="sd">    `(Y, Y_baseline) ~ f((X, X_baseline)), X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qLogNEI = qLogNoisyExpectedImprovement(model, train_X, sampler)</span>
<span class="sd">        &gt;&gt;&gt; acqval = qLogNEI(test_X)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">prune_baseline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cache_root</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">tau_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_MAX</span><span class="p">,</span>
        <span class="n">tau_relu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">TAU_RELU</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""q-Noisy Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            X_baseline: A `batch_shape x r x d`-dim Tensor of `r` design points</span>
<span class="sd">                that have already been observed. These points are considered as</span>
<span class="sd">                the potential best design point.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape x m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated. Concatenated into `X` upon</span>
<span class="sd">                forward call. Copied and set to have no gradient.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. See the docs of</span>
<span class="sd">                `compute_(log_)smoothed_constraint_indicator` for details.</span>
<span class="sd">            fat: Toggles the logarithmic / linear asymptotic behavior of the smooth</span>
<span class="sd">                approximation to the ReLU.</span>
<span class="sd">            prune_baseline: If True, remove points in `X_baseline` that are</span>
<span class="sd">                highly unlikely to be the best point. This can significantly</span>
<span class="sd">                improve performance and is generally recommended. In order to</span>
<span class="sd">                customize pruning parameters, instead manually call</span>
<span class="sd">                `botorch.acquisition.utils.prune_inferior_points` on `X_baseline`</span>
<span class="sd">                before instantiating the acquisition function.</span>
<span class="sd">            cache_root: A boolean indicating whether to cache the root</span>
<span class="sd">                decomposition over `X_baseline` and use low-rank updates.</span>
<span class="sd">            tau_max: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to max.</span>
<span class="sd">            tau_relu: Temperature parameter controlling the sharpness of the smooth</span>
<span class="sd">                approximations to ReLU.</span>
<span class="sd">            kwargs: Here for qNEI for compatibility.</span>

<span class="sd">        TODO: similar to qNEHVI, when we are using sequential greedy candidate</span>
<span class="sd">        selection, we could incorporate pending points X_baseline and compute</span>
<span class="sd">        the incremental q(Log)NEI from the new point. This would greatly increase</span>
<span class="sd">        efficiency for large batches.</span>
<span class="sd">        """</span>
        <span class="c1"># TODO: separate out baseline variables initialization and other functions</span>
        <span class="c1"># in qNEI to avoid duplication of both code and work at runtime.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="n">fat</span><span class="p">,</span>
            <span class="n">tau_max</span><span class="o">=</span><span class="n">tau_max</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span> <span class="o">=</span> <span class="n">tau_relu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_baseline</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">X_baseline</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">prune_baseline</span><span class="o">=</span><span class="n">prune_baseline</span><span class="p">,</span>
            <span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Evaluate qLogNoisyExpectedImprovement per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `mc_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of log noisy expected smoothed</span>
<span class="sd">            improvement values.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">_log_improvement</span><span class="p">(</span>
            <span class="n">Y</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">best_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_best_f</span><span class="p">(</span><span class="n">obj</span><span class="p">),</span>
            <span class="n">tau</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tau_relu</span><span class="p">,</span>
            <span class="n">fat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fat</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_baseline</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prune_baseline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cache_root</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># setup of CachedCholeskyMCAcquisitionFunction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prune_baseline</span><span class="p">:</span>
            <span class="n">X_baseline</span> <span class="o">=</span> <span class="n">prune_inferior_points</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
                <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
                <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
                <span class="n">marginalize_dim</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"marginalize_dim"</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"X_baseline"</span><span class="p">,</span> <span class="n">X_baseline</span><span class="p">)</span>
        <span class="c1"># registering buffers for _get_samples_and_objectives in the next `if` block</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"baseline_samples"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"baseline_obj"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">q_in</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="c1"># set baseline samples</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># this is _get_samples_and_objectives(X_baseline)</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                    <span class="n">X_baseline</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
                <span class="p">)</span>
                <span class="c1"># Note: The root decomposition is cached in two different places. It</span>
                <span class="c1"># may be confusing to have two different caches, but this is not</span>
                <span class="c1"># trivial to change since each is needed for a different reason:</span>
                <span class="c1"># - LinearOperator caching to `posterior.mvn` allows for reuse within</span>
                <span class="c1">#   this function, which may be helpful if the same root decomposition</span>
                <span class="c1">#   is produced by the calls to `self.base_sampler` and</span>
                <span class="c1">#   `self._cache_root_decomposition`.</span>
                <span class="c1"># - self._baseline_L allows a root decomposition to be persisted outside</span>
                <span class="c1">#   this method.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">)</span>

            <span class="c1"># We make a copy here because we will write an attribute `base_samples`</span>
            <span class="c1"># to `self.base_sampler.base_samples`, and we don't want to mutate</span>
            <span class="c1"># `self.sampler`.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_sampler</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">"_baseline_best_f"</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                    <span class="n">samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_L</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_root_decomposition</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>

<div class="viewcode-block" id="qLogNoisyExpectedImprovement.compute_best_f"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.qLogNoisyExpectedImprovement.compute_best_f">[docs]</a>    <span class="k">def</span> <span class="nf">compute_best_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Computes the best (feasible) noisy objective value.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `sample_shape x batch_shape x q`-dim Tensor of objectives in forward.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x 1`-dim Tensor of best feasible objectives.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_best_f</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                <span class="n">samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span>
            <span class="p">)</span>
        <span class="c1"># ensuring shape, dtype, device compatibility with obj</span>
        <span class="n">n_sample_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">)</span>
        <span class="n">view_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">n_sample_dims</span><span class="p">],</span>  <span class="c1"># sample dimensions</span>
                <span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="n">val</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span>  <span class="c1"># pad to match obj</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">n_sample_dims</span><span class="p">:],</span>  <span class="c1"># the rest</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_get_samples_and_objectives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Compute samples at new points, using the cached root decomposition.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple `(samples, obj)`, where `samples` is a tensor of posterior</span>
<span class="sd">            samples with shape `sample_shape x batch_shape x q x m`, and `obj` is a</span>
<span class="sd">            tensor of MC objective values with shape `sample_shape x batch_shape x q`.</span>
<span class="sd">        """</span>
        <span class="n">n_baseline</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">X</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># TODO: Implement more efficient way to compute posterior over both training and</span>
        <span class="c1"># test points in GPyTorch (https://github.com/cornellius-gp/gpytorch/issues/567)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">X_full</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">samples_full</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
            <span class="n">obj_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples_full</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">)</span>
            <span class="c1"># assigning baseline buffers so `best_f` can be computed in _sample_forward</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">samples_full</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="n">n_baseline</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span><span class="p">,</span> <span class="n">obj</span> <span class="o">=</span> <span class="n">obj_full</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="n">n_baseline</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

        <span class="c1"># handle one-to-many input transforms</span>
        <span class="n">n_plus_q</span> <span class="o">=</span> <span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">n_w</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_extended_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="n">n_plus_q</span>
        <span class="n">q_in</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">n_w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_sampler</span><span class="p">(</span><span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">,</span> <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_f_X_samples</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:,</span> <span class="p">:])</span>
        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

    <span class="k">def</span> <span class="nf">_compute_best_feasible_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">compute_best_feasible_objective</span><span class="p">(</span>
            <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
            <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_baseline</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span>
        <span class="p">)</span></div>


<span class="sd">"""</span>
<span class="sd">###################################### utils ##########################################</span>
<span class="sd">"""</span>


<span class="k">def</span> <span class="nf">_log_improvement</span><span class="p">(</span>
    <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">best_f</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">tau</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Computes the logarithm of the softplus-smoothed improvement, i.e.</span>
<span class="sd">    `log_softplus(Y - best_f, beta=(1 / tau))`.</span>
<span class="sd">    Note that softplus is an approximation to the regular ReLU objective whose maximum</span>
<span class="sd">    pointwise approximation error is linear with respect to tau as tau goes to zero.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj: `mc_samples x batch_shape x q`-dim Tensor of output samples.</span>
<span class="sd">        best_f: Best previously observed objective value(s), broadcastable with `obj`.</span>
<span class="sd">        tau: Temperature parameter for smooth approximation of ReLU.</span>
<span class="sd">            as `tau -&gt; 0`, maximum pointwise approximation error is linear w.r.t. `tau`.</span>
<span class="sd">        fat: Toggles the logarithmic / linear asymptotic behavior of the</span>
<span class="sd">            smooth approximation to ReLU.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `mc_samples x batch_shape x q`-dim Tensor of improvement values.</span>
<span class="sd">    """</span>
    <span class="n">log_soft_clamp</span> <span class="o">=</span> <span class="n">log_fatplus</span> <span class="k">if</span> <span class="n">fat</span> <span class="k">else</span> <span class="n">log_softplus</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">best_f</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_soft_clamp</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>  <span class="c1"># ~ ((Y - best_f) / Y_std).clamp(0)</span>


<div class="viewcode-block" id="check_tau"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.logei.check_tau">[docs]</a><span class="k">def</span> <span class="nf">check_tau</span><span class="p">(</span><span class="n">tau</span><span class="p">:</span> <span class="n">FloatOrTensor</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatOrTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Checks the validity of the tau arguments of the functions below, and returns</span>
<span class="sd">    `tau` if it is valid."""</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">tau</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">" is not a scalar: </span><span class="si">{</span><span class="n">tau</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="si">= }</span><span class="s2">."</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">tau</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">" is non-positive: </span><span class="si">{</span><span class="n">tau</span><span class="w"> </span><span class="si">= }</span><span class="s2">."</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tau</span></div>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../index.html">Documentation overview</a><ul>
<li><a href="../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/0.9.1/" class="nav-home"><img src="/v/0.9.1/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/0.9.1/docs/introduction">Introduction</a><a href="/v/0.9.1/docs/getting_started">Getting Started</a><a href="/v/0.9.1/tutorials/">Tutorials</a><a href="/v/0.9.1/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/0.9.1/img/oss_logo.png" alt="Meta Open Source" width="300" height="25"/></a><section class="copyright"> Copyright © 2023 Meta Platforms, Inc</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/0.9.1/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div></body></html>