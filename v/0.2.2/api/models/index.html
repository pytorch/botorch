<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/0.2.2/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/0.2.2/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/0.2.2/img/botorch.png"/><link rel="shortcut icon" href="/v/0.2.2/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-2', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/v/0.2.2/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/0.2.2/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/0.2.2/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/0.2.2/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/0.2.2/css/main.css"/><script src="/v/0.2.2/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/0.2.2/"><img class="logo" src="/v/0.2.2/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/0.2.2/versions"><h3>0.2.2</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/0.2.2/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/0.2.2/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/0.2.2/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="module-botorch.models">
<span id="botorch-models"></span><h1>botorch.models<a class="headerlink" href="#module-botorch.models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="model-apis">
<h2>Model APIs<a class="headerlink" href="#model-apis" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-botorch.models.model">
<span id="abstract-model-api"></span><h3>Abstract Model API<a class="headerlink" href="#module-botorch.models.model" title="Permalink to this headline">¶</a></h3>
<p>Abstract base module for all BoTorch models.</p>
<dl class="class">
<dt id="botorch.models.model.Model">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.model.</code><code class="sig-name descname">Model</code><a class="reference internal" href="_modules/botorch/models/model.html#Model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for BoTorch models.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.model.Model.posterior">
<em class="property">abstract </em><code class="sig-name descname">posterior</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">output_indices=None</em>, <em class="sig-param">observation_noise=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model.Model.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>b x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of the
feature space, <cite>q</cite> is the number of points considered jointly,
and <cite>b</cite> is the batch dimension.</p></li>
<li><p><strong>output_indices</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, add observation noise to the posterior.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>Posterior</cite> object, representing a batch of <cite>b</cite> joint distributions
over <cite>q</cite> points and <cite>m</cite> outputs each.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.model.Model.num_outputs">
<em class="property">property </em><code class="sig-name descname">num_outputs</code><a class="headerlink" href="#botorch.models.model.Model.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of outputs of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.model.Model.subset_output">
<code class="sig-name descname">subset_output</code><span class="sig-paren">(</span><em class="sig-param">idcs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.subset_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model.Model.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>Model</cite> object of the same type and with the same parameters as
the current model, subset to the specified output indices.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.model.Model.condition_on_observations">
<code class="sig-name descname">condition_on_observations</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.condition_on_observations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model.Model.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, it is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.model.Model.fantasize">
<code class="sig-name descname">fantasize</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">sampler</em>, <em class="sig-param">observation_noise=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model.html#Model.fantasize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model.Model.fantasize" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a fantasy model.</p>
<p>Constructs a fantasy model in the following fashion:
(1) compute the model posterior at <cite>X</cite> (including observation noise if
<cite>observation_noise=True</cite>).
(2) sample from this posterior (using <cite>sampler</cite>) to generate “fake”
observations.
(3) condition the model on the new fake observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.samplers.MCSampler" title="botorch.sampling.samplers.MCSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSampler</span></code></a>) – The sampler used for sampling from the posterior at <cite>X</cite>.</p></li>
<li><p><strong>observation_noise</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, include observation noise.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The constructed fantasy model.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.gpytorch">
<span id="gpytorch-model-api"></span><h3>GPyTorch Model API<a class="headerlink" href="#module-botorch.models.gpytorch" title="Permalink to this headline">¶</a></h3>
<p>Abstract model class for all GPyTorch-based botorch models.</p>
<p>To implement your own, simply inherit from both the provided classes and a
GPyTorch Model class such as an ExactGP.</p>
<dl class="class">
<dt id="botorch.models.gpytorch.GPyTorchModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gpytorch.</code><code class="sig-name descname">GPyTorchModel</code><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.model.Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for models based on GPyTorch models.</p>
<p>The easiest way to use this is to subclass a model from a GPyTorch model
class (e.g. an <cite>ExactGP</cite>) and this <cite>GPyTorchModel</cite>. See e.g. <cite>SingleTaskGP</cite>.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.gpytorch.GPyTorchModel.num_outputs">
<em class="property">property </em><code class="sig-name descname">num_outputs</code><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of outputs of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gpytorch.GPyTorchModel.posterior">
<code class="sig-name descname">posterior</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">observation_noise=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel.posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>observation_noise</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q</cite>).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchPosterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>GPyTorchPosterior</cite> object, representing a batch of <cite>b</cite> joint
distributions over <cite>q</cite> points. Includes observation noise if
specified.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gpytorch.GPyTorchModel.condition_on_observations">
<code class="sig-name descname">condition_on_observations</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#GPyTorchModel.condition_on_observations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.GPyTorchModel.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape’ x n x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gpytorch.</code><code class="sig-name descname">BatchedMultiOutputGPyTorchModel</code><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.GPyTorchModel</span></code></a></p>
<p>Base class for batched multi-output GPyTorch models with independent outputs.</p>
<p>This model should be used when the same training data is used for all outputs.
Outputs are modeled independently by using a different batch for each output.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.get_batch_dimensions">
<em class="property">static </em><code class="sig-name descname">get_batch_dimensions</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.get_batch_dimensions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.get_batch_dimensions" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the raw batch shape and output-augmented batch shape of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x d</cite> or <cite>batch_shape x n x d</cite> (batch mode) tensor of training
features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Size</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Size</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>The <cite>input_batch_shape</cite></p></li>
<li><p>The output-augmented batch shape: <cite>input_batch_shape x (m)</cite></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.posterior">
<code class="sig-name descname">posterior</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">output_indices=None</em>, <em class="sig-param">observation_noise=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>output_indices</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q x m</cite>).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchPosterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes observation noise if specified.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.condition_on_observations">
<code class="sig-name descname">condition_on_observations</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.condition_on_observations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>m</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>BatchedMultiOutputGPyTorchModel</cite> object of the same type with
<cite>n + n’</cite> training examples, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.subset_output">
<code class="sig-name descname">subset_output</code><span class="sig-paren">(</span><em class="sig-param">idcs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#BatchedMultiOutputGPyTorchModel.subset_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The current model, subset to the specified output indices.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.gpytorch.ModelListGPyTorchModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gpytorch.</code><code class="sig-name descname">ModelListGPyTorchModel</code><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.GPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for models based on multi-output GPyTorch models.</p>
<p>This is meant to be used with a gpytorch ModelList wrapper for independent
evaluation of submodels.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.gpytorch.ModelListGPyTorchModel.posterior">
<code class="sig-name descname">posterior</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">output_indices=None</em>, <em class="sig-param">observation_noise=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel.posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>b x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of the
feature space, <cite>q</cite> is the number of points considered jointly,
and <cite>b</cite> is the batch dimension.</p></li>
<li><p><strong>output_indices</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – If True, add the observation noise from the
respective likelihoods to the posterior. If a Tensor of shape
<cite>(batch_shape) x q x m</cite>, use it directly as the observation
noise (with <cite>observation_noise[…,i]</cite> added to the posterior
of the <cite>i</cite>-th model).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchPosterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes measurement noise if
<cite>observation_noise</cite> is specified.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gpytorch.ModelListGPyTorchModel.condition_on_observations">
<code class="sig-name descname">condition_on_observations</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#ModelListGPyTorchModel.condition_on_observations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.ModelListGPyTorchModel.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape’ x n x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="botorch.models.gpytorch.ModelListGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelListGPyTorchModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>Model</cite> object of the same type, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.gpytorch.MultiTaskGPyTorchModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gpytorch.</code><code class="sig-name descname">MultiTaskGPyTorchModel</code><a class="reference internal" href="_modules/botorch/models/gpytorch.html#MultiTaskGPyTorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.GPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for multi-task models baed on GPyTorch models.</p>
<p>This class provides the <cite>posterior</cite> method to models that implement a
“long-format” multi-task GP in the style of <cite>MultiTaskGP</cite>.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.gpytorch.MultiTaskGPyTorchModel.posterior">
<code class="sig-name descname">posterior</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">output_indices=None</em>, <em class="sig-param">observation_noise=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gpytorch.html#MultiTaskGPyTorchModel.posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>q x d</cite> or <cite>batch_shape x q x d</cite> (batch mode) tensor, where <cite>d</cite> is the
dimension of the feature space (not including task indices) and
<cite>q</cite> is the number of points considered jointly.</p></li>
<li><p><strong>output_indices</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – If True, add observation noise from the respective
likelihoods. If a Tensor, specifies the observation noise levels
to add.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.gpytorch.GPyTorchPosterior" title="botorch.posteriors.gpytorch.GPyTorchPosterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchPosterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite>. Includes measurement noise if
<cite>observation_noise</cite> is specified.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.deterministic">
<span id="deterministic-model-api"></span><h3>Deterministic Model API<a class="headerlink" href="#module-botorch.models.deterministic" title="Permalink to this headline">¶</a></h3>
<p>Deterministic Models. Simple wrappers that allow the usage of deterministic
mappings via the BoTorch Model and Posterior APIs. Useful e.g. for defining
known cost functions for cost-aware acquisition utilities.</p>
<dl class="class">
<dt id="botorch.models.deterministic.DeterministicModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.deterministic.</code><code class="sig-name descname">DeterministicModel</code><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.model.Model" title="botorch.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.model.Model</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for deterministic models.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.deterministic.DeterministicModel.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.deterministic.DeterministicModel.num_outputs">
<em class="property">property </em><code class="sig-name descname">num_outputs</code><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.num_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of outputs of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.deterministic.DeterministicModel.posterior">
<code class="sig-name descname">posterior</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">output_indices=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#DeterministicModel.posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.DeterministicModel.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) posterior at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.deterministic.DeterministicPosterior" title="botorch.posteriors.deterministic.DeterministicPosterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">DeterministicPosterior</span></code></a></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.deterministic.GenericDeterministicModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.deterministic.</code><code class="sig-name descname">GenericDeterministicModel</code><span class="sig-paren">(</span><em class="sig-param">f</em>, <em class="sig-param">num_outputs=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.deterministic.DeterministicModel</span></code></a></p>
<p>A generic deterministic model constructed from a callable.</p>
<p>A generic deterministic model constructed from a callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A callable mapping a <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>
to a <cite>batch_shape x n x m</cite>-dimensional output tensor (the
outcome dimension <cite>m</cite> must be explicit, even if <cite>m=1</cite>).</p></li>
<li><p><strong>num_outputs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of outputs <cite>m</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.deterministic.GenericDeterministicModel.subset_output">
<code class="sig-name descname">subset_output</code><span class="sig-paren">(</span><em class="sig-param">idcs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel.subset_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.deterministic.GenericDeterministicModel" title="botorch.models.deterministic.GenericDeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericDeterministicModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The current model, subset to the specified output indices.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.deterministic.GenericDeterministicModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#GenericDeterministicModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.GenericDeterministicModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.deterministic.AffineDeterministicModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.deterministic.</code><code class="sig-name descname">AffineDeterministicModel</code><span class="sig-paren">(</span><em class="sig-param">a</em>, <em class="sig-param">b=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.deterministic.DeterministicModel</span></code></a></p>
<p>An affine deterministic model.</p>
<p>Affine deterministic model from weights and offset terms.</p>
<p>A simple model of the form</p>
<blockquote>
<div><p>y[…, m] = b[m] + sum_{i=1}^d a[i, m] * X[…, i]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>d x m</cite>-dim tensor of linear weights, where <cite>m</cite> is the number
of outputs (must be explicit if <cite>m=1</cite>)</p></li>
<li><p><strong>b</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]) – The affine (offset) term. Either a float (for single-output
models or if the offset is shared), or a <cite>m</cite>-dim tensor (with
different offset values for for the <cite>m</cite> different outputs).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.deterministic.AffineDeterministicModel.subset_output">
<code class="sig-name descname">subset_output</code><span class="sig-paren">(</span><em class="sig-param">idcs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel.subset_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.deterministic.AffineDeterministicModel" title="botorch.models.deterministic.AffineDeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">AffineDeterministicModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The current model, subset to the specified output indices.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.deterministic.AffineDeterministicModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/deterministic.html#AffineDeterministicModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.deterministic.AffineDeterministicModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the (deterministic) model output at X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim input tensor <cite>X</cite>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x m</cite>-dimensional output tensor (the outcome
dimension <cite>m</cite> must be explicit if <cite>m=1</cite>).</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
<div class="section" id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-botorch.models.cost">
<span id="cost-models-for-cost-aware-optimization"></span><h3>Cost Models (for cost-aware optimization)<a class="headerlink" href="#module-botorch.models.cost" title="Permalink to this headline">¶</a></h3>
<p>Cost models to be used with multi-fidelity optimization.</p>
<dl class="class">
<dt id="botorch.models.cost.AffineFidelityCostModel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.cost.</code><code class="sig-name descname">AffineFidelityCostModel</code><span class="sig-paren">(</span><em class="sig-param">fidelity_weights=None</em>, <em class="sig-param">fixed_cost=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#AffineFidelityCostModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.cost.AffineFidelityCostModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.deterministic.DeterministicModel" title="botorch.models.deterministic.DeterministicModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.deterministic.DeterministicModel</span></code></a></p>
<p>Affine cost model operating on fidelity parameters.</p>
<p>For each (q-batch) element of a candidate set <cite>X</cite>, this module computes a
cost of the form</p>
<blockquote>
<div><p>cost = fixed_cost + sum_j weights[j] * X[fidelity_dims[j]]</p>
</div></blockquote>
<p>Affine cost model operating on fidelity parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fidelity_weights</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]]) – A dictionary mapping a subset of columns of <cite>X</cite>
(the fidelity parameters) to it’s associated weight in the
affine cost expression. If omitted, assumes that the last
column of X is the fidelity parameter with a weight of 1.0.</p></li>
<li><p><strong>fixed_cost</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The fixed cost of running a single candidate point (i.e.
an element of a q-batch).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.cost.AffineFidelityCostModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/cost.html#AffineFidelityCostModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.cost.AffineFidelityCostModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the cost on a candidate set X.</p>
<p>Computes a cost of the form</p>
<blockquote>
<div><p>cost = fixed_cost + sum_j weights[j] * X[fidelity_dims[j]]</p>
</div></blockquote>
<p>for each element of the q-batch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x q x d’</cite>-dim tensor of candidate points.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x q x 1</cite>-dim tensor of costs.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.gp_regression">
<span id="gp-regression-models"></span><h3>GP Regression Models<a class="headerlink" href="#module-botorch.models.gp_regression" title="Permalink to this headline">¶</a></h3>
<p>Gaussian Process Regression models based on GPyTorch models.</p>
<dl class="class">
<dt id="botorch.models.gp_regression.SingleTaskGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gp_regression.</code><code class="sig-name descname">SingleTaskGP</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">likelihood=None</em>, <em class="sig-param">covar_module=None</em>, <em class="sig-param">outcome_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code></p>
<p>A single-task exact GP model.</p>
<p>A single-task exact GP using relatively strong priors on the Kernel
hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance).</p>
<p>This model works in batch mode (each batch having its own hyperparameters).
When the training observations include multiple outputs, this model will use
batching to model outputs independently.</p>
<p>Use this model when you have independent output(s) and all outputs use the
same training data. If outputs are independent and outputs have different
training data, use the ModelListGP. When modeling correlations between
outputs, use the MultiTaskGP.</p>
<p>A single-task exact GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>]) – A likelihood. If omitted, use a standard
GaussianLikelihood with inferred noise level.</p></li>
<li><p><strong>covar_module</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]) – The module computing the covariance (Kernel) matrix.
If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>]) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="botorch.models.gp_regression.SingleTaskGP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#SingleTaskGP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.SingleTaskGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MultivariateNormal</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.gp_regression.FixedNoiseGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gp_regression.</code><code class="sig-name descname">FixedNoiseGP</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">train_Yvar</em>, <em class="sig-param">covar_module=None</em>, <em class="sig-param">outcome_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code></p>
<p>A single-task exact GP model using fixed noise levels.</p>
<p>A single-task exact GP that uses fixed observation noise levels. This model
also uses relatively strong priors on the Kernel hyperparameters, which work
best when covariates are normalized to the unit cube and outcomes are
standardized (zero mean, unit variance).</p>
<p>This model works in batch mode (each batch having its own hyperparameters).</p>
<p>A single-task exact GP model using fixed noise levels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>]) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="botorch.models.gp_regression.FixedNoiseGP.fantasize">
<code class="sig-name descname">fantasize</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">sampler</em>, <em class="sig-param">observation_noise=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP.fantasize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP.fantasize" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a fantasy model.</p>
<p>Constructs a fantasy model in the following fashion:
(1) compute the model posterior at <cite>X</cite> (if <cite>observation_noise=True</cite>,
this includes observation noise taken as the mean across the observation
noise in the training data. If <cite>observation_noise</cite> is a Tensor, use
it directly as the observation noise to add).
(2) sample from this posterior (using <cite>sampler</cite>) to generate “fake”
observations.
(3) condition the model on the new fake observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>sampler</strong> (<a class="reference internal" href="sampling.html#botorch.sampling.samplers.MCSampler" title="botorch.sampling.samplers.MCSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MCSampler</span></code></a>) – The sampler used for sampling from the posterior at <cite>X</cite>.</p></li>
<li><p><strong>observation_noise</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – If True, include the mean across the observation
noise in the training data as observation noise in the posterior
from which the samples are drawn. If a Tensor, use it directly
as the specified measurement noise.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gp_regression.FixedNoiseGP" title="botorch.models.gp_regression.FixedNoiseGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">FixedNoiseGP</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The constructed fantasy model.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gp_regression.FixedNoiseGP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MultivariateNormal</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gp_regression.FixedNoiseGP.subset_output">
<code class="sig-name descname">subset_output</code><span class="sig-paren">(</span><em class="sig-param">idcs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#FixedNoiseGP.subset_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.FixedNoiseGP.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The current model, subset to the specified output indices.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.gp_regression.HeteroskedasticSingleTaskGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gp_regression.</code><code class="sig-name descname">HeteroskedasticSingleTaskGP</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">train_Yvar</em>, <em class="sig-param">outcome_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#HeteroskedasticSingleTaskGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.SingleTaskGP</span></code></a></p>
<p>A single-task exact GP model using a heteroskeastic noise model.</p>
<p>This model internally wraps another GP (a SingleTaskGP) to model the
observation noise. This allows the likelihood to make out-of-sample
predictions for the observation noise levels.</p>
<p>A single-task exact GP model using a heteroskedastic noise model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>]) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).
Note that the noise model internally log-transforms the
variances, which will happen after this transform is applied.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">se</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="n">se</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">HeteroskedasticSingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="botorch.models.gp_regression.HeteroskedasticSingleTaskGP.condition_on_observations">
<code class="sig-name descname">condition_on_observations</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#HeteroskedasticSingleTaskGP.condition_on_observations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>m</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP" title="botorch.models.gp_regression.HeteroskedasticSingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">HeteroskedasticSingleTaskGP</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>BatchedMultiOutputGPyTorchModel</cite> object of the same type with
<cite>n + n’</cite> training examples, representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">new_X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">new_X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">new_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="method">
<dt id="botorch.models.gp_regression.HeteroskedasticSingleTaskGP.subset_output">
<code class="sig-name descname">subset_output</code><span class="sig-paren">(</span><em class="sig-param">idcs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression.html#HeteroskedasticSingleTaskGP.subset_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gp_regression.HeteroskedasticSingleTaskGP" title="botorch.models.gp_regression.HeteroskedasticSingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">HeteroskedasticSingleTaskGP</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The current model, subset to the specified output indices.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.gp_regression_fidelity">
<span id="multi-fidelity-gp-regression-models"></span><h3>Multi-Fidelity GP Regression Models<a class="headerlink" href="#module-botorch.models.gp_regression_fidelity" title="Permalink to this headline">¶</a></h3>
<p>Gaussian Process Regression models based on GPyTorch models.</p>
<dl class="citation">
<dt class="label" id="wu2019mf"><span class="brackets">Wu2019mf</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>J. Wu, S. Toscano-Palmerin, P. I. Frazier, and A. G. Wilson. Practical
multi-fidelity bayesian optimization for hyperparameter tuning. ArXiv 2019.</p>
</dd>
</dl>
<dl class="class">
<dt id="botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gp_regression_fidelity.</code><code class="sig-name descname">SingleTaskMultiFidelityGP</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">iteration_fidelity=None</em>, <em class="sig-param">data_fidelity=None</em>, <em class="sig-param">linear_truncated=True</em>, <em class="sig-param">nu=2.5</em>, <em class="sig-param">likelihood=None</em>, <em class="sig-param">outcome_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#SingleTaskMultiFidelityGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.SingleTaskGP" title="botorch.models.gp_regression.SingleTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.SingleTaskGP</span></code></a></p>
<p>A single task multi-fidelity GP model.</p>
<p>A SingleTaskGP model using a DownsamplingKernel for the data fidelity
parameter (if present) and an ExponentialDecayKernel for the iteration
fidelity parameter (if present).</p>
<p>This kernel is described in <a class="reference internal" href="#wu2019mf" id="id1"><span>[Wu2019mf]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x (d + s)</cite> tensor of training features,
where <cite>s</cite> is the dimension of the fidelity parameters (either one
or two).</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>iteration_fidelity</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The column index for the training iteration fidelity
parameter (optional).</p></li>
<li><p><strong>data_fidelity</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The column index for the downsampling fidelity parameter
(optional).</p></li>
<li><p><strong>linear_truncated</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, use a <cite>LinearTruncatedFidelityKernel</cite> instead
of the default kernel.</p></li>
<li><p><strong>nu</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2, or
5/2. Only used when <cite>linear_truncated=True</cite>.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>]) – A likelihood. If omitted, use a standard GaussianLikelihood
with inferred noise level.</p></li>
<li><p><strong>outcome_transform</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>]) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskMultiFidelityGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">data_fidelity</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>A single-task exact GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>]) – A likelihood. If omitted, use a standard
GaussianLikelihood with inferred noise level.</p></li>
<li><p><strong>covar_module</strong> – The module computing the covariance (Kernel) matrix.
If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>]) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="class">
<dt id="botorch.models.gp_regression_fidelity.FixedNoiseMultiFidelityGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.gp_regression_fidelity.</code><code class="sig-name descname">FixedNoiseMultiFidelityGP</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">train_Yvar</em>, <em class="sig-param">iteration_fidelity=None</em>, <em class="sig-param">data_fidelity=None</em>, <em class="sig-param">linear_truncated=True</em>, <em class="sig-param">nu=2.5</em>, <em class="sig-param">outcome_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/gp_regression_fidelity.html#FixedNoiseMultiFidelityGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.gp_regression_fidelity.FixedNoiseMultiFidelityGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.gp_regression.FixedNoiseGP" title="botorch.models.gp_regression.FixedNoiseGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.FixedNoiseGP</span></code></a></p>
<p>A single task multi-fidelity GP model using fixed noise levels.</p>
<p>A FixedNoiseGP model analogue to SingleTaskMultiFidelityGP, using a
DownsamplingKernel for the data fidelity parameter (if present) and
an ExponentialDecayKernel for the iteration fidelity parameter (if present).</p>
<p>This kernel is described in <a class="reference internal" href="#wu2019mf" id="id2"><span>[Wu2019mf]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x (d + s)</cite> tensor of training features,
where <cite>s</cite> is the dimension of the fidelity parameters (either one
or two).</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement noise.</p></li>
<li><p><strong>iteration_fidelity</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The column index for the training iteration fidelity
parameter (optional).</p></li>
<li><p><strong>data_fidelity</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The column index for the downsampling fidelity parameter
(optional).</p></li>
<li><p><strong>linear_truncated</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, use a <cite>LinearTruncatedFidelityKernel</cite> instead
of the default kernel.</p></li>
<li><p><strong>nu</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2, or
5/2. Only used when <cite>linear_truncated=True</cite>.</p></li>
<li><p><strong>outcome_transform</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>]) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseMultiFidelityGP</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train_X</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train_Y</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train_Yvar</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">data_fidelity</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>A single-task exact GP model using fixed noise levels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite> tensor of training features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite> tensor of observed measurement
noise.</p></li>
<li><p><strong>outcome_transform</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>]) – An outcome transform that is applied to the
training data during instantiation and to the posterior during
inference (that is, the <cite>Posterior</cite> obtained by calling
<cite>.posterior</cite> on the model will be on the original scale).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.model_list_gp_regression">
<span id="model-list-gp-regression-models"></span><h3>Model List GP Regression Models<a class="headerlink" href="#module-botorch.models.model_list_gp_regression" title="Permalink to this headline">¶</a></h3>
<p>Model List GP Regression models.</p>
<dl class="class">
<dt id="botorch.models.model_list_gp_regression.ModelListGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.model_list_gp_regression.</code><code class="sig-name descname">ModelListGP</code><span class="sig-paren">(</span><em class="sig-param">*gp_models</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.model_list.IndependentModelList</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.ModelListGPyTorchModel" title="botorch.models.gpytorch.ModelListGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.ModelListGPyTorchModel</span></code></a></p>
<p>A multi-output GP model with independent GPs for the outputs.</p>
<p>This model supports different-shaped training inputs for each of its
sub-models. It can be used with any BoTorch models.</p>
<p>Internally, this model is just a list of individual models, but it implements
the same input/output interface as all other BoTorch models. This makes it
very flexible and convenient to work with. The sequential evaluation comes
at a performance cost though - if you are using a block design (i.e. the
same number of training example for each output, and a similar model
structure, you should consider using a batched GP model instead).</p>
<p>A multi-output GP model with independent GPs for the outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>*gp_models</strong> – An variable number of single-output BoTorch models.
If models have input/output transforms, these are honored
individually for each model.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model1</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X1</span><span class="p">,</span> <span class="n">train_Y1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model2</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X2</span><span class="p">,</span> <span class="n">train_Y2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelListGP</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="botorch.models.model_list_gp_regression.ModelListGP.condition_on_observations">
<code class="sig-name descname">condition_on_observations</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP.condition_on_observations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP.condition_on_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Condition the model on new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n’ x d</cite>-dim Tensor, where <cite>d</cite> is the dimension of
the feature space, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape</cite> is the batch shape (must be compatible with the
batch shape of the model).</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape’ x n’ x m</cite>-dim Tensor, where <cite>m</cite> is the number of
model outputs, <cite>n’</cite> is the number of points per batch, and
<cite>batch_shape’</cite> is the batch shape of the observations.
<cite>batch_shape’</cite> must be broadcastable to <cite>batch_shape</cite> using
standard broadcasting semantics. If <cite>Y</cite> has fewer batch dimensions
than <cite>X</cite>, its is assumed that the missing batch dimensions are
the same for all <cite>Y</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelListGP</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>ModelListGPyTorchModel</cite> representing the original model
conditioned on the new observations <cite>(X, Y)</cite> (and possibly noise
observations passed in via kwargs). Here the <cite>i</cite>-th model has
<cite>n_i + n’</cite> training examples, where the <cite>n’</cite> training examples have
been added and all test-time caches have been updated.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.model_list_gp_regression.ModelListGP.subset_output">
<code class="sig-name descname">subset_output</code><span class="sig-paren">(</span><em class="sig-param">idcs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/model_list_gp_regression.html#ModelListGP.subset_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.model_list_gp_regression.ModelListGP.subset_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset the model along the output dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The output indices to subset the model to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelListGP</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The current model, subset to the specified output indices.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.multitask">
<span id="multitask-gp-models"></span><h3>Multitask GP Models<a class="headerlink" href="#module-botorch.models.multitask" title="Permalink to this headline">¶</a></h3>
<p>Multi-Task GP models.</p>
<dl class="class">
<dt id="botorch.models.multitask.MultiTaskGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.multitask.</code><code class="sig-name descname">MultiTaskGP</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">task_feature</em>, <em class="sig-param">output_tasks=None</em>, <em class="sig-param">rank=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.models.exact_gp.ExactGP</span></code>, <a class="reference internal" href="#botorch.models.gpytorch.MultiTaskGPyTorchModel" title="botorch.models.gpytorch.MultiTaskGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gpytorch.MultiTaskGPyTorchModel</span></code></a></p>
<p>Multi-Task GP model using an ICM kernel, inferring observation noise.</p>
<p>Multi-task exact GP that uses a simple ICM kernel. Can be single-output or
multi-output. This model uses relatively strong priors on the base Kernel
hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance).</p>
<p>This model infers the noise level. WARNING: It currently does not support
different noise levels for the different tasks. If you have known observation
noise, please use <cite>FixedNoiseMultiTaskGP</cite> instead.</p>
<p>Multi-Task GP model using an ICM kernel, inferring observation noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x (d + 1)</cite> or <cite>b x n x (d + 1)</cite> (batch mode) tensor
of training data. One of the columns should contain the task
features (see <cite>task_feature</cite> argument).</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of training
observations.</p></li>
<li><p><strong>task_feature</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the task feature
(<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>output_tasks</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The rank to be used for the index kernel. If omitted, use a
full rank (i.e. number of tasks) kernel.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">task_feature</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="botorch.models.multitask.MultiTaskGP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#MultiTaskGP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.multitask.MultiTaskGP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MultivariateNormal</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.multitask.FixedNoiseMultiTaskGP">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.multitask.</code><code class="sig-name descname">FixedNoiseMultiTaskGP</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">train_Yvar</em>, <em class="sig-param">task_feature</em>, <em class="sig-param">output_tasks=None</em>, <em class="sig-param">rank=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/multitask.html#FixedNoiseMultiTaskGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.multitask.FixedNoiseMultiTaskGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.multitask.MultiTaskGP" title="botorch.models.multitask.MultiTaskGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.multitask.MultiTaskGP</span></code></a></p>
<p>Multi-Task GP model using an ICM kernel, with known observation noise.</p>
<p>Multi-task exact GP that uses a simple ICM kernel. Can be single-output or
multi-output. This model uses relatively strong priors on the base Kernel
hyperparameters, which work best when covariates are normalized to the unit
cube and outcomes are standardized (zero mean, unit variance).</p>
<p>This model requires observation noise data (specified in <cite>train_Yvar</cite>).</p>
<p>Multi-Task GP model using an ICM kernel and known observatioon noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x (d + 1)</cite> or <cite>b x n x (d + 1)</cite> (batch mode) tensor
of training data. One of the columns should contain the task
features (see <cite>task_feature</cite> argument).</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of training
observations.</p></li>
<li><p><strong>train_Yvar</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n</cite> or <cite>b x n</cite> (batch mode) tensor of observation
noise standard errors.</p></li>
<li><p><strong>task_feature</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The index of the task feature
(<cite>-d &lt;= task_feature &lt;= d</cite>).</p></li>
<li><p><strong>output_tasks</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – A list of task indices for which to compute model
outputs for. If omitted, return outputs for all task indices.</p></li>
<li><p><strong>rank</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The rank to be used for the index kernel. If omitted, use a
full rank (i.e. number of tasks) kernel.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X2</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">X1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">X2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Yvar</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">FixedNoiseMultiTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">train_Yvar</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</div>
</div>
<div class="section" id="model-components">
<h2>Model Components<a class="headerlink" href="#model-components" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-botorch.models.kernels.downsampling">
<span id="kernels"></span><h3>Kernels<a class="headerlink" href="#module-botorch.models.kernels.downsampling" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="botorch.models.kernels.downsampling.DownsamplingKernel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.kernels.downsampling.</code><code class="sig-name descname">DownsamplingKernel</code><span class="sig-paren">(</span><em class="sig-param">power_prior=None</em>, <em class="sig-param">offset_prior=None</em>, <em class="sig-param">power_constraint=None</em>, <em class="sig-param">offset_constraint=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/downsampling.html#DownsamplingKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.kernels.downsampling.DownsamplingKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>GPyTorch Downsampling Kernel.</p>
<p>Computes a covariance matrix based on the down sampling kernel between
inputs <cite>x_1</cite> and <cite>x_2</cite> (we expect <cite>d = 1</cite>):</p>
<blockquote>
<div><dl class="simple">
<dt>K(mathbf{x_1}, mathbf{x_2}) = c + (1 - x_1)^(1 + delta) *</dt><dd><p>(1 - x_2)^(1 + delta).</p>
</dd>
</dl>
</div></blockquote>
<p>where <cite>c</cite> is an offset parameter, and <cite>delta</cite> is a power parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>power_constraint</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Interval</span></code>]) – Constraint to place on power parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>power_prior</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Prior</span></code>]) – Prior over the power parameter.</p></li>
<li><p><strong>offset_constraint</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Interval</span></code>]) – Constraint to place on offset parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>active_dims</strong> – List of data dimensions to operate on. <cite>len(active_dims)</cite>
should equal <cite>num_dimensions</cite>.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
<span class="target" id="module-botorch.models.kernels.exponential_decay"></span><dl class="class">
<dt id="botorch.models.kernels.exponential_decay.ExponentialDecayKernel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.kernels.exponential_decay.</code><code class="sig-name descname">ExponentialDecayKernel</code><span class="sig-paren">(</span><em class="sig-param">power_prior=None</em>, <em class="sig-param">offset_prior=None</em>, <em class="sig-param">power_constraint=None</em>, <em class="sig-param">offset_constraint=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/exponential_decay.html#ExponentialDecayKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.kernels.exponential_decay.ExponentialDecayKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>GPyTorch Exponential Decay Kernel.</p>
<p>Computes a covariance matrix based on the exponential decay kernel
between inputs <cite>x_1</cite> and <cite>x_2</cite> (we expect <cite>d = 1</cite>):</p>
<blockquote>
<div><p>K(x_1, x_2) = w + beta^alpha / (x_1 + x_2 + beta)^alpha.</p>
</div></blockquote>
<p>where <cite>w</cite> is an offset parameter, <cite>beta</cite> is a lenthscale parameter, and
<cite>alpha</cite> is a power parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lengthscale_constraint</strong> – Constraint to place on lengthscale parameter.
Default is <cite>Positive</cite>.</p></li>
<li><p><strong>lengthscale_prior</strong> – Prior over the lengthscale parameter.</p></li>
<li><p><strong>power_constraint</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Interval</span></code>]) – Constraint to place on power parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>power_prior</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Prior</span></code>]) – Prior over the power parameter.</p></li>
<li><p><strong>offset_constraint</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Interval</span></code>]) – Constraint to place on offset parameter. Default is
<cite>Positive</cite>.</p></li>
<li><p><strong>active_dims</strong> – List of data dimensions to operate on. <cite>len(active_dims)</cite>
should equal <cite>num_dimensions</cite>.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
<span class="target" id="module-botorch.models.kernels.linear_truncated_fidelity"></span><dl class="class">
<dt id="botorch.models.kernels.linear_truncated_fidelity.LinearTruncatedFidelityKernel">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.kernels.linear_truncated_fidelity.</code><code class="sig-name descname">LinearTruncatedFidelityKernel</code><span class="sig-paren">(</span><em class="sig-param">fidelity_dims</em>, <em class="sig-param">dimension=None</em>, <em class="sig-param">power_prior=None</em>, <em class="sig-param">power_constraint=None</em>, <em class="sig-param">nu=2.5</em>, <em class="sig-param">lengthscale_prior_unbiased=None</em>, <em class="sig-param">lengthscale_prior_biased=None</em>, <em class="sig-param">lengthscale_constraint_unbiased=None</em>, <em class="sig-param">lengthscale_constraint_biased=None</em>, <em class="sig-param">covar_module_unbiased=None</em>, <em class="sig-param">covar_module_biased=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/kernels/linear_truncated_fidelity.html#LinearTruncatedFidelityKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.kernels.linear_truncated_fidelity.LinearTruncatedFidelityKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>GPyTorch Linear Truncated Fidelity Kernel.</p>
<p>Computes a covariance matrix based on the Linear truncated kernel between
inputs <cite>x_1</cite> and <cite>x_2</cite> for up to two fidelity parmeters:</p>
<blockquote>
<div><p>K(x_1, x_2) = k_0 + c_1(x_1, x_2)k_1 + c_2(x_1,x_2)k_2 + c_3(x_1,x_2)k_3</p>
</div></blockquote>
<p>where</p>
<ul class="simple">
<li><dl class="simple">
<dt><cite>k_i(i=0,1,2,3)</cite> are Matern kernels calculated between non-fidelity</dt><dd><p>parameters of <cite>x_1</cite> and <cite>x_2</cite> with different priors.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_1=(1 - x_1[f_1])(1 - x_2[f_1]))(1 + x_1[f_1] x_2[f_1])^p</cite> is the kernel</dt><dd><p>of the the bias term, which can be decomposed into a determistic part
and a polynomial kernel. Here <cite>f_1</cite> is the first fidelity dimension and
<cite>p</cite> is the order of the polynomial kernel.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_3</cite> is the same as <cite>c_1</cite> but is calculated for the second fidelity</dt><dd><p>dimension <cite>f_2</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>c_2</cite> is the interaction term with four deterministic terms and the</dt><dd><p>polynomial kernel between <cite>x_1[…, [f_1, f_2]]</cite> and
<cite>x_2[…, [f_1, f_2]]</cite>.</p>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fidelity_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – A list containing either one or two indices specifying
the fidelity parameters of the input.</p></li>
<li><p><strong>dimension</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The dimension of <cite>x</cite>. Unused if <cite>active_dims</cite> is specified.</p></li>
<li><p><strong>power_prior</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Prior</span></code>]) – Prior for the power parameter of the polynomial kernel.
Default is <cite>None</cite>.</p></li>
<li><p><strong>power_constraint</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Interval</span></code>]) – Constraint on the power parameter of the polynomial
kernel. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>nu</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The smoothness parameter for the Matern kernel: either 1/2, 3/2,
or 5/2. Unused if both <cite>covar_module_unbiased</cite> and
<cite>covar_module_biased</cite> are specified.</p></li>
<li><p><strong>lengthscale_prior_unbiased</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Prior</span></code>]) – Prior on the lengthscale parameter of Matern
kernel <cite>k_0</cite>. Default is <cite>Gamma(1.1, 1/20)</cite>.</p></li>
<li><p><strong>lengthscale_constraint_unbiased</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Interval</span></code>]) – Constraint on the lengthscale parameter
of the Matern kernel <cite>k_0</cite>. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>lengthscale_prior_biased</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Prior</span></code>]) – Prior on the lengthscale parameter of Matern
kernels <cite>k_i(i&gt;0)</cite>. Default is <cite>Gamma(5, 1/20)</cite>.</p></li>
<li><p><strong>lengthscale_constraint_biased</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Interval</span></code>]) – Constraint on the lengthscale parameter
of the Matern kernels <cite>k_i(i&gt;0)</cite>. Default is <cite>Positive</cite>.</p></li>
<li><p><strong>covar_module_unbiased</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code>]) – Specify a custom kernel for <cite>k_0</cite>. If omitted,
use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>covar_module_biased</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code>]) – Specify a custom kernel for the biased parts
<cite>k_i(i&gt;0)</cite>. If omitted, use a <cite>MaternKernel</cite>.</p></li>
<li><p><strong>batch_shape</strong> – If specified, use a separate lengthscale for each batch of
input data. If <cite>x1</cite> is a <cite>batch_shape x n x d</cite> tensor, this should
be <cite>batch_shape</cite>.</p></li>
<li><p><strong>active_dims</strong> – Compute the covariance of a subset of input dimensions. The
numbers correspond to the indices of the dimensions.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Non-batch: Simple option</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">LinearTruncatedFidelityKernel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Output: LazyVariable of size (10 x 10)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Batch: Simple option</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">LinearTruncatedFidelityKernel</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">covar</span> <span class="o">=</span> <span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Output: LazyVariable of size (2 x 10 x 10)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>
</div>
</div>
<div class="section" id="transforms">
<h2>Transforms<a class="headerlink" href="#transforms" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-botorch.models.transforms.outcome">
<span id="outcome-transforms"></span><h3>Outcome Transforms<a class="headerlink" href="#module-botorch.models.transforms.outcome" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="botorch.models.transforms.outcome.OutcomeTransform">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.transforms.outcome.</code><code class="sig-name descname">OutcomeTransform</code><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for outcome transforms.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.transforms.outcome.OutcomeTransform.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the outcomes in a model’s training targets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.OutcomeTransform.untransform">
<code class="sig-name descname">untransform</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.untransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform previously transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of transfomred training targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of transformed observation
noises associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-transformed outcome observations.</p></li>
<li><p>The un-transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.OutcomeTransform.untransform_posterior">
<code class="sig-name descname">untransform_posterior</code><span class="sig-paren">(</span><em class="sig-param">posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#OutcomeTransform.untransform_posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.OutcomeTransform.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform a posterior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a>) – A posterior in the transformed space.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The un-transformed posterior.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.transforms.outcome.ChainedOutcomeTransform">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.transforms.outcome.</code><code class="sig-name descname">ChainedOutcomeTransform</code><span class="sig-paren">(</span><em class="sig-param">**transforms</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.OutcomeTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.ModuleDict</span></code></p>
<p>An outcome transform representing the chaining of individual transforms</p>
<p>Chaining of outcome transforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>transforms</strong> (<a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">OutcomeTransform</span></code></a>) – The transforms to chain. Internally, the names of the
kwargs are used as the keys for accessing the individual
transforms on the module.</p>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.ChainedOutcomeTransform.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the outcomes in a model’s training targets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform">
<code class="sig-name descname">untransform</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.untransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform previously transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of transfomred training targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of transformed observation
noises associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-transformed outcome observations.</p></li>
<li><p>The un-transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform_posterior">
<code class="sig-name descname">untransform_posterior</code><span class="sig-paren">(</span><em class="sig-param">posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#ChainedOutcomeTransform.untransform_posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.ChainedOutcomeTransform.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform a posterior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a>) – A posterior in the transformed space.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The un-transformed posterior.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.transforms.outcome.Standardize">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.transforms.outcome.</code><code class="sig-name descname">Standardize</code><span class="sig-paren">(</span><em class="sig-param">m</em>, <em class="sig-param">outputs=None</em>, <em class="sig-param">batch_shape=torch.Size([])</em>, <em class="sig-param">min_stdv=1e-08</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.OutcomeTransform</span></code></a></p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<p>This module is stateful: If in train mode, calling forward updates the
module state (i.e. the mean/std normalizing constants). If in eval mode,
calling forward simply applies the standardization using the current module
state.</p>
<p>Standardize outcomes (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The output dimension.</p></li>
<li><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – Which of the outputs to standardize. If omitted, all
outputs will be standardized.</p></li>
<li><p><strong>batch_shape</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Size</span></code>) – The batch_shape of the training targets.</p></li>
<li><p><strong>min_stddv</strong> – The minimum standard deviation for which to perform
standardization (if lower, only de-mean the data).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.Standardize.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Standardize outcomes.</p>
<p>If the module is in train mode, this updates the module state (i.e. the
mean/std normalizing constants). If the module is in eval mode, simply
applies the normalization using the module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.Standardize.untransform">
<code class="sig-name descname">untransform</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.untransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-standardize outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of standardized observation
noises associated with the targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The un-standardized outcome observations.</p></li>
<li><p>The un-standardized observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-standardized outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.Standardize.untransform_posterior">
<code class="sig-name descname">untransform_posterior</code><span class="sig-paren">(</span><em class="sig-param">posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Standardize.untransform_posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Standardize.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-standardize the posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a>) – A posterior in the standardized space.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The un-standardized posterior. If the input posterior is a MVN,
the transformed posterior is again an MVN.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.transforms.outcome.Log">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.transforms.outcome.</code><code class="sig-name descname">Log</code><span class="sig-paren">(</span><em class="sig-param">outputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.outcome.OutcomeTransform" title="botorch.models.transforms.outcome.OutcomeTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.outcome.OutcomeTransform</span></code></a></p>
<p>Log-transform outcomes.</p>
<p>Useful if the targets are modeled using a (multivariate) log-Normal
distribution. This means that we can use a standard GP model on the
log-transformed outcomes and un-transform the model posterior of that GP.</p>
<p>Log-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>outputs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]) – Which of the outputs to log-transform. If omitted, all
outputs will be standardized.</p>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.Log.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Log-transform outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of training targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of observation noises
associated with the training targets (if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The transformed outcome observations.</p></li>
<li><p>The transformed observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.Log.untransform">
<code class="sig-name descname">untransform</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.untransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform log-transformed outcomes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x m</cite>-dim tensor of log-transfomred targets.</p></li>
<li><p><strong>Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite>-dim tensor of log- transformed
observation noises associated with the training targets
(if applicable).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The exponentiated outcome observations.</p></li>
<li><p>The exponentiated observation noise (if applicable).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple with the un-transformed outcomes</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.outcome.Log.untransform_posterior">
<code class="sig-name descname">untransform_posterior</code><span class="sig-paren">(</span><em class="sig-param">posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/outcome.html#Log.untransform_posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.outcome.Log.untransform_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform the log-transformed posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>posterior</strong> (<a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a>) – A posterior in the log-transformed space.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="posteriors.html#botorch.posteriors.posterior.Posterior" title="botorch.posteriors.posterior.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The un-transformed posterior.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.transforms.input">
<span id="input-transforms"></span><h3>Input Transforms<a class="headerlink" href="#module-botorch.models.transforms.input" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="botorch.models.transforms.input.InputTransform">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.transforms.input.</code><code class="sig-name descname">InputTransform</code><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class for input transforms.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="botorch.models.transforms.input.InputTransform.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.input.InputTransform.untransform">
<code class="sig-name descname">untransform</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#InputTransform.untransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.InputTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform the inputs to a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.transforms.input.ChainedInputTransform">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.transforms.input.</code><code class="sig-name descname">ChainedInputTransform</code><span class="sig-paren">(</span><em class="sig-param">**transforms</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.InputTransform</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.ModuleDict</span></code></p>
<p>An input transform representing the chaining of individual transforms</p>
<p>Chaining of input transforms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>transforms</strong> (<a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">InputTransform</span></code></a>) – The transforms to chain. Internally, the names of the
kwargs are used as the keys for accessing the individual
transforms on the module.</p>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.transforms.input.ChainedInputTransform.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the inputs to a model.</p>
<p>Individual transforms are applied in sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.input.ChainedInputTransform.untransform">
<code class="sig-name descname">untransform</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#ChainedInputTransform.untransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.ChainedInputTransform.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-transform the inputs to a model.</p>
<p>Un-transforms of the individual transforms are applied in reverse sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim tensor of transformed inputs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-transformed inputs.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="botorch.models.transforms.input.Normalize">
<em class="property">class </em><code class="sig-prename descclassname">botorch.models.transforms.input.</code><code class="sig-name descname">Normalize</code><span class="sig-paren">(</span><em class="sig-param">d</em>, <em class="sig-param">bounds=None</em>, <em class="sig-param">batch_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Normalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.Normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.models.transforms.input.InputTransform" title="botorch.models.transforms.input.InputTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.transforms.input.InputTransform</span></code></a></p>
<p>Normalize the inputs to the unit cube.</p>
<p>If no explicit bounds are provided this module is stateful: If in train mode,
calling <cite>forward</cite> updates the module state (i.e. the normalizing bounds). If
in eval mode, calling <cite>forward</cite> simply applies the normalization using the
current module state.</p>
<p>Normalize the inputs to the unit cube.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The dimension of the input space.</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – If provided, use these bounds to normalize the inputs. If
omitted, learn the bounds in train mode.</p></li>
<li><p><strong>batch_shape</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Size</span></code>) – The batch shape of the inputs (asssuming input tensors
of shape <cite>batch_shape x n x d</cite>). If provided, perform individual
normalization per batch, otherwise uses a single normalization.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="botorch.models.transforms.input.Normalize.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Normalize.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.Normalize.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalize the inputs.</p>
<p>If no explicit bounds are provided, this is stateful: In train mode,
calling <cite>forward</cite> updates the module state (i.e. the normalizing bounds).
In eval mode, calling <cite>forward</cite> simply applies the normalization using
the current module state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim tensor of inputs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x d</cite>-dim tensor of inputs normalized to the
module’s bounds.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.input.Normalize.untransform">
<code class="sig-name descname">untransform</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/input.html#Normalize.untransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.input.Normalize.untransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Un-normalize the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite>-dim tensor of normalized inputs.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>batch_shape x n x d</cite>-dim tensor of un-normalized inputs.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="botorch.models.transforms.input.Normalize.bounds">
<em class="property">property </em><code class="sig-name descname">bounds</code><a class="headerlink" href="#botorch.models.transforms.input.Normalize.bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>The bounds used for normalizing the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.transforms.utils">
<span id="transform-utilities"></span><h3>Transform Utilities<a class="headerlink" href="#module-botorch.models.transforms.utils" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="botorch.models.transforms.utils.lognorm_to_norm">
<code class="sig-prename descclassname">botorch.models.transforms.utils.</code><code class="sig-name descname">lognorm_to_norm</code><span class="sig-paren">(</span><em class="sig-param">mu</em>, <em class="sig-param">Cov</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#lognorm_to_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.utils.lognorm_to_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean and covariance of a MVN from those of the associated log-MVN</p>
<p>If <cite>Y</cite> is log-normal with mean mu_ln and covariance Cov_ln, then
<cite>X ~ N(mu_n, Cov_n)</cite> with</p>
<blockquote>
<div><p>Cov_n_{ij} = log(1 + Cov_ln_{ij} / (mu_ln_{i} * mu_n_{j}))
mu_n_{i} = log(mu_ln_{i}) - 0.5 * log(1 + Cov_ln_{ii} / mu_ln_{i}**2)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n</cite> mean vector of the log-Normal distribution.</p></li>
<li><p><strong>Cov</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x n</cite> covariance matrix of the log-Normal
distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The <cite>batch_shape x n</cite> mean vector of the Normal distribution</p></li>
<li><p>The <cite>batch_shape x n x n</cite> covariance matrix of the Normal distribution</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple containing</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.transforms.utils.norm_to_lognorm">
<code class="sig-prename descclassname">botorch.models.transforms.utils.</code><code class="sig-name descname">norm_to_lognorm</code><span class="sig-paren">(</span><em class="sig-param">mu</em>, <em class="sig-param">Cov</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean and covariance of a log-MVN from its MVN sufficient statistics</p>
<p>If <cite>X ~ N(mu, Cov)</cite> and <cite>Y = exp(X)</cite>, then <cite>Y</cite> is log-normal with</p>
<blockquote>
<div><p>mu_ln_{i} = exp(mu_{i} + 0.5 * Cov_{ii})
Cov_ln_{ij} = exp(mu_{i} + mu_{j} + 0.5 * (Cov_{ii} + Cov_{jj})) *
(exp(Cov_{ij}) - 1)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>Cov</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x n</cite> covariance matrix of the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The <cite>batch_shape x n</cite> mean vector of the log-Normal distribution.</p></li>
<li><dl class="simple">
<dt>The <cite>batch_shape x n x n</cite> covariance matrix of the log-Normal</dt><dd><p>distribution.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-tuple containing</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.transforms.utils.norm_to_lognorm_mean">
<code class="sig-prename descclassname">botorch.models.transforms.utils.</code><code class="sig-name descname">norm_to_lognorm_mean</code><span class="sig-paren">(</span><em class="sig-param">mu</em>, <em class="sig-param">var</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm_mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm_mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean of a log-MVN from its MVN marginals</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>var</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n</cite> variance vectorof the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The <cite>batch_shape x n</cite> mean vector of the log-Normal distribution</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.transforms.utils.norm_to_lognorm_variance">
<code class="sig-prename descclassname">botorch.models.transforms.utils.</code><code class="sig-name descname">norm_to_lognorm_variance</code><span class="sig-paren">(</span><em class="sig-param">mu</em>, <em class="sig-param">var</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/transforms/utils.html#norm_to_lognorm_variance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.transforms.utils.norm_to_lognorm_variance" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute variance of a log-MVN from its MVN marginals</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n</cite> mean vector of the Normal distribution.</p></li>
<li><p><strong>var</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n</cite> variance vectorof the Normal distribution.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The <cite>batch_shape x n</cite> variance vector of the log-Normal distribution.</p>
</dd>
</dl>
</dd></dl>
</div>
</div>
<div class="section" id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-botorch.models.converter">
<span id="model-conversion"></span><h3>Model Conversion<a class="headerlink" href="#module-botorch.models.converter" title="Permalink to this headline">¶</a></h3>
<p>Utilities for converting between different models.</p>
<dl class="function">
<dt id="botorch.models.converter.model_list_to_batched">
<code class="sig-prename descclassname">botorch.models.converter.</code><code class="sig-name descname">model_list_to_batched</code><span class="sig-paren">(</span><em class="sig-param">model_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#model_list_to_batched"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.converter.model_list_to_batched" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a ModelListGP to a BatchedMultiOutputGPyTorchModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_list</strong> (<a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelListGP</span></code></a>) – The <cite>ModelListGP</cite> to be converted to the appropriate
<cite>BatchedMultiOutputGPyTorchModel</cite>. All sub-models must be of the same
type and have the shape (batch shape and number of training inputs).</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel" title="botorch.models.gpytorch.BatchedMultiOutputGPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchedMultiOutputGPyTorchModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The model converted into a <cite>BatchedMultiOutputGPyTorchModel</cite>.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">list_gp</span> <span class="o">=</span> <span class="n">ModelListGP</span><span class="p">(</span><span class="n">gp1</span><span class="p">,</span> <span class="n">gp2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_gp</span> <span class="o">=</span> <span class="n">model_list_to_batched</span><span class="p">(</span><span class="n">list_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="function">
<dt id="botorch.models.converter.batched_to_model_list">
<code class="sig-prename descclassname">botorch.models.converter.</code><code class="sig-name descname">batched_to_model_list</code><span class="sig-paren">(</span><em class="sig-param">batch_model</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/converter.html#batched_to_model_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.converter.batched_to_model_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a BatchedMultiOutputGPyTorchModel to a ModelListGP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_list</strong> – The <cite>BatchedMultiOutputGPyTorchModel</cite> to be converted to a
<cite>ModelListGP</cite>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#botorch.models.model_list_gp_regression.ModelListGP" title="botorch.models.model_list_gp_regression.ModelListGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelListGP</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The model converted into a <cite>ModelListGP</cite>.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">list_gp</span> <span class="o">=</span> <span class="n">batched_to_model_list</span><span class="p">(</span><span class="n">batch_gp</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="module-botorch.models.utils">
<span id="other-utilties"></span><h3>Other Utilties<a class="headerlink" href="#module-botorch.models.utils" title="Permalink to this headline">¶</a></h3>
<p>Utiltiy functions for models.</p>
<dl class="function">
<dt id="botorch.models.utils.multioutput_to_batch_mode_transform">
<code class="sig-prename descclassname">botorch.models.utils.</code><code class="sig-name descname">multioutput_to_batch_mode_transform</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">num_outputs</em>, <em class="sig-param">train_Yvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#multioutput_to_batch_mode_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.utils.multioutput_to_batch_mode_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transforms training inputs for a multi-output model.</p>
<p>Used for multi-output models that internally are represented by a
batched single output model, where each output is modeled as an
independent batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x d</cite> or <cite>input_batch_shape x n x d</cite> (batch mode) tensor of
training features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x m</cite> or <cite>target_batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
<li><p><strong>num_outputs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of outputs</p></li>
<li><p><strong>train_Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>n x m</cite> or <cite>target_batch_shape x n x m</cite> tensor of observed
measurement noise.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>3-element tuple containing</p>
<ul class="simple">
<li><p>A <cite>input_batch_shape x m x n x d</cite> tensor of training features.</p></li>
<li><p>A <cite>target_batch_shape x m x n</cite> tensor of training observations.</p></li>
<li><p>A <cite>target_batch_shape x m x n</cite> tensor observed measurement noise.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.utils.add_output_dim">
<code class="sig-prename descclassname">botorch.models.utils.</code><code class="sig-name descname">add_output_dim</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">original_batch_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#add_output_dim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.utils.add_output_dim" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert the output dimension at the correct location.</p>
<p>The trailing batch dimensions of X must match the original batch dimensions
of the training inputs, but can also include extra batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>(new_batch_shape) x (original_batch_shape) x n x d</cite> tensor of
features.</p></li>
<li><p><strong>original_batch_shape</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Size</span></code>) – the batch shape of the model’s training inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A <cite>(new_batch_shape) x (original_batch_shape) x m x n x d</cite> tensor of</dt><dd><p>features.</p>
</dd>
</dl>
</li>
<li><p>The index corresponding to the output dimension.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.utils.check_no_nans">
<code class="sig-prename descclassname">botorch.models.utils.</code><code class="sig-name descname">check_no_nans</code><span class="sig-paren">(</span><em class="sig-param">Z</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#check_no_nans"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.utils.check_no_nans" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that tensor does not contain NaN values.</p>
<p>Raises an InputDataError if <cite>Z</cite> contains NaN values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>Z</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The input tensor.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.utils.check_min_max_scaling">
<code class="sig-prename descclassname">botorch.models.utils.</code><code class="sig-name descname">check_min_max_scaling</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">strict=False</em>, <em class="sig-param">atol=0.01</em>, <em class="sig-param">raise_on_fail=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#check_min_max_scaling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.utils.check_min_max_scaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that tensor is normalized to the unit cube.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>batch_shape x n x d</cite> input tensor. Typically the training inputs
of a model.</p></li>
<li><p><strong>strict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, require <cite>X</cite> to be scaled to the unit cube (rather than
just to be contained within the unit cube).</p></li>
<li><p><strong>atol</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The tolerance for the boundary check. Only used if <cite>strict=True</cite>.</p></li>
<li><p><strong>raise_on_fail</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, raise an exception instead of a warning.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.utils.check_standardization">
<code class="sig-prename descclassname">botorch.models.utils.</code><code class="sig-name descname">check_standardization</code><span class="sig-paren">(</span><em class="sig-param">Y</em>, <em class="sig-param">atol_mean=0.01</em>, <em class="sig-param">atol_std=0.01</em>, <em class="sig-param">raise_on_fail=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#check_standardization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.utils.check_standardization" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that tensor is standardized (zero mean, unit variance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The input tensor of shape <cite>batch_shape x n x m</cite>. Typically the
train targets of a model. Standardization is checked across the
<cite>n</cite>-dimension.</p></li>
<li><p><strong>atol_mean</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The tolerance for the mean check.</p></li>
<li><p><strong>atol_std</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The tolerance for the std check.</p></li>
<li><p><strong>raise_on_fail</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, raise an exception instead of a warning.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.utils.validate_input_scaling">
<code class="sig-prename descclassname">botorch.models.utils.</code><code class="sig-name descname">validate_input_scaling</code><span class="sig-paren">(</span><em class="sig-param">train_X</em>, <em class="sig-param">train_Y</em>, <em class="sig-param">train_Yvar=None</em>, <em class="sig-param">raise_on_fail=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#validate_input_scaling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.utils.validate_input_scaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function to validate input data to models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x d</cite> or <cite>batch_shape x n x d</cite> (batch mode) tensor of
training features.</p></li>
<li><p><strong>train_Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode) tensor of
training observations.</p></li>
<li><p><strong>train_Yvar</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A <cite>batch_shape x n x m</cite> or <cite>batch_shape x n x m</cite> (batch mode)
tensor of observed measurement noise.</p></li>
<li><p><strong>raise_on_fail</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, raise an error instead of emitting a warning
(only for normalization/standardization checks, an error is always
raised if NaN values are present).</p></li>
</ul>
</dd>
</dl>
<p>This function is typically called inside the constructor of standard BoTorch
models. It validates the following:
(i) none of the inputs contain NaN values
(ii) the training data (<cite>train_X</cite>) is normalized to the unit cube
(iii) the training targets (<cite>train_Y</cite>) are standardized (zero mean, unit var)
No checks (other than the NaN check) are performed for observed variances
(<cite>train_Yvar</cite>) at this point.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="botorch.models.utils.mod_batch_shape">
<code class="sig-prename descclassname">botorch.models.utils.</code><code class="sig-name descname">mod_batch_shape</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">names</em>, <em class="sig-param">b</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/models/utils.html#mod_batch_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.models.utils.mod_batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Recursive helper to modify gpytorch modules’ batch shape attribute.</p>
<p>Modifies the module in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – The module to be modified.</p></li>
<li><p><strong>names</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – The list of names to access the attribute. If the full name of
the module is <cite>“module.sub_module.leaf_module”</cite>, this will be
<cite>[“sub_module”, “leaf_module”]</cite>.</p></li>
<li><p><strong>b</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The new size of the last element of the module’s <cite>batch_shape</cite>
attribute.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>
</div>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="gen.html">botorch.gen</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="acquisition.html" title="previous chapter">botorch.acquisition</a></li>
<li>Next: <a href="posteriors.html" title="next chapter">botorch.posteriors</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/0.2.2/" class="nav-home"><img src="/v/0.2.2/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/0.2.2/docs/introduction">Introduction</a><a href="/v/0.2.2/docs/getting_started">Getting Started</a><a href="/v/0.2.2/tutorials/">Tutorials</a><a href="/v/0.2.2/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/0.2.2/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2020 Facebook Inc.</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/0.2.2/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div></body></html>