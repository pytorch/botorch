<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/img/botorch.png"/><link rel="shortcut icon" href="/img/botorch.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-2', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/versions"><h3>stable</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="module-botorch.optim">
<span id="botorch-optim"></span><h1>botorch.optim<a class="headerlink" href="#module-botorch.optim" title="Permalink to this headline">¶</a></h1>
<div class="section" id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-botorch.optim.optimize">
<span id="acquisition-function-optimization"></span><h3>Acquisition Function Optimization<a class="headerlink" href="#module-botorch.optim.optimize" title="Permalink to this headline">¶</a></h3>
<p>Methods for optimizing acquisition functions.</p>
<dl class="py function">
<dt id="botorch.optim.optimize.optimize_acqf">
<code class="sig-prename descclassname">botorch.optim.optimize.</code><code class="sig-name descname">optimize_acqf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">acq_function</span></em>, <em class="sig-param"><span class="n">bounds</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">num_restarts</span></em>, <em class="sig-param"><span class="n">raw_samples</span></em>, <em class="sig-param"><span class="n">options</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inequality_constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">equality_constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fixed_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">post_processing_func</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">batch_initial_conditions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_best_only</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sequential</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of candidates via multi-start optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>) – An AcquisitionFunction.</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of samples for initialization.</p></li>
<li><p><strong>options</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]]) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>fixed_features</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]]) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>post_processing_func</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>return_best_only</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If False, outputs the solutions corresponding to all
random restart initializations of the optimization.</p></li>
<li><p><strong>sequential</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If False, uses joint optimization, otherwise uses sequential
optimization.</p></li>
<li><p><strong>Returns</strong> – <p>A two-element tuple containing</p>
<ul>
<li><p>a <cite>(num_restarts) x q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>a tensor of associated acquisiton values. If <cite>sequential=False</cite>,
this is a <cite>(num_restarts)</cite>-dim tensor of joint acquisition values
(with explicit restart dimension if <cite>return_best_only=False</cite>). If
<cite>sequential=True</cite>, this is a <cite>q</cite>-dim tensor of expected acquisition
values conditional on having observed canidates <cite>0,1,…,i-1</cite>.</p></li>
</ul>
</p></li>
<li><p><strong>Example</strong> – <div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=2` candidates jointly using 20 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and 512 raw samples</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span><span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; generate `q=3` candidates sequentially using 15 random restarts
&gt;&gt;&gt; # and 256 raw samples
&gt;&gt;&gt; qEI = qExpectedImprovement(model, best_f=0.2)
&gt;&gt;&gt; bounds = torch.tensor([[0.], [1.]])
&gt;&gt;&gt; candidates, acq_value_list = optimize_acqf(
&gt;&gt;&gt;     qEI, bounds, 3, 15, 256, sequential=True
&gt;&gt;&gt; )
</pre></div>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.optimize.optimize_acqf_cyclic">
<code class="sig-prename descclassname">botorch.optim.optimize.</code><code class="sig-name descname">optimize_acqf_cyclic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">acq_function</span></em>, <em class="sig-param"><span class="n">bounds</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">num_restarts</span></em>, <em class="sig-param"><span class="n">raw_samples</span></em>, <em class="sig-param"><span class="n">options</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inequality_constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">equality_constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fixed_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">post_processing_func</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">batch_initial_conditions</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">cyclic_options</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_cyclic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_cyclic" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of <cite>q</cite> candidates via cyclic optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>) – An AcquisitionFunction</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of samples for initialization</p></li>
<li><p><strong>options</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]]) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>fixed_features</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]]) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>post_processing_func</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – A tensor to specify the initial conditions.
If no initial conditions are provided, the default initialization will
be used.</p></li>
<li><p><strong>cyclic_options</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]]) – Options for stopping criterion for outer cyclic optimization.</p></li>
<li><p><strong>Returns</strong> – <p>A two-element tuple containing</p>
<ul>
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>a <cite>q</cite>-dim tensor of expected acquisition
values, where the <cite>i`th value is the acquistion value conditional on
having observed all candidates except candidate `i</cite>.</p></li>
</ul>
</p></li>
<li><p><strong>Example</strong> – <div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=3` candidates cyclically using 15 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 256 raw samples, and 4 cycles</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value_list</span> <span class="o">=</span> <span class="n">optimize_acqf_cyclic</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">cyclic_options</span><span class="o">=</span><span class="p">{</span><span class="s2">"maxiter"</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.optim.fit">
<span id="model-fitting-optimization"></span><h3>Model Fitting Optimization<a class="headerlink" href="#module-botorch.optim.fit" title="Permalink to this headline">¶</a></h3>
<p>Tools for model fitting.</p>
<dl class="py function">
<dt id="botorch.optim.fit.fit_gpytorch_torch">
<code class="sig-prename descclassname">botorch.optim.fit.</code><code class="sig-name descname">fit_gpytorch_torch</code><span class="sig-paren">(</span><em class="sig-param">mll</em>, <em class="sig-param">bounds=None</em>, <em class="sig-param">optimizer_cls=&lt;class 'torch.optim.adam.Adam'&gt;</em>, <em class="sig-param">options=None</em>, <em class="sig-param">track_iterations=True</em>, <em class="sig-param">approx_mll=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_torch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_torch" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a gpytorch model by maximizing MLL with a torch optimizer.</p>
<p>The model and likelihood in mll must already be in train mode.
Note: this method requires that the model has <cite>train_inputs</cite> and <cite>train_targets</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">MarginalLogLikelihood</span></code>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]]]]) – A ParameterBounds dictionary mapping parameter names to tuples
of lower and upper bounds. Bounds specified here take precedence
over bounds on the same parameters specified in the constraints
registered with the module.</p></li>
<li><p><strong>optimizer_cls</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>) – Torch optimizer to use. Must not require a closure.</p></li>
<li><p><strong>options</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – options for model fitting. Relevant options will be passed to
the <cite>optimizer_cls</cite>. Additionally, options can include: “disp”
to specify whether to display model fitting diagnostics and “maxiter”
to specify the maximum number of iterations.</p></li>
<li><p><strong>track_iterations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Track the function values and wall time for each
iteration.</p></li>
<li><p><strong>approx_mll</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, use gpytorch’s approximate MLL computation (
according to the gpytorch defaults based on the training at size).
Unlike for the deterministic algorithms used in fit_gpytorch_scipy,
this is not an issue for stochastic optimizers.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">MarginalLogLikelihood</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizationIteration</span></code>]]]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>2-element tuple containing
- mll with parameters optimized in-place.
- Dictionary with the following key/values:
“fopt”: Best mll value.
“wall_time”: Wall time of fitting.
“iterations”: List of OptimizationIteration objects with information on each
iteration. If track_iterations is False, will be empty.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">gp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_gpytorch_torch</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.fit.fit_gpytorch_scipy">
<code class="sig-prename descclassname">botorch.optim.fit.</code><code class="sig-name descname">fit_gpytorch_scipy</code><span class="sig-paren">(</span><em class="sig-param">mll</em>, <em class="sig-param">bounds=None</em>, <em class="sig-param">method='L-BFGS-B'</em>, <em class="sig-param">options=None</em>, <em class="sig-param">track_iterations=True</em>, <em class="sig-param">approx_mll=False</em>, <em class="sig-param">scipy_objective=&lt;function _scipy_objective_and_grad&gt;</em>, <em class="sig-param">module_to_array_func=&lt;function module_to_array&gt;</em>, <em class="sig-param">module_from_array_func=&lt;function set_params_with_array&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_scipy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_scipy" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a gpytorch model by maximizing MLL with a scipy optimizer.</p>
<p>The model and likelihood in mll must already be in train mode.
This method requires that the model has <cite>train_inputs</cite> and <cite>train_targets</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">MarginalLogLikelihood</span></code>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]]]]) – A dictionary mapping parameter names to tuples of lower and upper
bounds.</p></li>
<li><p><strong>method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Solver type, passed along to scipy.minimize.</p></li>
<li><p><strong>options</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – Dictionary of solver options, passed along to scipy.minimize.</p></li>
<li><p><strong>track_iterations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Track the function values and wall time for each
iteration.</p></li>
<li><p><strong>approx_mll</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, use gpytorch’s approximate MLL computation. This is
disabled by default since the stochasticity is an issue for
determistic optimizers). Enabling this is only recommended when
working with large training data sets (n&gt;2000).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">MarginalLogLikelihood</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">OptimizationIteration</span></code>]]]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>2-element tuple containing
- MarginalLogLikelihood with parameters optimized in-place.
- Dictionary with the following key/values:
“fopt”: Best mll value.
“wall_time”: Wall time of fitting.
“iterations”: List of OptimizationIteration objects with information on each
iteration. If track_iterations is False, will be empty.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">gp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_gpytorch_scipy</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="module-botorch.optim.initializers">
<span id="initialization-helpers"></span><h3>Initialization Helpers<a class="headerlink" href="#module-botorch.optim.initializers" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt id="botorch.optim.initializers.gen_batch_initial_conditions">
<code class="sig-prename descclassname">botorch.optim.initializers.</code><code class="sig-name descname">gen_batch_initial_conditions</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">acq_function</span></em>, <em class="sig-param"><span class="n">bounds</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">num_restarts</span></em>, <em class="sig-param"><span class="n">raw_samples</span></em>, <em class="sig-param"><span class="n">options</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_batch_initial_conditions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.initializers.gen_batch_initial_conditions" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a batch of initial conditions for random-restart optimziation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.acquisition.AcquisitionFunction" title="botorch.acquisition.acquisition.AcquisitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">AcquisitionFunction</span></code></a>) – The acquisition function to be optimized.</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>options</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – Options for initial condition generation. For valid options see
<cite>initialize_q_batch</cite> and <cite>initialize_q_batch_nonneg</cite>. If <cite>options</cite>
contains a <cite>nonnegative=True</cite> entry, then <cite>acq_function</cite> is
assumed to be non-negative (useful when using custom acquisition
functions).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>num_restarts x q x d</cite> tensor of initial conditions.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_batch_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">500</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.initializers.gen_one_shot_kg_initial_conditions">
<code class="sig-prename descclassname">botorch.optim.initializers.</code><code class="sig-name descname">gen_one_shot_kg_initial_conditions</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">acq_function</span></em>, <em class="sig-param"><span class="n">bounds</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">num_restarts</span></em>, <em class="sig-param"><span class="n">raw_samples</span></em>, <em class="sig-param"><span class="n">options</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_one_shot_kg_initial_conditions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.initializers.gen_one_shot_kg_initial_conditions" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a batch of smart initializations for qKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing one-shot KG using
the maximizer of the posterior objective. Intutively, the maximizer of the
fantasized posterior will often be close to a maximizer of the current
posterior. This function uses that fact to generate the initital conditions
for the fantasy points. Specifically, a fraction of <cite>1 - frac_random</cite> (see
options) is generated by sampling from the set of maximizers of the
posterior objective (obtained via random restart optimization) according to
a softmax transformation of their respective values. This means that this
initialization strategy internally solves an acquisition function
maximization problem. The remaining <cite>frac_random</cite> fantasy points as well as
all <cite>q</cite> candidate points are chosen according to the standard initialization
strategy in <cite>gen_batch_initial_conditions</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><code class="xref py py-class docutils literal notranslate"><span class="pre">qKnowledgeGradient</span></code></a>) – The qKnowledgeGradient instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>q</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>options</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>num_restarts x q’ x d</cite> tensor that can be used as initial conditions
for <cite>optimize_acqf()</cite>. Here <cite>q’ = q + num_fantasies</cite> is the total number
of points (candidate points plus fantasy points).</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qKG</span> <span class="o">=</span> <span class="n">qKnowledgeGradient</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_fantasies</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_one_shot_kg_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qKG</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">"frac_random"</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.initializers.initialize_q_batch">
<code class="sig-prename descclassname">botorch.optim.initializers.</code><code class="sig-name descname">initialize_q_batch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Heuristic for selecting initial conditions for candidate generation.</p>
<p>This heuristic selects points from <cite>X</cite> (without replacement) with probability
proportional to <cite>exp(eta * Z)</cite>, where <cite>Z = (Y - mean(Y)) / std(Y)</cite> and <cite>eta</cite>
is a temperature parameter.</p>
<p>When using an acquisiton function that is non-negative and possibly zero
over large areas of the feature space (e.g. qEI), you should use
<cite>initialize_q_batch_nonneg</cite> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>b x q x d</cite> tensor of <cite>b</cite> samples of <cite>q</cite>-batches from a <cite>d</cite>-dim.
feature space. Typically, these are generated using qMC sampling.</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A tensor of <cite>b</cite> outcomes associated with the samples. Typically, this
is the value of the batch acquisition function to be maximized.</p></li>
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Temperature parameter for weighting samples.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>n x q x d</cite> tensor of <cite>n</cite> <cite>q</cite>-batch initial conditions.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qUCB</span> <span class="o">=</span> <span class="n">qUpperConfidenceBound</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xrnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">initialize_q_batch</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">,</span> <span class="n">qUCB</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.initializers.initialize_q_batch_nonneg">
<code class="sig-prename descclassname">botorch.optim.initializers.</code><code class="sig-name descname">initialize_q_batch_nonneg</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.0001</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch_nonneg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch_nonneg" title="Permalink to this definition">¶</a></dt>
<dd><p>Heuristic for selecting initial conditions for non-neg. acquisition functions.</p>
<p>This function is similar to <cite>initialize_q_batch</cite>, but designed specifically
for acquisition functions that are non-negative and possibly zero over
large areas of the feature space (e.g. qEI). All samples for which
<cite>Y &lt; alpha * max(Y)</cite> will be ignored (assuming that <cite>Y</cite> contains at least
one positive value).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A <cite>b x q x d</cite> tensor of <cite>b</cite> samples of <cite>q</cite>-batches from a <cite>d</cite>-dim.
feature space. Typically, these are generated using qMC.</p></li>
<li><p><strong>Y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – A tensor of <cite>b</cite> outcomes associated with the samples. Typically, this
is the value of the batch acquisition function to be maximized.</p></li>
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Temperature parameter for weighting samples.</p></li>
<li><p><strong>alpha</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The threshold (as a fraction of the maximum observed value) under
which to ignore samples. All input samples for which
<cite>Y &lt; alpha * max(Y)</cite> will be ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>n x q x d</cite> tensor of <cite>n</cite> <cite>q</cite>-batch initial conditions.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xrnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">initialize_q_batch</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">,</span> <span class="n">qEI</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="module-botorch.optim.stopping">
<span id="stopping-criteria"></span><h3>Stopping Criteria<a class="headerlink" href="#module-botorch.optim.stopping" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="botorch.optim.stopping.StoppingCriterion">
<em class="property">class </em><code class="sig-prename descclassname">botorch.optim.stopping.</code><code class="sig-name descname">StoppingCriterion</code><a class="reference internal" href="_modules/botorch/optim/stopping.html#StoppingCriterion"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.stopping.StoppingCriterion" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Base class for evaluating optimization convergence.</p>
<p>Stopping criteria are implemented as a objects rather than a function, so that they
can keep track of past function values between optimization steps.</p>
<dl class="py method">
<dt id="botorch.optim.stopping.StoppingCriterion.evaluate">
<em class="property">abstract </em><code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fvals</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#StoppingCriterion.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.stopping.StoppingCriterion.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fvals</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – tensor containing function values for the current iteration. If
<cite>fvals</cite> contains more than one element, then the stopping criterion is
evaluated element-wise and True is returned if the stopping criterion is
true for all elements.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Stopping indicator (if True, stop the optimziation).</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt id="botorch.optim.stopping.ExpMAStoppingCriterion">
<em class="property">class </em><code class="sig-prename descclassname">botorch.optim.stopping.</code><code class="sig-name descname">ExpMAStoppingCriterion</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">maxiter</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">minimize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">n_window</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">rel_tol</span><span class="o">=</span><span class="default_value">1e-05</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.optim.stopping.StoppingCriterion" title="botorch.optim.stopping.StoppingCriterion"><code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.optim.stopping.StoppingCriterion</span></code></a></p>
<p>Exponential moving average stopping criterion.</p>
<p>Computes an exponentially weighted moving average over window length <cite>n_window</cite>
and checks whether the relative decrease in this moving average between steps
is less than a provided tolerance level. That is, in iteration <cite>i</cite>, it computes</p>
<blockquote>
<div><p>v[i,j] := fvals[i - n_window + j] * w[j]</p>
</div></blockquote>
<p>for all <cite>j = 0, …, n_window</cite>, where <cite>w[j] = exp(-eta * (1 - j / n_window))</cite>.
Letting <cite>ma[i] := sum_j(v[i,j])</cite>, the criterion evaluates to <cite>True</cite> whenever</p>
<blockquote>
<div><p>(ma[i-1] - ma[i]) / abs(ma[i-1]) &lt; rel_tol (if minimize=True)
(ma[i] - ma[i-1]) / abs(ma[i-1]) &lt; rel_tol (if minimize=False)</p>
</div></blockquote>
<p>Exponential moving average stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>maxiter</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Maximum number of iterations.</p></li>
<li><p><strong>minimize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, assume minimization.</p></li>
<li><p><strong>n_window</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The size of the exponential moving average window.</p></li>
<li><p><strong>eta</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The exponential decay factor in the weights.</p></li>
<li><p><strong>rel_tol</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Relative tolerance for termination.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="botorch.optim.stopping.ExpMAStoppingCriterion.evaluate">
<code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fvals</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fvals</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – tensor containing function values for the current iteration. If
<cite>fvals</cite> contains more than one element, then the stopping criterion is
evaluated element-wise and True is returned if the stopping criterion is
true for all elements.</p>
</dd>
</dl>
<p>TODO: add support for utilizing gradient information</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Stopping indicator (if True, stop the optimziation).</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
<div class="section" id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-botorch.optim.numpy_converter">
<span id="numpy-torch-conversion-tools"></span><h3>Numpy - Torch Conversion Tools<a class="headerlink" href="#module-botorch.optim.numpy_converter" title="Permalink to this headline">¶</a></h3>
<p>A converter that simplifies using numpy-based optimizers with generic torch
<cite>nn.Module</cite> classes. This enables using a <cite>scipy.optim.minimize</cite> optimizer
for optimizing module parameters.</p>
<dl class="py class">
<dt id="botorch.optim.numpy_converter.TorchAttr">
<em class="property">class </em><code class="sig-prename descclassname">botorch.optim.numpy_converter.</code><code class="sig-name descname">TorchAttr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shape</span></em>, <em class="sig-param"><span class="n">dtype</span></em>, <em class="sig-param"><span class="n">device</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/numpy_converter.html#TorchAttr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.numpy_converter.TorchAttr" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<p>Create new instance of TorchAttr(shape, dtype, device)</p>
<dl class="py method">
<dt id="botorch.optim.numpy_converter.TorchAttr.shape">
<em class="property">property </em><code class="sig-name descname">shape</code><a class="headerlink" href="#botorch.optim.numpy_converter.TorchAttr.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>
<dl class="py method">
<dt id="botorch.optim.numpy_converter.TorchAttr.dtype">
<em class="property">property </em><code class="sig-name descname">dtype</code><a class="headerlink" href="#botorch.optim.numpy_converter.TorchAttr.dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>
<dl class="py method">
<dt id="botorch.optim.numpy_converter.TorchAttr.device">
<em class="property">property </em><code class="sig-name descname">device</code><a class="headerlink" href="#botorch.optim.numpy_converter.TorchAttr.device" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.numpy_converter.module_to_array">
<code class="sig-prename descclassname">botorch.optim.numpy_converter.</code><code class="sig-name descname">module_to_array</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span></em>, <em class="sig-param"><span class="n">bounds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">exclude</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/numpy_converter.html#module_to_array"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.numpy_converter.module_to_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract named parameters from a module into a numpy array.</p>
<p>Only extracts parameters with requires_grad, since it is meant for optimizing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – A module with parameters. May specify parameter constraints in
a <cite>named_parameters_and_constraints</cite> method.</p></li>
<li><p><strong>bounds</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]]]]) – A ParameterBounds dictionary mapping parameter names to tuples
of lower and upper bounds. Bounds specified here take precedence
over bounds on the same parameters specified in the constraints
registered with the module.</p></li>
<li><p><strong>exclude</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Set</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]) – A list of parameter names that are to be excluded from extraction.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <a class="reference internal" href="#botorch.optim.numpy_converter.TorchAttr" title="botorch.optim.numpy_converter.TorchAttr"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchAttr</span></code></a>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>3-element tuple containing
- The parameter values as a numpy array.
- An ordered dictionary with the name and tensor attributes of each
parameter.
- A <cite>2 x n_params</cite> numpy array with lower and upper bounds if at least
one constraint is finite, and None otherwise.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameter_array</span><span class="p">,</span> <span class="n">property_dict</span><span class="p">,</span> <span class="n">bounds_out</span> <span class="o">=</span> <span class="n">module_to_array</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.numpy_converter.set_params_with_array">
<code class="sig-prename descclassname">botorch.optim.numpy_converter.</code><code class="sig-name descname">set_params_with_array</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">property_dict</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/numpy_converter.html#set_params_with_array"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.numpy_converter.set_params_with_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Set module parameters with values from numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – Module with parameters to be set</p></li>
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>) – Numpy array with parameter values</p></li>
<li><p><strong>property_dict</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <a class="reference internal" href="#botorch.optim.numpy_converter.TorchAttr" title="botorch.optim.numpy_converter.TorchAttr"><code class="xref py py-class docutils literal notranslate"><span class="pre">TorchAttr</span></code></a>]) – Dictionary of parameter names and torch attributes as
returned by module_to_array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>module with parameters updated in-place.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameter_array</span><span class="p">,</span> <span class="n">property_dict</span><span class="p">,</span> <span class="n">bounds_out</span> <span class="o">=</span> <span class="n">module_to_array</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameter_array</span> <span class="o">+=</span> <span class="mf">0.1</span>  <span class="c1"># perturb parameters (for example only)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">set_params_with_array</span><span class="p">(</span><span class="n">mll</span><span class="p">,</span> <span class="n">parameter_array</span><span class="p">,</span>  <span class="n">property_dict</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="module-botorch.optim.parameter_constraints">
<span id="parameter-constraint-utilities"></span><h3>Parameter Constraint Utilities<a class="headerlink" href="#module-botorch.optim.parameter_constraints" title="Permalink to this headline">¶</a></h3>
<p>Utility functions for constrained optimization.</p>
<dl class="py function">
<dt id="botorch.optim.parameter_constraints.make_scipy_bounds">
<code class="sig-prename descclassname">botorch.optim.parameter_constraints.</code><code class="sig-name descname">make_scipy_bounds</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">lower_bounds</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">upper_bounds</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_bounds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a scipy Bounds object for optimziation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – <cite>… x d</cite> tensor</p></li>
<li><p><strong>lower_bounds</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>]) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
<li><p><strong>upper_bounds</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>]) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Bounds</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A scipy <cite>Bounds</cite> object if either lower_bounds or upper_bounds is not
None, and None otherwise.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scipy_bounds</span> <span class="o">=</span> <span class="n">make_scipy_bounds</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.parameter_constraints.make_scipy_linear_constraints">
<code class="sig-prename descclassname">botorch.optim.parameter_constraints.</code><code class="sig-name descname">make_scipy_linear_constraints</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shapeX</span></em>, <em class="sig-param"><span class="n">inequality_constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">equality_constraints</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_linear_constraints"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_linear_constraints" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate scipy constraints from torch representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shapeX</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Size</span></code>) – The shape of the torch.Tensor to optimize over (i.e. <cite>b x q x d</cite>)</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>, where
<cite>indices</cite> is a single-dimensional index tensor (long dtype) containing
indices into the last dimension of <cite>X</cite>, <cite>coefficients</cite> is a
single-dimensional tensor of coefficients of the same length, and
rhs is a scalar.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) == rhs</cite> (with <cite>indices</cite>
and <cite>coefficients</cite> of the same form as in <cite>inequality_constraints</cite>).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]]]]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A list of dictionaries containing callables for constraint function
values and Jacobians and a string indicating the associated constraint
type (“eq”, “ineq”), as expected by <cite>scipy.minimize</cite>.</p>
</dd>
</dl>
<p>This function assumes that constraints are the same for each input batch,
and broadcasts the constraints accordingly to the input batch shape. This
function does support constraints across elements of a q-batch if the
indices are a 2-d Tensor.</p>
<p class="rubric">Example</p>
<p>The following will enforce that <cite>x[1] + 0.5 x[3] &gt;= -0.1</cite> for each <cite>x</cite>
in both elements of the q-batch, and each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>The following will enforce that <cite>x[0, 1] + 0.5 x[1, 3] &gt;= -0.1</cite> where
x[0, :] is the first element of the q-batch and x[1, :] is the second
element of the q-batch, for each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.parameter_constraints.eval_lin_constraint">
<code class="sig-prename descclassname">botorch.optim.parameter_constraints.</code><code class="sig-name descname">eval_lin_constraint</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">flat_idxr</span></em>, <em class="sig-param"><span class="n">coeffs</span></em>, <em class="sig-param"><span class="n">rhs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#eval_lin_constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.eval_lin_constraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate a single linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The indices in <cite>x</cite> to consider.</p></li>
<li><p><strong>coeffs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>rhs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The right-hand-side of the constraint.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><cite>sum_i (coeffs[i] * x[i]) - rhs</cite></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The evaluted constraint</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.parameter_constraints.lin_constraint_jac">
<code class="sig-prename descclassname">botorch.optim.parameter_constraints.</code><code class="sig-name descname">lin_constraint_jac</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">flat_idxr</span></em>, <em class="sig-param"><span class="n">coeffs</span></em>, <em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#lin_constraint_jac"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.lin_constraint_jac" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the Jacobian associated with a linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]) – The indices for the elements of x that appear in the constraint.</p></li>
<li><p><strong>coeffs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of elements</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The Jacobian.</p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-botorch.optim.utils">
<span id="general-optimization-utilities"></span><h3>General Optimization Utilities<a class="headerlink" href="#module-botorch.optim.utils" title="Permalink to this headline">¶</a></h3>
<p>Utilities for optimization.</p>
<dl class="py function">
<dt id="botorch.optim.utils.sample_all_priors">
<code class="sig-prename descclassname">botorch.optim.utils.</code><code class="sig-name descname">sample_all_priors</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils.html#sample_all_priors"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.utils.sample_all_priors" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample from hyperparameter priors (in-place).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="models.html#botorch.models.gpytorch.GPyTorchModel" title="botorch.models.gpytorch.GPyTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPyTorchModel</span></code></a>) – A GPyTorchModel.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.utils.columnwise_clamp">
<code class="sig-prename descclassname">botorch.optim.utils.</code><code class="sig-name descname">columnwise_clamp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">lower</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">upper</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">raise_on_violation</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils.html#columnwise_clamp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.utils.columnwise_clamp" title="Permalink to this definition">¶</a></dt>
<dd><p>Clamp values of a Tensor in column-wise fashion (with support for t-batches).</p>
<p>This function is useful in conjunction with optimizers from the torch.optim
package, which don’t natively handle constraints. If you apply this after
a gradient step you can be fancy and call it “projected gradient descent”.
This funtion is also useful for post-processing candidates generated by the
scipy optimizer that satisfy bounds only up to numerical accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – The <cite>b x n x d</cite> input tensor. If 2-dimensional, <cite>b</cite> is assumed to be 1.</p></li>
<li><p><strong>lower</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>]) – The column-wise lower bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>upper</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>]) – The column-wise upper bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>raise_on_violation</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If <cite>True</cite>, raise an exception when the elments in <cite>X</cite>
are out of the specified bounds (up to numerical accuracy). This is
useful for post-processing candidates generated by optimizers that
satisfy imposed bounds only up to numerical accuracy.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The clamped tensor.</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt id="botorch.optim.utils.fix_features">
<code class="sig-prename descclassname">botorch.optim.utils.</code><code class="sig-name descname">fix_features</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">fixed_features</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils.html#fix_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#botorch.optim.utils.fix_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Fix feature values in a Tensor.</p>
<p>The fixed features will have zero gradient in downstream calculations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – input Tensor with shape <cite>… x p</cite>, where <cite>p</cite> is the number of features</p></li>
<li><p><strong>fixed_features</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]]]) – A dictionary with keys as column indices and values
equal to what the feature should be set to in <cite>X</cite>. If the value is
None, that column is just considered fixed. Keys should be in the
range <cite>[0, p - 1]</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The tensor X with fixed features.</p>
</dd>
</dl>
</dd></dl>
</div>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="gen.html">Generation utilities [DEPRECATED - use botorch.generation.gen]</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="posteriors.html" title="previous chapter">botorch.posteriors</a></li>
<li>Next: <a href="fit.html" title="next chapter">botorch.fit</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/getting_started">Getting Started</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2020 Facebook Inc.</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'botorch',
                inputSelector: '#search_input_react'
              });
            </script></body></html>