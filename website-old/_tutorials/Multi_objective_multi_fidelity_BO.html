
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<div class="notebook">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Multi-fidelity-Multi-Objective-optimization">Multi-fidelity Multi-Objective optimization<a class="anchor-link" href="#Multi-fidelity-Multi-Objective-optimization">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial notebook we demonstrate how to perform multi-objective multi-fidelity optimization in BoTorch using the multi-fidelity Hypervolume Knowledge Gradient (MF-HVKG) [3] and a method called Multi-Objective Multi-Fidelity (MOMF) [1].</p>
<p>MF-HVKG performs one-step lookahead: it operates under the assumption that we can make one additional observation, and after receiving that additional observation, we will select the Pareto set of optimal designs. HVKG seeks to select the design <code>x</code> to evaluate that maximizes the value of information about the Pareto set by maximizing the hypervolume under the posterior mean (conditional on receiving on new observation for the design <code>x</code>).</p>
<p>MOMF is an alternative approach that introduces an additional "fidelity objective" that is optimized along with the problem objectives. This fidelity objective can be thought of as a trust objective that rewards the optimization when going to higher fidelity. Thus, the MOMF explicitly optimizes for getting more high-fidelity (trustworthy) data while taking into account the higher computational costs associated with it.</p>
<p>HVKG is generally more cost efficient [3], since it explicitly targets the goal of MF optimization: select design points and fidelities that enable identifying about the Pareto Frontier at the target fidelity in a cost-aware fashion. MOMF will typically result in faster candidate generation. If the application is high-throughput and requires fast candidate generation, MOMF will be preferable. Otherwise, MF-HVKG will likely give better sample efficiency and performance [3].</p>
<p>In this tutorial, we will optimize a synthetic function that is a modified multi-fidelity Branin-Currin [1]. This is a 3-dimesional, bi-objective problem with one of the input dimensions being the fidelity. For the MOMF, this results in a 3-objective problem since it also takes the fidelity objective into account. In this case the fidelity objective is a linear function of fidelity, $ f(s)=s$, where $s$ is the fidelity. The MOMF algorithm can accept any discrete or continuous cost functions as an input. In this example, we choose an exponential dependency of the form $C(s)=\exp(4.8s)$. The goal of the optimization is to find the Pareto front, which is a trade-off solution set for Multi-objective problems, at the highest fidelity.</p>
<p>Note: pymoo is an optional dependency that is used for determining the Pareto set of optimal designs under the model posterior mean using NSGA-II (which is not a sample efficient method, but sample efficiency is not critical for this step). If pymoo is not available, the Pareto set of optimal designs is selected from a discrete set. This will work okay for low-dim (e.g.
dimensions) problems, but in general NSGA-II will yield far better results.</p>
<p>[1] <a href="https://arxiv.org/abs/2112.13901">Irshad, Faran, Stefan Karsch, and Andreas Döpp. "Expected hypervolume improvement for simultaneous multi-objective and multi-fidelity optimization." arXiv preprint arXiv:2112.13901 (2021).</a></p>
<p>[2] <a href="https://proceedings.neurips.cc/paper/2021/hash/11704817e347269b7254e744b5e22dac-Abstract.html">S. Daulton, M. Balandat, and E. Bakshy. Parallel Bayesian Optimization of Multiple Noisy Objectives. NeurIPS, 2021.</a></p>
<p>[3] <a href="https://proceedings.mlr.press/v202/daulton23a.html">S. Daulton, M. Balandat, and E. Bakshy. Hypervolume Knowledge Gradient for Multi-Objective Bayesian Optimization with Partial Information. ICML, 2023.</a></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Set-dtype-and-device">Set dtype and device<a class="anchor-link" href="#Set-dtype-and-device">¶</a></h3><p>Setting up the global variable that determine the device to run the optimization. The optimization is much faster when it runs on GPU.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span>  <span class="c1"># Tkwargs is a dictionary contaning data about data type and data device</span>
    <span class="s2">"dtype"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
    <span class="s2">"device"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">),</span>
<span class="p">}</span>
<span class="n">SMOKE_TEST</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"SMOKE_TEST"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Define-the-problem-and-optimization-settings">Define the problem and optimization settings<a class="anchor-link" href="#Define-the-problem-and-optimization-settings">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">botorch.test_functions.multi_objective_multi_fidelity</span> <span class="kn">import</span> <span class="n">MOMFBraninCurrin</span>

<span class="n">BC</span> <span class="o">=</span> <span class="n">MOMFBraninCurrin</span><span class="p">(</span><span class="n">negate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
<span class="n">dim_x</span> <span class="o">=</span> <span class="n">BC</span><span class="o">.</span><span class="n">dim</span>
<span class="n">dim_y</span> <span class="o">=</span> <span class="n">BC</span><span class="o">.</span><span class="n">num_objectives</span>

<span class="n">ref_point</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dim_y</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>


<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># For batch optimization, BATCH_SIZE should be greater than 1</span>
<span class="c1"># This evaluation budget is set to be very low to make the notebook run fast. This should be much higher.</span>
<span class="n">EVAL_BUDGET</span> <span class="o">=</span> <span class="mf">2.05</span>  <span class="c1"># in terms of the number of full-fidelity evaluations</span>
<span class="n">n_INIT</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Initialization budget in terms of the number of full-fidelity evaluations</span>
<span class="c1"># Number of Monte Carlo samples, used to approximate MOMF</span>
<span class="n">MC_SAMPLES</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">128</span>
<span class="c1"># Number of restart points for multi-start optimization</span>
<span class="n">NUM_RESTARTS</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">10</span>
<span class="c1"># Number of raw samples for initial point selection heuristic</span>
<span class="n">RAW_SAMPLES</span> <span class="o">=</span> <span class="mi">4</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">512</span>

<span class="n">standard_bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim_x</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
<span class="n">standard_bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># mapping from index to target fidelity (highest fidelity)</span>
<span class="n">target_fidelities</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Helper-functions-to-define-Cost">Helper functions to define Cost<a class="anchor-link" href="#Helper-functions-to-define-Cost">¶</a></h3><p>The cost_func function returns an exponential cost from the fidelity. The cost_callable is a wrapper around it that takes care of the input output shapes. This is provided to the MF algorithms which inversely weight the expected utility by the cost.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">exp</span>


<span class="k">def</span> <span class="nf">cost_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A simple exponential cost function."""</span>
    <span class="n">exp_arg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">4.8</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">exp_arg</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">val</span>


<span class="c1"># Displaying the min and max costs for this optimization</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Min Cost: </span><span class="si">{</span><span class="n">cost_func</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Max Cost: </span><span class="si">{</span><span class="n">cost_func</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">cost_callable</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""Wrapper for the cost function that takes care of shaping</span>
<span class="sd">    input and output arrays for interfacing with cost_func.</span>
<span class="sd">    This is passed as a callable function to MOMF.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x q x d`-dim Tensor</span>
<span class="sd">    Returns:</span>
<span class="sd">        Cost `batch_shape x q x m`-dim Tensor of cost generated</span>
<span class="sd">        from fidelity dimension using cost_func.</span>
<span class="sd">    """</span>

    <span class="k">return</span> <span class="n">cost_func</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Min Cost: 1.0
Max Cost: 121.51041751873485
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-Initialization">Model Initialization<a class="anchor-link" href="#Model-Initialization">¶</a></h3><p>We use a multi-output SingleTaskGP to model the problem with a homoskedastic Gaussian likelihood with an inferred noise level.
The model is initialized with random points, where the fidelity is sampled from a probability distribution with a PDF that is inversely proportional to the cost: $p(s)=C(s)^{-1}$. The initialization is given a budget equivalent to 2 full-fidelity evaluations.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">botorch.models.gp_regression</span> <span class="kn">import</span> <span class="n">SingleTaskGP</span>
<span class="kn">from</span> <span class="nn">botorch.models.model_list_gp_regression</span> <span class="kn">import</span> <span class="n">ModelListGP</span>
<span class="kn">from</span> <span class="nn">botorch.models.transforms.outcome</span> <span class="kn">import</span> <span class="n">Standardize</span>
<span class="kn">from</span> <span class="nn">botorch.utils.transforms</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="kn">from</span> <span class="nn">gpytorch.kernels</span> <span class="kn">import</span> <span class="n">MaternKernel</span><span class="p">,</span> <span class="n">ScaleKernel</span>
<span class="kn">from</span> <span class="nn">gpytorch.mlls.sum_marginal_log_likelihood</span> <span class="kn">import</span> <span class="n">SumMarginalLogLikelihood</span>
<span class="kn">from</span> <span class="nn">gpytorch.priors</span> <span class="kn">import</span> <span class="n">GammaPrior</span>


<span class="k">def</span> <span class="nf">inv_transform</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
    <span class="c1"># define inverse transform to sample from the probability distribution with</span>
    <span class="c1"># PDF proportional to 1/(c(x))</span>
    <span class="c1"># u is a uniform(0,1) rv</span>
    <span class="k">return</span> <span class="mi">5</span> <span class="o">/</span> <span class="mi">24</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">exp</span><span class="p">(</span><span class="mi">24</span> <span class="o">/</span> <span class="mi">5</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="mi">24</span> <span class="o">/</span> <span class="mi">5</span><span class="p">)</span> <span class="o">*</span> <span class="n">u</span> <span class="o">-</span> <span class="n">u</span> <span class="o">-</span> <span class="n">exp</span><span class="p">(</span><span class="mi">24</span> <span class="o">/</span> <span class="mi">5</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">gen_init_data</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    Generates the initial data. Sample fidelities inversely proportional to cost.</span>
<span class="sd">    """</span>
    <span class="c1"># total cost budget is n</span>
    <span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
        <span class="mi">0</span><span class="p">,</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>
    <span class="n">total_cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># assume target fidelity is 1</span>
    <span class="n">total_cost_limit</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">n</span>
        <span class="o">*</span> <span class="n">cost_callable</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="k">while</span> <span class="n">total_cost</span> <span class="o">&lt;</span> <span class="n">total_cost_limit</span><span class="p">:</span>
        <span class="n">new_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="n">new_x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">inv_transform</span><span class="p">(</span><span class="n">new_x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">total_cost</span> <span class="o">+=</span> <span class="n">cost_callable</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
        <span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">train_x</span><span class="p">,</span> <span class="n">new_x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_x</span> <span class="o">=</span> <span class="n">train_x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">train_obj</span> <span class="o">=</span> <span class="n">BC</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_obj</span>


<span class="k">def</span> <span class="nf">initialize_model</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_obj</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Initializes a ModelList with Matern 5/2 Kernel and returns the model and its MLL.</span>

<span class="sd">    Note: a batched model could also be used here.</span>
<span class="sd">    """</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">train_obj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span>
            <span class="n">train_x</span><span class="p">,</span>
            <span class="n">train_obj</span><span class="p">[:,</span> <span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">train_Yvar</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">train_obj</span><span class="p">[:,</span> <span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="mf">1e-6</span><span class="p">),</span>
            <span class="n">outcome_transform</span><span class="o">=</span><span class="n">Standardize</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">covar_module</span><span class="o">=</span><span class="n">ScaleKernel</span><span class="p">(</span>
                <span class="n">MaternKernel</span><span class="p">(</span>
                    <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
                    <span class="n">ard_num_dims</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">lengthscale_prior</span><span class="o">=</span><span class="n">GammaPrior</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="n">outputscale_prior</span><span class="o">=</span><span class="n">GammaPrior</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ModelListGP</span><span class="p">(</span><span class="o">*</span><span class="n">models</span><span class="p">)</span>
    <span class="n">mll</span> <span class="o">=</span> <span class="n">SumMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">state_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mll</span><span class="p">,</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Helper-function-to-optimize-acquisition-function">Helper function to optimize acquisition function<a class="anchor-link" href="#Helper-function-to-optimize-acquisition-function">¶</a></h3><p>This is a helper function that initializes, optimizes the acquisition function MOMF and returns the new_x and new_obj. The problem is called from within this helper function.</p>
<p>A simple initialization heuristic is used to select the 20 restart initial locations from a set of 1024 random points. Multi-start optimization of the acquisition function is performed using LBFGS-B with exact gradients computed via auto-differentiation.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">botorch.acquisition.multi_objective.multi_fidelity</span> <span class="kn">import</span> <span class="n">MOMF</span>
<span class="kn">from</span> <span class="nn">botorch.optim.optimize</span> <span class="kn">import</span> <span class="n">optimize_acqf</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.normal</span> <span class="kn">import</span> <span class="n">SobolQMCNormalSampler</span>
<span class="kn">from</span> <span class="nn">botorch.utils.multi_objective.box_decompositions.non_dominated</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">FastNondominatedPartitioning</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.utils.transforms</span> <span class="kn">import</span> <span class="n">unnormalize</span>


<span class="n">dim_y_momf</span> <span class="o">=</span> <span class="n">dim_y</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Output Dimesnion for MOMF optimization</span>
<span class="n">ref_point_momf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dim_y_momf</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fid_obj</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    A Fidelity Objective that can be thought of as a trust objective.</span>
<span class="sd">    Higher Fidelity simulations are rewarded as being more</span>
<span class="sd">    trustworthy. Here we consider just a linear fidelity objective.</span>
<span class="sd">    """</span>
    <span class="n">fid_obj</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">fid_obj</span>


<span class="k">def</span> <span class="nf">get_objective_momf</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Wrapper around the Objective function to take care of fid_obj stacking"""</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">BC</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># The Branin-Currin is called</span>
    <span class="n">fid</span> <span class="o">=</span> <span class="n">fid_obj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Getting the fidelity objective values</span>
    <span class="n">fid_out</span> <span class="o">=</span> <span class="n">fid</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Concatenating objective values with fid_objective</span>
    <span class="n">y_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">fid_out</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_out</span>


<span class="k">def</span> <span class="nf">optimize_MOMF_and_get_obs</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">SingleTaskGP</span><span class="p">,</span>
    <span class="n">train_obj</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">SobolQMCNormalSampler</span><span class="p">,</span>
    <span class="n">ref_point</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">standard_bounds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">BATCH_SIZE</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">cost_call</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Wrapper to call MOMF and optimizes it in a sequential greedy</span>
<span class="sd">    fashion returning a new candidate and evaluation</span>
<span class="sd">    """</span>
    <span class="n">partitioning</span> <span class="o">=</span> <span class="n">FastNondominatedPartitioning</span><span class="p">(</span><span class="n">ref_point</span><span class="o">=</span><span class="n">ref_point</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">train_obj</span><span class="p">)</span>
    <span class="n">acq_func</span> <span class="o">=</span> <span class="n">MOMF</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">ref_point</span><span class="o">=</span><span class="n">ref_point</span><span class="p">,</span>  <span class="c1"># use known reference point</span>
        <span class="n">partitioning</span><span class="o">=</span><span class="n">partitioning</span><span class="p">,</span>
        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
        <span class="n">cost_call</span><span class="o">=</span><span class="n">cost_call</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Optimization</span>
    <span class="n">candidates</span><span class="p">,</span> <span class="n">vals</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span>
        <span class="n">acq_function</span><span class="o">=</span><span class="n">acq_func</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">standard_bounds</span><span class="p">,</span>
        <span class="n">q</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
        <span class="n">num_restarts</span><span class="o">=</span><span class="n">NUM_RESTARTS</span><span class="p">,</span>
        <span class="n">raw_samples</span><span class="o">=</span><span class="n">RAW_SAMPLES</span><span class="p">,</span>  <span class="c1"># used for intialization heuristic</span>
        <span class="n">options</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">"batch_limit"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">"maxiter"</span><span class="p">:</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">200</span><span class="p">,</span>
            <span class="s2">"nonnegative"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">sequential</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># if the AF val is 0, set the fidelity parameter to zero</span>
    <span class="k">if</span> <span class="n">vals</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">candidates</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># observe new values</span>
    <span class="n">new_x</span> <span class="o">=</span> <span class="n">unnormalize</span><span class="p">(</span><span class="n">candidates</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">bounds</span><span class="o">=</span><span class="n">standard_bounds</span><span class="p">)</span>
    <span class="n">new_obj</span> <span class="o">=</span> <span class="n">get_objective_momf</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_obj</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Define-helper-functions-for-MF-HVKG">Define helper functions for MF-HVKG<a class="anchor-link" href="#Define-helper-functions-for-MF-HVKG">¶</a></h3><p><code>get_current_value</code> optimizes the current posterior mean at the full fidelity to determine the hypervolume under the current model.</p>
<p><code>optimize_HVKG_and_get_obs</code> creates the MF-HVKG acquisition function, optimizes it, and returns the new design and corresponding observation.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">botorch.acquisition.cost_aware</span> <span class="kn">import</span> <span class="n">InverseCostWeightedUtility</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.fixed_feature</span> <span class="kn">import</span> <span class="n">FixedFeatureAcquisitionFunction</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.multi_objective.hypervolume_knowledge_gradient</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_get_hv_value_function</span><span class="p">,</span>
    <span class="n">qMultiFidelityHypervolumeKnowledgeGradient</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.utils</span> <span class="kn">import</span> <span class="n">project_to_target_fidelity</span>
<span class="kn">from</span> <span class="nn">botorch.models.deterministic</span> <span class="kn">import</span> <span class="n">GenericDeterministicModel</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">NUM_INNER_MC_SAMPLES</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">32</span>
<span class="n">NUM_PARETO</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">10</span>
<span class="n">NUM_FANTASIES</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">8</span>


<span class="k">def</span> <span class="nf">get_current_value</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">SingleTaskGP</span><span class="p">,</span>
    <span class="n">ref_point</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">normalized_target_fidelities</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Helper to get the hypervolume of the current hypervolume</span>
<span class="sd">    maximizing set.</span>
<span class="sd">    """</span>
    <span class="n">fidelity_dims</span><span class="p">,</span> <span class="n">fidelity_targets</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">normalized_target_fidelities</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
    <span class="c1"># optimize</span>
    <span class="n">non_fidelity_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dim_x</span><span class="p">))</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">fidelity_dims</span><span class="p">))</span>
    <span class="n">curr_val_acqf</span> <span class="o">=</span> <span class="n">FixedFeatureAcquisitionFunction</span><span class="p">(</span>
        <span class="n">acq_function</span><span class="o">=</span><span class="n">_get_hv_value_function</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">ref_point</span><span class="o">=</span><span class="n">ref_point</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">SobolQMCNormalSampler</span><span class="p">(</span>
                <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">NUM_INNER_MC_SAMPLES</span><span class="p">]),</span>
            <span class="p">),</span>
            <span class="n">use_posterior_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">d</span><span class="o">=</span><span class="n">dim_x</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">fidelity_dims</span><span class="p">,</span>
        <span class="n">values</span><span class="o">=</span><span class="n">fidelity_targets</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># optimize</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">current_value</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span>
        <span class="n">acq_function</span><span class="o">=</span><span class="n">curr_val_acqf</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">[:,</span> <span class="n">non_fidelity_dims</span><span class="p">],</span>
        <span class="n">q</span><span class="o">=</span><span class="n">NUM_PARETO</span><span class="p">,</span>
        <span class="n">num_restarts</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">raw_samples</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">RAW_SAMPLES</span><span class="p">,</span>
        <span class="n">return_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">options</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">"nonnegative"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">"maxiter"</span><span class="p">:</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">200</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">current_value</span>


<span class="n">normalized_target_fidelities</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">fidelity</span> <span class="ow">in</span> <span class="n">target_fidelities</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">standard_bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="n">standard_bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">normalized_target_fidelities</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fidelity</span> <span class="o">-</span> <span class="n">lb</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">ub</span> <span class="o">-</span> <span class="n">lb</span><span class="p">)</span>
<span class="n">project_d</span> <span class="o">=</span> <span class="n">dim_x</span>


<span class="k">def</span> <span class="nf">project</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>

    <span class="k">return</span> <span class="n">project_to_target_fidelity</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">d</span><span class="o">=</span><span class="n">project_d</span><span class="p">,</span>
        <span class="n">target_fidelities</span><span class="o">=</span><span class="n">normalized_target_fidelities</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">optimize_HVKG_and_get_obs</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">SingleTaskGP</span><span class="p">,</span>
    <span class="n">ref_point</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">standard_bounds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">BATCH_SIZE</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">cost_call</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Utility to initialize and optimize HVKG."""</span>
    <span class="n">cost_model</span> <span class="o">=</span> <span class="n">GenericDeterministicModel</span><span class="p">(</span><span class="n">cost_call</span><span class="p">)</span>
    <span class="n">cost_aware_utility</span> <span class="o">=</span> <span class="n">InverseCostWeightedUtility</span><span class="p">(</span><span class="n">cost_model</span><span class="o">=</span><span class="n">cost_model</span><span class="p">)</span>
    <span class="n">current_value</span> <span class="o">=</span> <span class="n">get_current_value</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">ref_point</span><span class="o">=</span><span class="n">ref_point</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">standard_bounds</span><span class="p">,</span>
        <span class="n">normalized_target_fidelities</span><span class="o">=</span><span class="n">normalized_target_fidelities</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">acq_func</span> <span class="o">=</span> <span class="n">qMultiFidelityHypervolumeKnowledgeGradient</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">ref_point</span><span class="o">=</span><span class="n">ref_point</span><span class="p">,</span>  <span class="c1"># use known reference point</span>
        <span class="n">num_fantasies</span><span class="o">=</span><span class="n">NUM_FANTASIES</span><span class="p">,</span>
        <span class="n">num_pareto</span><span class="o">=</span><span class="n">NUM_PARETO</span><span class="p">,</span>
        <span class="n">current_value</span><span class="o">=</span><span class="n">current_value</span><span class="p">,</span>
        <span class="n">cost_aware_utility</span><span class="o">=</span><span class="n">cost_aware_utility</span><span class="p">,</span>
        <span class="n">target_fidelities</span><span class="o">=</span><span class="n">normalized_target_fidelities</span><span class="p">,</span>
        <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Optimization</span>
    <span class="n">candidates</span><span class="p">,</span> <span class="n">vals</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span>
        <span class="n">acq_function</span><span class="o">=</span><span class="n">acq_func</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">standard_bounds</span><span class="p">,</span>
        <span class="n">q</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
        <span class="n">num_restarts</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">raw_samples</span><span class="o">=</span><span class="n">RAW_SAMPLES</span><span class="p">,</span>  <span class="c1"># used for intialization heuristic</span>
        <span class="n">options</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">"batch_limit"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">"maxiter"</span><span class="p">:</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">200</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="c1"># if the AF val is 0, set the fidelity parameter to zero</span>
    <span class="k">if</span> <span class="n">vals</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">candidates</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># observe new values</span>
    <span class="n">new_x</span> <span class="o">=</span> <span class="n">unnormalize</span><span class="p">(</span><span class="n">candidates</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">bounds</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
    <span class="n">new_obj</span> <span class="o">=</span> <span class="n">BC</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_obj</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Define-helper-functions-for-MF-HVKG">Define helper functions for MF-HVKG<a class="anchor-link" href="#Define-helper-functions-for-MF-HVKG">¶</a></h3><p>We run MOMF to optimize the multi-fidelity versions of the Branin-Currin functions. The optimization loop works in the following sequence.</p>
<ol>
<li>At the start with an initialization equivalent to 2 full fidelity evaluations.</li>
<li>The models are used to generate an acquisition function that is optimized to select new input parameters</li>
<li>The objective function is evaluated at the suggested new_x and returns a new_obj.</li>
<li>The models are updated with the new points and then are used again to make the next prediction.</li>
</ol>
<p>The evaluation budget for the optimization is set to 4 full fidelity evaluations.</p>
<p>Note: running this takes some time.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">botorch</span> <span class="kn">import</span> <span class="n">fit_gpytorch_mll</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="c1"># Intializing train_x to zero</span>
<span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">train_x_momf</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">gen_init_data</span><span class="p">(</span><span class="n">n_INIT</span><span class="p">)</span>
<span class="n">train_obj_momf</span> <span class="o">=</span> <span class="n">get_objective_momf</span><span class="p">(</span><span class="n">train_x_momf</span><span class="p">)</span>
<span class="c1"># Generate Sampler</span>
<span class="n">momf_sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">MC_SAMPLES</span><span class="p">]))</span>

<span class="c1"># run N_BATCH rounds of BayesOpt after the initial random batch</span>
<span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_cost</span> <span class="o">=</span> <span class="n">cost_callable</span><span class="p">(</span><span class="n">train_x_momf</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="k">while</span> <span class="n">total_cost</span> <span class="o">&lt;</span> <span class="n">EVAL_BUDGET</span> <span class="o">*</span> <span class="n">cost_func</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cost: </span><span class="si">{</span><span class="n">total_cost</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># reinitialize the models so they are ready for fitting on next iteration</span>
    <span class="n">mll</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">initialize_model</span><span class="p">(</span><span class="n">normalize</span><span class="p">(</span><span class="n">train_x_momf</span><span class="p">,</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="p">),</span> <span class="n">train_obj_momf</span><span class="p">)</span>

    <span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="o">=</span><span class="n">mll</span><span class="p">)</span>  <span class="c1"># Fit the model</span>

    <span class="c1"># optimize acquisition functions and get new observations</span>
    <span class="n">new_x</span><span class="p">,</span> <span class="n">new_obj</span> <span class="o">=</span> <span class="n">optimize_MOMF_and_get_obs</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">train_obj</span><span class="o">=</span><span class="n">train_obj_momf</span><span class="p">,</span>
        <span class="n">sampler</span><span class="o">=</span><span class="n">momf_sampler</span><span class="p">,</span>
        <span class="n">ref_point</span><span class="o">=</span><span class="n">ref_point_momf</span><span class="p">,</span>
        <span class="n">standard_bounds</span><span class="o">=</span><span class="n">standard_bounds</span><span class="p">,</span>
        <span class="n">BATCH_SIZE</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
        <span class="n">cost_call</span><span class="o">=</span><span class="n">cost_callable</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Updating train_x and train_obj</span>
    <span class="n">train_x_momf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">train_x_momf</span><span class="p">,</span> <span class="n">new_x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_obj_momf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">train_obj_momf</span><span class="p">,</span> <span class="n">new_obj</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">total_cost</span> <span class="o">+=</span> <span class="n">cost_callable</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 7s, sys: 238 ms, total: 1min 7s
Wall time: 19.5 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Run-MF-HVKG">Run MF-HVKG<a class="anchor-link" href="#Run-MF-HVKG">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">train_x_kg</span><span class="p">,</span> <span class="n">train_obj_kg</span> <span class="o">=</span> <span class="n">gen_init_data</span><span class="p">(</span><span class="n">n_INIT</span><span class="p">)</span>
<span class="n">MF_n_INIT</span> <span class="o">=</span> <span class="n">train_x_kg</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_cost</span> <span class="o">=</span> <span class="n">cost_callable</span><span class="p">(</span><span class="n">train_x_kg</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="k">while</span> <span class="n">total_cost</span> <span class="o">&lt;</span> <span class="n">EVAL_BUDGET</span> <span class="o">*</span> <span class="n">cost_func</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cost: </span><span class="si">{</span><span class="n">total_cost</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># reinitialize the models so they are ready for fitting on next iteration</span>
    <span class="n">mll</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">initialize_model</span><span class="p">(</span><span class="n">normalize</span><span class="p">(</span><span class="n">train_x_kg</span><span class="p">,</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="p">),</span> <span class="n">train_obj_kg</span><span class="p">)</span>

    <span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="o">=</span><span class="n">mll</span><span class="p">)</span>  <span class="c1"># Fit the model</span>
    <span class="c1"># optimize acquisition functions and get new observations</span>
    <span class="n">new_x</span><span class="p">,</span> <span class="n">new_obj</span> <span class="o">=</span> <span class="n">optimize_HVKG_and_get_obs</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">ref_point</span><span class="o">=</span><span class="n">ref_point</span><span class="p">,</span>
        <span class="n">standard_bounds</span><span class="o">=</span><span class="n">standard_bounds</span><span class="p">,</span>
        <span class="n">BATCH_SIZE</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
        <span class="n">cost_call</span><span class="o">=</span><span class="n">cost_callable</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Updating train_x and train_obj</span>
    <span class="n">train_x_kg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">train_x_kg</span><span class="p">,</span> <span class="n">new_x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_obj_kg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">train_obj_kg</span><span class="p">,</span> <span class="n">new_obj</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">total_cost</span> <span class="o">+=</span> <span class="n">cost_callable</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 16min 30s, sys: 3.03 s, total: 16min 33s
Wall time: 4min 36s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Result:--Evaluating-the-Pareto-front-at-the-highest-fidelity-using-NSGA-II-on-the-posterior-mean">Result:  Evaluating the Pareto front at the highest fidelity using NSGA-II on the posterior mean<a class="anchor-link" href="#Result:--Evaluating-the-Pareto-front-at-the-highest-fidelity-using-NSGA-II-on-the-posterior-mean">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">botorch.utils.multi_objective.pareto</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_is_non_dominated_loop</span><span class="p">,</span>
    <span class="n">is_non_dominated</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">gpytorch</span> <span class="kn">import</span> <span class="n">settings</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Note: These are the pymoo 0.6+ imports, if you happen to be stuck on</span>
    <span class="c1"># an older pymoo version you need to replace them with the ones below.</span>
    <span class="kn">from</span> <span class="nn">pymoo.algorithms.moo.nsga2</span> <span class="kn">import</span> <span class="n">NSGA2</span>
    <span class="kn">from</span> <span class="nn">pymoo.core.problem</span> <span class="kn">import</span> <span class="n">Problem</span>
    <span class="kn">from</span> <span class="nn">pymoo.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
    <span class="kn">from</span> <span class="nn">pymoo.termination.max_gen</span> <span class="kn">import</span> <span class="n">MaximumGenerationTermination</span>

    <span class="c1"># from pymoo.algorithms.nsga2 import NSGA2</span>
    <span class="c1"># from pymoo.model.problem import Problem</span>
    <span class="c1"># from pymoo.util.termination.max_gen import MaximumGenerationTermination</span>

    <span class="k">def</span> <span class="nf">get_pareto</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">non_fidelity_indices</span><span class="p">,</span>
        <span class="n">project</span><span class="p">,</span>
        <span class="n">population_size</span><span class="o">=</span><span class="mi">20</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">250</span><span class="p">,</span>
        <span class="n">max_gen</span><span class="o">=</span><span class="mi">10</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">is_mf_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""Optimize the posterior mean using NSGA-II."""</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"dtype"</span><span class="p">:</span> <span class="n">BC</span><span class="o">.</span><span class="n">ref_point</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="n">BC</span><span class="o">.</span><span class="n">ref_point</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">non_fidelity_indices</span><span class="p">)</span>

        <span class="k">class</span> <span class="nc">PosteriorMeanPymooProblem</span><span class="p">(</span><span class="n">Problem</span><span class="p">):</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
                    <span class="n">n_var</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                    <span class="n">n_obj</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">num_objectives</span><span class="p">,</span>
                    <span class="n">type_var</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">xl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">xu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">is_mf_model</span><span class="p">:</span>
                    <span class="n">X</span> <span class="o">=</span> <span class="n">project</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">cholesky_max_tries</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
                        <span class="c1"># eval in batch mode</span>
                        <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">out</span><span class="p">[</span><span class="s2">"F"</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">pymoo_problem</span> <span class="o">=</span> <span class="n">PosteriorMeanPymooProblem</span><span class="p">()</span>
        <span class="n">algorithm</span> <span class="o">=</span> <span class="n">NSGA2</span><span class="p">(</span>
            <span class="n">pop_size</span><span class="o">=</span><span class="n">population_size</span><span class="p">,</span>
            <span class="n">eliminate_duplicates</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
            <span class="n">pymoo_problem</span><span class="p">,</span>
            <span class="n">algorithm</span><span class="p">,</span>
            <span class="n">termination</span><span class="o">=</span><span class="n">MaximumGenerationTermination</span><span class="p">(</span><span class="n">max_gen</span><span class="p">),</span>
            <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># fix seed</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="n">res</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="o">**</span><span class="n">tkwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># project to full fidelity</span>
        <span class="k">if</span> <span class="n">is_mf_model</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">project</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">project</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># determine Pareto set of designs under model</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">pareto_mask</span> <span class="o">=</span> <span class="n">is_non_dominated</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">pareto_mask</span><span class="p">]</span>
        <span class="c1"># evaluate Pareto set of designs on true function and compute hypervolume</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_mf_model</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">project</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">unnormalize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">BC</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># compute HV</span>
        <span class="n">partitioning</span> <span class="o">=</span> <span class="n">FastNondominatedPartitioning</span><span class="p">(</span><span class="n">ref_point</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">ref_point</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">partitioning</span><span class="o">.</span><span class="n">compute_hypervolume</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">NUM_DISCRETE_POINTS</span> <span class="o">=</span> <span class="mi">10</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">100000</span>
    <span class="n">CHUNK_SIZE</span> <span class="o">=</span> <span class="mi">512</span>

    <span class="k">def</span> <span class="nf">get_pareto</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">non_fidelity_indices</span><span class="p">,</span>
        <span class="n">project</span><span class="p">,</span>
        <span class="n">population_size</span><span class="o">=</span><span class="mi">20</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">250</span><span class="p">,</span>
        <span class="n">max_gen</span><span class="o">=</span><span class="mi">10</span> <span class="k">if</span> <span class="n">SMOKE_TEST</span> <span class="k">else</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">is_mf_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""Optimize the posterior mean over a discrete set."""</span>
        <span class="n">tkwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"dtype"</span><span class="p">:</span> <span class="n">BC</span><span class="o">.</span><span class="n">ref_point</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="n">BC</span><span class="o">.</span><span class="n">ref_point</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">dim_x</span> <span class="o">=</span> <span class="n">BC</span><span class="o">.</span><span class="n">dim</span>

        <span class="n">discrete_set</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">NUM_DISCRETE_POINTS</span><span class="p">,</span> <span class="n">dim_x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">tkwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_mf_model</span><span class="p">:</span>
            <span class="n">discrete_set</span> <span class="o">=</span> <span class="n">project</span><span class="p">(</span><span class="n">discrete_set</span><span class="p">)</span>
        <span class="n">discrete_set</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># set to target fidelity</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">preds_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">NUM_DISCRETE_POINTS</span><span class="p">,</span> <span class="n">CHUNK_SIZE</span><span class="p">):</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                    <span class="n">discrete_set</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">CHUNK_SIZE</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">preds_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">preds_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">pareto_mask</span> <span class="o">=</span> <span class="n">_is_non_dominated_loop</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
            <span class="n">pareto_X</span> <span class="o">=</span> <span class="n">discrete_set</span><span class="p">[</span><span class="n">pareto_mask</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_mf_model</span><span class="p">:</span>
            <span class="n">pareto_X</span> <span class="o">=</span> <span class="n">project</span><span class="p">(</span><span class="n">pareto_X</span><span class="p">)</span>
        <span class="n">pareto_X</span> <span class="o">=</span> <span class="n">unnormalize</span><span class="p">(</span><span class="n">pareto_X</span><span class="p">,</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">BC</span><span class="p">(</span><span class="n">pareto_X</span><span class="p">)</span>
        <span class="c1"># compute HV</span>
        <span class="n">partitioning</span> <span class="o">=</span> <span class="n">FastNondominatedPartitioning</span><span class="p">(</span><span class="n">ref_point</span><span class="o">=</span><span class="n">BC</span><span class="o">.</span><span class="n">ref_point</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">partitioning</span><span class="o">.</span><span class="n">compute_hypervolume</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluate-MF-HVKG">Evaluate MF-HVKG<a class="anchor-link" href="#Evaluate-MF-HVKG">¶</a></h2><p>We evaluate performance after every 5 evaluations (this is to speed things up, since there are many observations).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">hvs_kg</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MF_n_INIT</span><span class="p">,</span> <span class="n">train_x_kg</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>

    <span class="n">mll</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">initialize_model</span><span class="p">(</span>
        <span class="n">normalize</span><span class="p">(</span><span class="n">train_x_kg</span><span class="p">[:</span><span class="n">i</span><span class="p">],</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="p">),</span> <span class="n">train_obj_kg</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
    <span class="n">hypervolume</span> <span class="o">=</span> <span class="n">get_pareto</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">non_fidelity_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">hvs_kg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hypervolume</span><span class="p">)</span>
    <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_callable</span><span class="p">(</span><span class="n">train_x_kg</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 20s, sys: 240 ms, total: 1min 21s
Wall time: 30.6 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluate-MOMF">Evaluate MOMF<a class="anchor-link" href="#Evaluate-MOMF">¶</a></h2><p>We evaluate performance after every evaluation (there are not as many evaluations since MOMF queries higher fidelities more frequently).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">hvs_momf</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">costs_momf</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MF_n_INIT</span><span class="p">,</span> <span class="n">train_x_momf</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

    <span class="n">mll</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">initialize_model</span><span class="p">(</span>
        <span class="n">normalize</span><span class="p">(</span><span class="n">train_x_momf</span><span class="p">[:</span><span class="n">i</span><span class="p">],</span> <span class="n">BC</span><span class="o">.</span><span class="n">bounds</span><span class="p">),</span> <span class="n">train_obj_momf</span><span class="p">[:</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
    <span class="n">hypervolume</span> <span class="o">=</span> <span class="n">get_pareto</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">non_fidelity_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">hvs_momf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hypervolume</span><span class="p">)</span>
    <span class="n">costs_momf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost_callable</span><span class="p">(</span><span class="n">train_x_momf</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
/home/alexander/.local/lib/python3.10/site-packages/gpytorch/likelihoods/noise_models.py:148: NumericalWarning: Very small noise values detected. This will likely lead to numerical instabilities. Rounding small noise values up to 1e-06.
  warnings.warn(
</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 18s, sys: 260 ms, total: 1min 19s
Wall time: 28.4 s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Plot-log-inference-hypervolume-regret-(under-the-model)-vs-cost">Plot log inference hypervolume regret (under the model) vs cost<a class="anchor-link" href="#Plot-log-inference-hypervolume-regret-(under-the-model)-vs-cost">¶</a></h3><p>Log inference hypervolume regret, defined as the logarithm of the difference between the maximum hypervolume dominated by the Pareto frontier and the hypervolume corresponding to the Pareto set identified by each algorithm, is a performance evaluation criterion for multi-information source multi-objective optimization [3].</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">costs_momf</span><span class="p">,</span>
    <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">BC</span><span class="o">.</span><span class="n">max_hv</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hvs_momf</span><span class="p">)),</span>
    <span class="s2">"--"</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">"s"</span><span class="p">,</span>
    <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">"MOMF"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">costs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">BC</span><span class="o">.</span><span class="n">max_hv</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hvs_kg</span><span class="p">)),</span> <span class="s2">"--"</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">"d"</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"HVKG"</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Log Inference Hypervolume Regret"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Cost"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[14]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.legend.Legend at 0x7f2b5e484550&gt;</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_png output_subarea">
<img alt="No description has been provided for this image" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
</div>